{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/1xa100-2/llama-stack/envs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>markdown</th>\n",
       "      <th>html</th>\n",
       "      <th>crawlDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤗 Transformers</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># 🤗 Transformers\\n\\nState-of-the-art Machine L...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:30:32.994Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quick tour</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Quick tour\\n\\nGet up and running with 🤗 Tran...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:30:34.381Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Installation</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Installation\\n\\nInstall 🤗 Transformers for w...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:30:34.498Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pipelines for inference</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Pipelines for inference\\n\\nThe [pipeline()](...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:30:35.128Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Load pretrained instances with an AutoClass</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Load pretrained instances with an AutoClass\\...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:30:35.231Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0                               🤗 Transformers   \n",
       "1                                   Quick tour   \n",
       "2                                 Installation   \n",
       "3                      Pipelines for inference   \n",
       "4  Load pretrained instances with an AutoClass   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://huggingface.co/docs/transformers/v4.34...   \n",
       "1  https://huggingface.co/docs/transformers/v4.34...   \n",
       "2  https://huggingface.co/docs/transformers/v4.34...   \n",
       "3  https://huggingface.co/docs/transformers/v4.34...   \n",
       "4  https://huggingface.co/docs/transformers/v4.34...   \n",
       "\n",
       "                                            markdown  \\\n",
       "0  # 🤗 Transformers\\n\\nState-of-the-art Machine L...   \n",
       "1  # Quick tour\\n\\nGet up and running with 🤗 Tran...   \n",
       "2  # Installation\\n\\nInstall 🤗 Transformers for w...   \n",
       "3  # Pipelines for inference\\n\\nThe [pipeline()](...   \n",
       "4  # Load pretrained instances with an AutoClass\\...   \n",
       "\n",
       "                                                html                 crawlDate  \n",
       "0  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:30:32.994Z  \n",
       "1  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:30:34.381Z  \n",
       "2  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:30:34.498Z  \n",
       "3  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:30:35.128Z  \n",
       "4  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:30:35.231Z  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"philschmid/markdown-documentation-transformers\")\n",
    "\n",
    "dataset\n",
    "\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>markdown</th>\n",
       "      <th>context</th>\n",
       "      <th>crawlDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PoolFormer</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># PoolFormer\\n\\n## Overview\\n\\nThe PoolFormer ...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:32:52.509Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object detection</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Object detection\\n\\nObject detection is the ...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:33:45.839Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utilities for `FeatureExtractors`</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Utilities for \\`FeatureExtractors\\`\\n\\nThis ...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:31:15.859Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perplexity of fixed-length models</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Perplexity of fixed-length models\\n\\nPerplex...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:30:55.946Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sample usage</td>\n",
       "      <td>https://huggingface.co/docs/transformers/v4.34...</td>\n",
       "      <td># Sample usage\\n\\n## UMT5\\n\\n[![Models](https:...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html class=\"\"&gt;&lt;head&gt;\\n\\t\\t&lt;met...</td>\n",
       "      <td>2023-10-05T13:33:19.915Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                         PoolFormer   \n",
       "1                   Object detection   \n",
       "2  Utilities for `FeatureExtractors`   \n",
       "3  Perplexity of fixed-length models   \n",
       "4                       Sample usage   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://huggingface.co/docs/transformers/v4.34...   \n",
       "1  https://huggingface.co/docs/transformers/v4.34...   \n",
       "2  https://huggingface.co/docs/transformers/v4.34...   \n",
       "3  https://huggingface.co/docs/transformers/v4.34...   \n",
       "4  https://huggingface.co/docs/transformers/v4.34...   \n",
       "\n",
       "                                            markdown  \\\n",
       "0  # PoolFormer\\n\\n## Overview\\n\\nThe PoolFormer ...   \n",
       "1  # Object detection\\n\\nObject detection is the ...   \n",
       "2  # Utilities for \\`FeatureExtractors\\`\\n\\nThis ...   \n",
       "3  # Perplexity of fixed-length models\\n\\nPerplex...   \n",
       "4  # Sample usage\\n\\n## UMT5\\n\\n[![Models](https:...   \n",
       "\n",
       "                                             context                 crawlDate  \n",
       "0  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:32:52.509Z  \n",
       "1  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:33:45.839Z  \n",
       "2  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:31:15.859Z  \n",
       "3  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:30:55.946Z  \n",
       "4  <!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<met...  2023-10-05T13:33:19.915Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'html': 'context'})\n",
    "# All 300 documents takes about an 1.5 hours to ingest\n",
    "# So let's sample 100 for now\n",
    "df = df.sample(n=100).reset_index(drop=True)\n",
    "df.to_parquet(\"data/transformers.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank_54'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from counter import get_and_increment_counter\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.types.memory_insert_params import Document\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=\"http://localhost:5001\",\n",
    ")\n",
    "\n",
    "providers = client.providers.list()\n",
    "memory_banks_response = client.memory_banks.list()\n",
    "\n",
    "bank_id = f\"bank_{get_and_increment_counter()}\"\n",
    "provider = providers[\"memory\"][0]\n",
    "client.memory_banks.register(\n",
    "    memory_bank_id=bank_id,\n",
    "    params={\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "        # Is the default for agent config: https://github.com/meta-llama/llama-stack/blob/66d8f4ffd126bff668434b314892a99fe854a034/llama_stack/providers/inline/agents/meta_reference/agent_instance.py#L668\n",
    "        \"chunk_size_in_tokens\": 512,\n",
    "    },\n",
    "    provider_id=provider.provider_id,\n",
    ")\n",
    "bank_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document_id': '0',\n",
       "  'content': '<!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<meta charset=\"utf-8\">\\n\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\">\\n\\t\\t<meta name=\"description\" content=\"We’re on a journey to advance and democratize artificial intelligence through open source and open science.\">\\n\\t\\t<meta property=\"fb:app_id\" content=\"1321688464574422\">\\n\\t\\t<meta name=\"twitter:card\" content=\"summary_large_image\">\\n\\t\\t<meta name=\"twitter:site\" content=\"@huggingface\">\\n\\t\\t<meta property=\"og:title\" content=\"PoolFormer\">\\n\\t\\t<meta property=\"og:type\" content=\"website\">\\n\\t\\t<meta property=\"og:url\" content=\"https://huggingface.co/docs/transformers/v4.34.0/en/model_doc/poolformer\">\\n\\t\\t<meta property=\"og:image\" content=\"https://huggingface.co/front/thumbnails/docs/transformers.png\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"/front/build/kube-b0520c1/style.css\">\\n\\n\\t\\t<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap\" rel=\"stylesheet\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap\" rel=\"stylesheet\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" as=\"style\" onload=\"this.onload=null;this.rel=\\'stylesheet\\'\">\\n\\t\\t<noscript>\\n\\t\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" />\\n\\t\\t</noscript>\\n\\n\\t\\t  \\n\\n\\t\\t<title>PoolFormer</title>\\n\\n\\t\\t<script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script defer=\"\" data-domain=\"huggingface.co\" src=\"/js/script.js\"></script>\\n\\t<script src=\"https://js.stripe.com/v3/\" async=\"\"></script><script src=\"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\" async=\"\"></script><meta http-equiv=\"origin-trial\" content=\"AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9\"><link rel=\"stylesheet\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/assets/0.e3b0c442.css\"><link rel=\"modulepreload\" as=\"script\" crossorigin=\"\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/nodes/1.38c5c2f6.js\"><meta name=\"hf:doc:metadata\" content=\"{&quot;local&quot;:&quot;poolformer&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;overview&quot;,&quot;title&quot;:&quot;Overview&quot;},{&quot;local&quot;:&quot;resources&quot;,&quot;title&quot;:&quot;Resources&quot;},{&quot;local&quot;:&quot;transformers.PoolFormerConfig&quot;,&quot;title&quot;:&quot;PoolFormerConfig&quot;},{&quot;local&quot;:&quot;transformers.PoolFormerFeatureExtractor&quot;,&quot;title&quot;:&quot;PoolFormerFeatureExtractor&quot;},{&quot;local&quot;:&quot;transformers.PoolFormerImageProcessor&quot;,&quot;title&quot;:&quot;PoolFormerImageProcessor&quot;},{&quot;local&quot;:&quot;transformers.PoolFormerModel&quot;,&quot;title&quot;:&quot;PoolFormerModel&quot;},{&quot;local&quot;:&quot;transformers.PoolFormerForImageClassification&quot;,&quot;title&quot;:&quot;PoolFormerForImageClassification&quot;}],&quot;title&quot;:&quot;PoolFormer&quot;}\"></head>\\n\\t<body class=\"flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage\">\\n\\t\\t<div class=\"flex min-h-screen flex-col\">\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}\" data-target=\"MainHeader\"><header class=\"border-b border-gray-100 \"><div class=\"w-full px-4  flex h-16 items-center\"><div class=\"flex flex-1 items-center\"><a class=\"mr-5 flex flex-none items-center lg:mr-6\" href=\"/\"><img alt=\"Hugging Face\\'s logo\" class=\"w-7 md:mr-2\" src=\"/front/assets/huggingface_logo-noborder.svg\"> <span class=\"hidden whitespace-nowrap text-lg font-bold md:block\">Hugging Face</span></a> <div class=\"relative flex-1 lg:max-w-sm mr-2 sm:mr-4 lg:mr-6\"><input autocomplete=\"off\" class=\"w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl\" name=\"\" placeholder=\"Search models, datasets, users...\" spellcheck=\"false\" type=\"text\"> <svg class=\"absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> </div> <div class=\"flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden\"><button class=\"relative z-40 flex h-6 w-8 items-center justify-center\" type=\"button\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 10 10\" class=\"text-xl\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" preserveAspectRatio=\"xMidYMid meet\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\"></path></svg> </button> </div></div> <nav aria-label=\"Main\" class=\"ml-auto hidden lg:block\"><ul class=\"flex items-center space-x-2\"><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700\" href=\"/models\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg> Models</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700\" href=\"/datasets\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-red-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 25 25\"><ellipse cx=\"12.5\" cy=\"5\" fill=\"currentColor\" fill-opacity=\"0.25\" rx=\"7.5\" ry=\"2\"></ellipse><path d=\"M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z\" fill=\"currentColor\"></path></svg> Datasets</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700\" href=\"/spaces\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-blue-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 25 25\"><path opacity=\".5\" d=\"M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z\" fill=\"currentColor\"></path><path opacity=\".75\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z\" fill=\"currentColor\"></path><path opacity=\".25\" d=\"M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z\" fill=\"currentColor\"></path></svg> Spaces</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/docs\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path opacity=\"0.5\" d=\"M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z\" fill=\"currentColor\"></path><path d=\"M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z\" fill=\"currentColor\" fill-opacity=\"0.75\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z\" fill=\"currentColor\"></path><path opacity=\"0.5\" d=\"M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z\" fill=\"currentColor\"></path></svg> Docs</a></li> <li><div class=\"relative \"><button class=\"px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-green-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-tertiary\" d=\"M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z\" fill=\"currentColor\"></path></svg> Solutions </button> </div></li> <li><a class=\"group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/pricing\">Pricing</a></li> <li><div class=\"relative group\"><button class=\"px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 32 18\" preserveAspectRatio=\"xMidYMid meet\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z\" fill=\"currentColor\"></path></svg>  </button> </div></li> <li><hr class=\"h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800\"></li> <li><a class=\"block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/login\">Log In</a></li> <li><a class=\"rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black\" href=\"/join\">Sign Up</a></li></ul></nav></div></header></div>\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"GoogleAnalyticsTracker\"></div>\\n\\t\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"SSOBanner\"></div>\\n\\n\\t<main class=\"flex flex-1 flex-col\"><div class=\"relative lg:flex\"><div class=\"sticky top-0 z-20 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;🤗 Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/index&quot;},{&quot;title&quot;:&quot;Quick tour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;installation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/installation&quot;}]},{&quot;title&quot;:&quot;Tutorials&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Run inference with pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_tutorial&quot;},{&quot;title&quot;:&quot;Write portable code with AutoClass&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;autoclass_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/autoclass_tutorial&quot;},{&quot;title&quot;:&quot;Preprocess data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocessing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/preprocessing&quot;},{&quot;title&quot;:&quot;Fine-tune a pretrained model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/training&quot;},{&quot;title&quot;:&quot;Train with a script&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;run_scripts&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/run_scripts&quot;},{&quot;title&quot;:&quot;Set up distributed training with 🤗 Accelerate&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/accelerate&quot;},{&quot;title&quot;:&quot;Load and train adapters with 🤗 PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;peft&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/peft&quot;},{&quot;title&quot;:&quot;Share your model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_sharing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_sharing&quot;},{&quot;title&quot;:&quot;Agents&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers_agents&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/transformers_agents&quot;},{&quot;title&quot;:&quot;Generation with LLMs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;llm_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/llm_tutorial&quot;}]},{&quot;title&quot;:&quot;Task Guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Natural Language Processing&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text classification&quot;,&quot;id&quot;:&quot;tasks/sequence_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/sequence_classification&quot;},{&quot;title&quot;:&quot;Token classification&quot;,&quot;id&quot;:&quot;tasks/token_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/token_classification&quot;},{&quot;title&quot;:&quot;Question answering&quot;,&quot;id&quot;:&quot;tasks/question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/question_answering&quot;},{&quot;title&quot;:&quot;Causal language modeling&quot;,&quot;id&quot;:&quot;tasks/language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/language_modeling&quot;},{&quot;title&quot;:&quot;Masked language modeling&quot;,&quot;id&quot;:&quot;tasks/masked_language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/masked_language_modeling&quot;},{&quot;title&quot;:&quot;Translation&quot;,&quot;id&quot;:&quot;tasks/translation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/translation&quot;},{&quot;title&quot;:&quot;Summarization&quot;,&quot;id&quot;:&quot;tasks/summarization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/summarization&quot;},{&quot;title&quot;:&quot;Multiple choice&quot;,&quot;id&quot;:&quot;tasks/multiple_choice&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/multiple_choice&quot;}]},{&quot;title&quot;:&quot;Audio&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio classification&quot;,&quot;id&quot;:&quot;tasks/audio_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/audio_classification&quot;},{&quot;title&quot;:&quot;Automatic speech recognition&quot;,&quot;id&quot;:&quot;tasks/asr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/asr&quot;}]},{&quot;title&quot;:&quot;Computer Vision&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image classification&quot;,&quot;id&quot;:&quot;tasks/image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_classification&quot;},{&quot;title&quot;:&quot;Semantic segmentation&quot;,&quot;id&quot;:&quot;tasks/semantic_segmentation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/semantic_segmentation&quot;},{&quot;title&quot;:&quot;Video classification&quot;,&quot;id&quot;:&quot;tasks/video_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/video_classification&quot;},{&quot;title&quot;:&quot;Object detection&quot;,&quot;id&quot;:&quot;tasks/object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot object detection&quot;,&quot;id&quot;:&quot;tasks/zero_shot_object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot image classification&quot;,&quot;id&quot;:&quot;tasks/zero_shot_image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_image_classification&quot;},{&quot;title&quot;:&quot;Depth estimation&quot;,&quot;id&quot;:&quot;tasks/monocular_depth_estimation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/monocular_depth_estimation&quot;}]},{&quot;title&quot;:&quot;Multimodal&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image captioning&quot;,&quot;id&quot;:&quot;tasks/image_captioning&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_captioning&quot;},{&quot;title&quot;:&quot;Document Question Answering&quot;,&quot;id&quot;:&quot;tasks/document_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/document_question_answering&quot;},{&quot;title&quot;:&quot;Visual Question Answering&quot;,&quot;id&quot;:&quot;tasks/visual_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/visual_question_answering&quot;},{&quot;title&quot;:&quot;Text to speech&quot;,&quot;id&quot;:&quot;tasks/text-to-speech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/text-to-speech&quot;}]},{&quot;title&quot;:&quot;Generation&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Customize the generation strategy&quot;,&quot;id&quot;:&quot;generation_strategies&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/generation_strategies&quot;}]},{&quot;title&quot;:&quot;Prompting&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image tasks with IDEFICS&quot;,&quot;id&quot;:&quot;tasks/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/idefics&quot;}]}]},{&quot;title&quot;:&quot;Developer guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Use fast tokenizers from 🤗 Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/fast_tokenizers&quot;},{&quot;title&quot;:&quot;Run inference with multilingual models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multilingual&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/multilingual&quot;},{&quot;title&quot;:&quot;Use model-specific APIs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;create_a_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/create_a_model&quot;},{&quot;title&quot;:&quot;Share a custom model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_models&quot;},{&quot;title&quot;:&quot;Templates for chat models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;chat_templating&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/chat_templating&quot;},{&quot;title&quot;:&quot;Run training on Amazon SageMaker&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sagemaker&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/sagemaker&quot;},{&quot;title&quot;:&quot;Export to ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;serialization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/serialization&quot;},{&quot;title&quot;:&quot;Export to TFLite&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tflite&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tflite&quot;},{&quot;title&quot;:&quot;Export to TorchScript&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;torchscript&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/torchscript&quot;},{&quot;title&quot;:&quot;Benchmarks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;benchmarks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/benchmarks&quot;},{&quot;title&quot;:&quot;Notebooks with examples&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;notebooks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/notebooks&quot;},{&quot;title&quot;:&quot;Community resources&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;community&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/community&quot;},{&quot;title&quot;:&quot;Custom Tools and Prompts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_tools&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_tools&quot;},{&quot;title&quot;:&quot;Troubleshoot&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;troubleshooting&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/troubleshooting&quot;}]},{&quot;title&quot;:&quot;Performance and scalability&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Overview&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/performance&quot;},{&quot;title&quot;:&quot;Efficient training techniques&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Methods and tools for efficient training on a single GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_one&quot;},{&quot;title&quot;:&quot;Multiple GPUs and parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_many&quot;},{&quot;title&quot;:&quot;Efficient training on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu&quot;},{&quot;title&quot;:&quot;Distributed CPU training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu_many&quot;},{&quot;title&quot;:&quot;Training on TPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu&quot;},{&quot;title&quot;:&quot;Training on TPU with TensorFlow&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu_tf&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu_tf&quot;},{&quot;title&quot;:&quot;Training on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_special&quot;},{&quot;title&quot;:&quot;Custom hardware for training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_hardware&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_hardware&quot;},{&quot;title&quot;:&quot;Hyperparameter Search using Trainer API&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;hpo_train&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/hpo_train&quot;}]},{&quot;title&quot;:&quot;Optimizing inference&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Inference on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_cpu&quot;},{&quot;title&quot;:&quot;Inference on one GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_one&quot;},{&quot;title&quot;:&quot;Inference on many GPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_many&quot;},{&quot;title&quot;:&quot;Inference on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_special&quot;}]},{&quot;title&quot;:&quot;Instantiating a big model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;big_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/big_models&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;debugging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/debugging&quot;},{&quot;title&quot;:&quot;XLA Integration for TensorFlow Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tf_xla&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tf_xla&quot;},{&quot;title&quot;:&quot;Optimize inference using `torch.compile()`&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_torch_compile&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_torch_compile&quot;}]},{&quot;title&quot;:&quot;Contribute&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;How to contribute to transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contributing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/contributing&quot;},{&quot;title&quot;:&quot;How to add a model to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_model&quot;},{&quot;title&quot;:&quot;How to convert a 🤗 Transformers model to TensorFlow?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_tensorflow_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_tensorflow_model&quot;},{&quot;title&quot;:&quot;How to add a pipeline to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_pipeline&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_pipeline&quot;},{&quot;title&quot;:&quot;Testing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;testing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/testing&quot;},{&quot;title&quot;:&quot;Checks on a Pull Request&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pr_checks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pr_checks&quot;}]},{&quot;title&quot;:&quot;Conceptual guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Philosophy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;philosophy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/philosophy&quot;},{&quot;title&quot;:&quot;Glossary&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;glossary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/glossary&quot;},{&quot;title&quot;:&quot;What 🤗 Transformers can do&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/task_summary&quot;},{&quot;title&quot;:&quot;How 🤗 Transformers solve tasks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tasks_explained&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks_explained&quot;},{&quot;title&quot;:&quot;The Transformer model family&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_summary&quot;},{&quot;title&quot;:&quot;Summary of the tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tokenizer_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tokenizer_summary&quot;},{&quot;title&quot;:&quot;Attention mechanisms&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;attention&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/attention&quot;},{&quot;title&quot;:&quot;Padding and truncation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pad_truncation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pad_truncation&quot;},{&quot;title&quot;:&quot;BERTology&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bertology&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/bertology&quot;},{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perplexity&quot;},{&quot;title&quot;:&quot;Pipelines for webserver inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_webserver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_webserver&quot;},{&quot;title&quot;:&quot;Model training anatomy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_memory_anatomy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_memory_anatomy&quot;}]},{&quot;title&quot;:&quot;API&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main Classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Agents and Tools&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/agent&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/agent&quot;},{&quot;title&quot;:&quot;Auto Classes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/auto&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/auto&quot;},{&quot;title&quot;:&quot;Callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/callback&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/callback&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/configuration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/configuration&quot;},{&quot;title&quot;:&quot;Data Collator&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/data_collator&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/data_collator&quot;},{&quot;title&quot;:&quot;Keras callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/keras_callbacks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/keras_callbacks&quot;},{&quot;title&quot;:&quot;Logging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/logging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/logging&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/model&quot;},{&quot;title&quot;:&quot;Text Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/text_generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/text_generation&quot;},{&quot;title&quot;:&quot;ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/onnx&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/onnx&quot;},{&quot;title&quot;:&quot;Optimization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/optimizer_schedules&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules&quot;},{&quot;title&quot;:&quot;Model outputs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/output&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/output&quot;},{&quot;title&quot;:&quot;Pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/pipelines&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/pipelines&quot;},{&quot;title&quot;:&quot;Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/processors&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/processors&quot;},{&quot;title&quot;:&quot;Quantization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/quantization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/quantization&quot;},{&quot;title&quot;:&quot;Tokenizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/tokenizer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/tokenizer&quot;},{&quot;title&quot;:&quot;Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/trainer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/trainer&quot;},{&quot;title&quot;:&quot;DeepSpeed Integration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/deepspeed&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/deepspeed&quot;},{&quot;title&quot;:&quot;Feature Extractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/feature_extractor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/feature_extractor&quot;},{&quot;title&quot;:&quot;Image Processor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/image_processor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/image_processor&quot;}]},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALBERT&quot;,&quot;id&quot;:&quot;model_doc/albert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/albert&quot;},{&quot;title&quot;:&quot;BART&quot;,&quot;id&quot;:&quot;model_doc/bart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bart&quot;},{&quot;title&quot;:&quot;BARThez&quot;,&quot;id&quot;:&quot;model_doc/barthez&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/barthez&quot;},{&quot;title&quot;:&quot;BARTpho&quot;,&quot;id&quot;:&quot;model_doc/bartpho&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bartpho&quot;},{&quot;title&quot;:&quot;BERT&quot;,&quot;id&quot;:&quot;model_doc/bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert&quot;},{&quot;title&quot;:&quot;BertGeneration&quot;,&quot;id&quot;:&quot;model_doc/bert-generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-generation&quot;},{&quot;title&quot;:&quot;BertJapanese&quot;,&quot;id&quot;:&quot;model_doc/bert-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-japanese&quot;},{&quot;title&quot;:&quot;Bertweet&quot;,&quot;id&quot;:&quot;model_doc/bertweet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bertweet&quot;},{&quot;title&quot;:&quot;BigBird&quot;,&quot;id&quot;:&quot;model_doc/big_bird&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/big_bird&quot;},{&quot;title&quot;:&quot;BigBirdPegasus&quot;,&quot;id&quot;:&quot;model_doc/bigbird_pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bigbird_pegasus&quot;},{&quot;title&quot;:&quot;BioGpt&quot;,&quot;id&quot;:&quot;model_doc/biogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/biogpt&quot;},{&quot;title&quot;:&quot;Blenderbot&quot;,&quot;id&quot;:&quot;model_doc/blenderbot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot&quot;},{&quot;title&quot;:&quot;Blenderbot Small&quot;,&quot;id&quot;:&quot;model_doc/blenderbot-small&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot-small&quot;},{&quot;title&quot;:&quot;BLOOM&quot;,&quot;id&quot;:&quot;model_doc/bloom&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bloom&quot;},{&quot;title&quot;:&quot;BORT&quot;,&quot;id&quot;:&quot;model_doc/bort&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bort&quot;},{&quot;title&quot;:&quot;ByT5&quot;,&quot;id&quot;:&quot;model_doc/byt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/byt5&quot;},{&quot;title&quot;:&quot;CamemBERT&quot;,&quot;id&quot;:&quot;model_doc/camembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/camembert&quot;},{&quot;title&quot;:&quot;CANINE&quot;,&quot;id&quot;:&quot;model_doc/canine&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/canine&quot;},{&quot;title&quot;:&quot;CodeGen&quot;,&quot;id&quot;:&quot;model_doc/codegen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/codegen&quot;},{&quot;title&quot;:&quot;CodeLlama&quot;,&quot;id&quot;:&quot;model_doc/code_llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/code_llama&quot;},{&quot;title&quot;:&quot;ConvBERT&quot;,&quot;id&quot;:&quot;model_doc/convbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convbert&quot;},{&quot;title&quot;:&quot;CPM&quot;,&quot;id&quot;:&quot;model_doc/cpm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpm&quot;},{&quot;title&quot;:&quot;CPMANT&quot;,&quot;id&quot;:&quot;model_doc/cpmant&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpmant&quot;},{&quot;title&quot;:&quot;CTRL&quot;,&quot;id&quot;:&quot;model_doc/ctrl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ctrl&quot;},{&quot;title&quot;:&quot;DeBERTa&quot;,&quot;id&quot;:&quot;model_doc/deberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta&quot;},{&quot;title&quot;:&quot;DeBERTa-v2&quot;,&quot;id&quot;:&quot;model_doc/deberta-v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta-v2&quot;},{&quot;title&quot;:&quot;DialoGPT&quot;,&quot;id&quot;:&quot;model_doc/dialogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dialogpt&quot;},{&quot;title&quot;:&quot;DistilBERT&quot;,&quot;id&quot;:&quot;model_doc/distilbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/distilbert&quot;},{&quot;title&quot;:&quot;DPR&quot;,&quot;id&quot;:&quot;model_doc/dpr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpr&quot;},{&quot;title&quot;:&quot;ELECTRA&quot;,&quot;id&quot;:&quot;model_doc/electra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/electra&quot;},{&quot;title&quot;:&quot;Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encoder-decoder&quot;},{&quot;title&quot;:&quot;ERNIE&quot;,&quot;id&quot;:&quot;model_doc/ernie&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie&quot;},{&quot;title&quot;:&quot;ErnieM&quot;,&quot;id&quot;:&quot;model_doc/ernie_m&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie_m&quot;},{&quot;title&quot;:&quot;ESM&quot;,&quot;id&quot;:&quot;model_doc/esm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/esm&quot;},{&quot;title&quot;:&quot;Falcon&quot;,&quot;id&quot;:&quot;model_doc/falcon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/falcon&quot;},{&quot;title&quot;:&quot;FLAN-T5&quot;,&quot;id&quot;:&quot;model_doc/flan-t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-t5&quot;},{&quot;title&quot;:&quot;FLAN-UL2&quot;,&quot;id&quot;:&quot;model_doc/flan-ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-ul2&quot;},{&quot;title&quot;:&quot;FlauBERT&quot;,&quot;id&quot;:&quot;model_doc/flaubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flaubert&quot;},{&quot;title&quot;:&quot;FNet&quot;,&quot;id&quot;:&quot;model_doc/fnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fnet&quot;},{&quot;title&quot;:&quot;FSMT&quot;,&quot;id&quot;:&quot;model_doc/fsmt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fsmt&quot;},{&quot;title&quot;:&quot;Funnel Transformer&quot;,&quot;id&quot;:&quot;model_doc/funnel&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/funnel&quot;},{&quot;title&quot;:&quot;GPT&quot;,&quot;id&quot;:&quot;model_doc/openai-gpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/openai-gpt&quot;},{&quot;title&quot;:&quot;GPT Neo&quot;,&quot;id&quot;:&quot;model_doc/gpt_neo&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neo&quot;},{&quot;title&quot;:&quot;GPT NeoX&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox&quot;},{&quot;title&quot;:&quot;GPT NeoX Japanese&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox_japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox_japanese&quot;},{&quot;title&quot;:&quot;GPT-J&quot;,&quot;id&quot;:&quot;model_doc/gptj&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptj&quot;},{&quot;title&quot;:&quot;GPT2&quot;,&quot;id&quot;:&quot;model_doc/gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt2&quot;},{&quot;title&quot;:&quot;GPTBigCode&quot;,&quot;id&quot;:&quot;model_doc/gpt_bigcode&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_bigcode&quot;},{&quot;title&quot;:&quot;GPTSAN Japanese&quot;,&quot;id&quot;:&quot;model_doc/gptsan-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptsan-japanese&quot;},{&quot;title&quot;:&quot;GPTSw3&quot;,&quot;id&quot;:&quot;model_doc/gpt-sw3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt-sw3&quot;},{&quot;title&quot;:&quot;HerBERT&quot;,&quot;id&quot;:&quot;model_doc/herbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/herbert&quot;},{&quot;title&quot;:&quot;I-BERT&quot;,&quot;id&quot;:&quot;model_doc/ibert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ibert&quot;},{&quot;title&quot;:&quot;Jukebox&quot;,&quot;id&quot;:&quot;model_doc/jukebox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/jukebox&quot;},{&quot;title&quot;:&quot;LED&quot;,&quot;id&quot;:&quot;model_doc/led&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/led&quot;},{&quot;title&quot;:&quot;LLaMA&quot;,&quot;id&quot;:&quot;model_doc/llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama&quot;},{&quot;title&quot;:&quot;Llama2&quot;,&quot;id&quot;:&quot;model_doc/llama2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama2&quot;},{&quot;title&quot;:&quot;Longformer&quot;,&quot;id&quot;:&quot;model_doc/longformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longformer&quot;},{&quot;title&quot;:&quot;LongT5&quot;,&quot;id&quot;:&quot;model_doc/longt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longt5&quot;},{&quot;title&quot;:&quot;LUKE&quot;,&quot;id&quot;:&quot;model_doc/luke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/luke&quot;},{&quot;title&quot;:&quot;M2M100&quot;,&quot;id&quot;:&quot;model_doc/m2m_100&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/m2m_100&quot;},{&quot;title&quot;:&quot;MarianMT&quot;,&quot;id&quot;:&quot;model_doc/marian&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/marian&quot;},{&quot;title&quot;:&quot;MarkupLM&quot;,&quot;id&quot;:&quot;model_doc/markuplm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/markuplm&quot;},{&quot;title&quot;:&quot;MBart and MBart-50&quot;,&quot;id&quot;:&quot;model_doc/mbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mbart&quot;},{&quot;title&quot;:&quot;MEGA&quot;,&quot;id&quot;:&quot;model_doc/mega&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mega&quot;},{&quot;title&quot;:&quot;MegatronBERT&quot;,&quot;id&quot;:&quot;model_doc/megatron-bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron-bert&quot;},{&quot;title&quot;:&quot;MegatronGPT2&quot;,&quot;id&quot;:&quot;model_doc/megatron_gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron_gpt2&quot;},{&quot;title&quot;:&quot;Mistral&quot;,&quot;id&quot;:&quot;model_doc/mistral&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mistral&quot;},{&quot;title&quot;:&quot;mLUKE&quot;,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MobileBERT&quot;,&quot;id&quot;:&quot;model_doc/mobilebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilebert&quot;},{&quot;title&quot;:&quot;MPNet&quot;,&quot;id&quot;:&quot;model_doc/mpnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpnet&quot;},{&quot;title&quot;:&quot;MPT&quot;,&quot;id&quot;:&quot;model_doc/mpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpt&quot;},{&quot;title&quot;:&quot;MRA&quot;,&quot;id&quot;:&quot;model_doc/mra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mra&quot;},{&quot;title&quot;:&quot;MT5&quot;,&quot;id&quot;:&quot;model_doc/mt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mt5&quot;},{&quot;title&quot;:&quot;MVP&quot;,&quot;id&quot;:&quot;model_doc/mvp&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mvp&quot;},{&quot;title&quot;:&quot;NEZHA&quot;,&quot;id&quot;:&quot;model_doc/nezha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nezha&quot;},{&quot;title&quot;:&quot;NLLB&quot;,&quot;id&quot;:&quot;model_doc/nllb&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb&quot;},{&quot;title&quot;:&quot;NLLB-MoE&quot;,&quot;id&quot;:&quot;model_doc/nllb-moe&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb-moe&quot;},{&quot;title&quot;:&quot;Nyströmformer&quot;,&quot;id&quot;:&quot;model_doc/nystromformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nystromformer&quot;},{&quot;title&quot;:&quot;Open-Llama&quot;,&quot;id&quot;:&quot;model_doc/open-llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/open-llama&quot;},{&quot;title&quot;:&quot;OPT&quot;,&quot;id&quot;:&quot;model_doc/opt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/opt&quot;},{&quot;title&quot;:&quot;Pegasus&quot;,&quot;id&quot;:&quot;model_doc/pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus&quot;},{&quot;title&quot;:&quot;PEGASUS-X&quot;,&quot;id&quot;:&quot;model_doc/pegasus_x&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus_x&quot;},{&quot;title&quot;:&quot;Persimmon&quot;,&quot;id&quot;:&quot;model_doc/persimmon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/persimmon&quot;},{&quot;title&quot;:&quot;PhoBERT&quot;,&quot;id&quot;:&quot;model_doc/phobert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/phobert&quot;},{&quot;title&quot;:&quot;PLBart&quot;,&quot;id&quot;:&quot;model_doc/plbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/plbart&quot;},{&quot;title&quot;:&quot;ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/prophetnet&quot;},{&quot;title&quot;:&quot;QDQBert&quot;,&quot;id&quot;:&quot;model_doc/qdqbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/qdqbert&quot;},{&quot;title&quot;:&quot;RAG&quot;,&quot;id&quot;:&quot;model_doc/rag&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rag&quot;},{&quot;title&quot;:&quot;REALM&quot;,&quot;id&quot;:&quot;model_doc/realm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/realm&quot;},{&quot;title&quot;:&quot;Reformer&quot;,&quot;id&quot;:&quot;model_doc/reformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/reformer&quot;},{&quot;title&quot;:&quot;RemBERT&quot;,&quot;id&quot;:&quot;model_doc/rembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rembert&quot;},{&quot;title&quot;:&quot;RetriBERT&quot;,&quot;id&quot;:&quot;model_doc/retribert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/retribert&quot;},{&quot;title&quot;:&quot;RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta&quot;},{&quot;title&quot;:&quot;RoBERTa-PreLayerNorm&quot;,&quot;id&quot;:&quot;model_doc/roberta-prelayernorm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta-prelayernorm&quot;},{&quot;title&quot;:&quot;RoCBert&quot;,&quot;id&quot;:&quot;model_doc/roc_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roc_bert&quot;},{&quot;title&quot;:&quot;RoFormer&quot;,&quot;id&quot;:&quot;model_doc/roformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roformer&quot;},{&quot;title&quot;:&quot;RWKV&quot;,&quot;id&quot;:&quot;model_doc/rwkv&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rwkv&quot;},{&quot;title&quot;:&quot;Splinter&quot;,&quot;id&quot;:&quot;model_doc/splinter&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/splinter&quot;},{&quot;title&quot;:&quot;SqueezeBERT&quot;,&quot;id&quot;:&quot;model_doc/squeezebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/squeezebert&quot;},{&quot;title&quot;:&quot;SwitchTransformers&quot;,&quot;id&quot;:&quot;model_doc/switch_transformers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/switch_transformers&quot;},{&quot;title&quot;:&quot;T5&quot;,&quot;id&quot;:&quot;model_doc/t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5&quot;},{&quot;title&quot;:&quot;T5v1.1&quot;,&quot;id&quot;:&quot;model_doc/t5v1.1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5v1.1&quot;},{&quot;title&quot;:&quot;TAPEX&quot;,&quot;id&quot;:&quot;model_doc/tapex&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapex&quot;},{&quot;title&quot;:&quot;Transformer XL&quot;,&quot;id&quot;:&quot;model_doc/transfo-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/transfo-xl&quot;},{&quot;title&quot;:&quot;UL2&quot;,&quot;id&quot;:&quot;model_doc/ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ul2&quot;},{&quot;title&quot;:&quot;UMT5&quot;,&quot;id&quot;:&quot;model_doc/umt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/umt5&quot;},{&quot;title&quot;:&quot;X-MOD&quot;,&quot;id&quot;:&quot;model_doc/xmod&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xmod&quot;},{&quot;title&quot;:&quot;XGLM&quot;,&quot;id&quot;:&quot;model_doc/xglm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xglm&quot;},{&quot;title&quot;:&quot;XLM&quot;,&quot;id&quot;:&quot;model_doc/xlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm&quot;},{&quot;title&quot;:&quot;XLM-ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/xlm-prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-prophetnet&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa-XL&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta-xl&quot;},{&quot;title&quot;:&quot;XLM-V&quot;,&quot;id&quot;:&quot;model_doc/xlm-v&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-v&quot;},{&quot;title&quot;:&quot;XLNet&quot;,&quot;id&quot;:&quot;model_doc/xlnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlnet&quot;},{&quot;title&quot;:&quot;YOSO&quot;,&quot;id&quot;:&quot;model_doc/yoso&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yoso&quot;}]},{&quot;title&quot;:&quot;Vision models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;BEiT&quot;,&quot;id&quot;:&quot;model_doc/beit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/beit&quot;},{&quot;title&quot;:&quot;BiT&quot;,&quot;id&quot;:&quot;model_doc/bit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bit&quot;},{&quot;title&quot;:&quot;Conditional DETR&quot;,&quot;id&quot;:&quot;model_doc/conditional_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/conditional_detr&quot;},{&quot;title&quot;:&quot;ConvNeXT&quot;,&quot;id&quot;:&quot;model_doc/convnext&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnext&quot;},{&quot;title&quot;:&quot;ConvNeXTV2&quot;,&quot;id&quot;:&quot;model_doc/convnextv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnextv2&quot;},{&quot;title&quot;:&quot;CvT&quot;,&quot;id&quot;:&quot;model_doc/cvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cvt&quot;},{&quot;title&quot;:&quot;Deformable DETR&quot;,&quot;id&quot;:&quot;model_doc/deformable_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deformable_detr&quot;},{&quot;title&quot;:&quot;DeiT&quot;,&quot;id&quot;:&quot;model_doc/deit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deit&quot;},{&quot;title&quot;:&quot;DETA&quot;,&quot;id&quot;:&quot;model_doc/deta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deta&quot;},{&quot;title&quot;:&quot;DETR&quot;,&quot;id&quot;:&quot;model_doc/detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/detr&quot;},{&quot;title&quot;:&quot;DiNAT&quot;,&quot;id&quot;:&quot;model_doc/dinat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinat&quot;},{&quot;title&quot;:&quot;DINO V2&quot;,&quot;id&quot;:&quot;model_doc/dinov2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinov2&quot;},{&quot;title&quot;:&quot;DiT&quot;,&quot;id&quot;:&quot;model_doc/dit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dit&quot;},{&quot;title&quot;:&quot;DPT&quot;,&quot;id&quot;:&quot;model_doc/dpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpt&quot;},{&quot;title&quot;:&quot;EfficientFormer&quot;,&quot;id&quot;:&quot;model_doc/efficientformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientformer&quot;},{&quot;title&quot;:&quot;EfficientNet&quot;,&quot;id&quot;:&quot;model_doc/efficientnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientnet&quot;},{&quot;title&quot;:&quot;FocalNet&quot;,&quot;id&quot;:&quot;model_doc/focalnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/focalnet&quot;},{&quot;title&quot;:&quot;GLPN&quot;,&quot;id&quot;:&quot;model_doc/glpn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/glpn&quot;},{&quot;title&quot;:&quot;ImageGPT&quot;,&quot;id&quot;:&quot;model_doc/imagegpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/imagegpt&quot;},{&quot;title&quot;:&quot;LeViT&quot;,&quot;id&quot;:&quot;model_doc/levit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/levit&quot;},{&quot;title&quot;:&quot;Mask2Former&quot;,&quot;id&quot;:&quot;model_doc/mask2former&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mask2former&quot;},{&quot;title&quot;:&quot;MaskFormer&quot;,&quot;id&quot;:&quot;model_doc/maskformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/maskformer&quot;},{&quot;title&quot;:&quot;MobileNetV1&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v1&quot;},{&quot;title&quot;:&quot;MobileNetV2&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v2&quot;},{&quot;title&quot;:&quot;MobileViT&quot;,&quot;id&quot;:&quot;model_doc/mobilevit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevit&quot;},{&quot;title&quot;:&quot;MobileViTV2&quot;,&quot;id&quot;:&quot;model_doc/mobilevitv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevitv2&quot;},{&quot;title&quot;:&quot;NAT&quot;,&quot;id&quot;:&quot;model_doc/nat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nat&quot;},{&quot;title&quot;:&quot;PoolFormer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/poolformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/poolformer&quot;},{&quot;title&quot;:&quot;Pyramid Vision Transformer (PVT)&quot;,&quot;id&quot;:&quot;model_doc/pvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pvt&quot;},{&quot;title&quot;:&quot;RegNet&quot;,&quot;id&quot;:&quot;model_doc/regnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/regnet&quot;},{&quot;title&quot;:&quot;ResNet&quot;,&quot;id&quot;:&quot;model_doc/resnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/resnet&quot;},{&quot;title&quot;:&quot;SegFormer&quot;,&quot;id&quot;:&quot;model_doc/segformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/segformer&quot;},{&quot;title&quot;:&quot;SwiftFormer&quot;,&quot;id&quot;:&quot;model_doc/swiftformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swiftformer&quot;},{&quot;title&quot;:&quot;Swin Transformer&quot;,&quot;id&quot;:&quot;model_doc/swin&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin&quot;},{&quot;title&quot;:&quot;Swin Transformer V2&quot;,&quot;id&quot;:&quot;model_doc/swinv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swinv2&quot;},{&quot;title&quot;:&quot;Swin2SR&quot;,&quot;id&quot;:&quot;model_doc/swin2sr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin2sr&quot;},{&quot;title&quot;:&quot;Table Transformer&quot;,&quot;id&quot;:&quot;model_doc/table-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/table-transformer&quot;},{&quot;title&quot;:&quot;TimeSformer&quot;,&quot;id&quot;:&quot;model_doc/timesformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/timesformer&quot;},{&quot;title&quot;:&quot;UperNet&quot;,&quot;id&quot;:&quot;model_doc/upernet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/upernet&quot;},{&quot;title&quot;:&quot;VAN&quot;,&quot;id&quot;:&quot;model_doc/van&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/van&quot;},{&quot;title&quot;:&quot;VideoMAE&quot;,&quot;id&quot;:&quot;model_doc/videomae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/videomae&quot;},{&quot;title&quot;:&quot;Vision Transformer (ViT)&quot;,&quot;id&quot;:&quot;model_doc/vit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit&quot;},{&quot;title&quot;:&quot;ViT Hybrid&quot;,&quot;id&quot;:&quot;model_doc/vit_hybrid&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_hybrid&quot;},{&quot;title&quot;:&quot;ViTDet&quot;,&quot;id&quot;:&quot;model_doc/vitdet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitdet&quot;},{&quot;title&quot;:&quot;ViTMAE&quot;,&quot;id&quot;:&quot;model_doc/vit_mae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_mae&quot;},{&quot;title&quot;:&quot;ViTMatte&quot;,&quot;id&quot;:&quot;model_doc/vitmatte&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitmatte&quot;},{&quot;title&quot;:&quot;ViTMSN&quot;,&quot;id&quot;:&quot;model_doc/vit_msn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_msn&quot;},{&quot;title&quot;:&quot;ViViT&quot;,&quot;id&quot;:&quot;model_doc/vivit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vivit&quot;},{&quot;title&quot;:&quot;YOLOS&quot;,&quot;id&quot;:&quot;model_doc/yolos&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yolos&quot;}]},{&quot;title&quot;:&quot;Audio models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio Spectrogram Transformer&quot;,&quot;id&quot;:&quot;model_doc/audio-spectrogram-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/audio-spectrogram-transformer&quot;},{&quot;title&quot;:&quot;Bark&quot;,&quot;id&quot;:&quot;model_doc/bark&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bark&quot;},{&quot;title&quot;:&quot;CLAP&quot;,&quot;id&quot;:&quot;model_doc/clap&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clap&quot;},{&quot;title&quot;:&quot;EnCodec&quot;,&quot;id&quot;:&quot;model_doc/encodec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encodec&quot;},{&quot;title&quot;:&quot;Hubert&quot;,&quot;id&quot;:&quot;model_doc/hubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/hubert&quot;},{&quot;title&quot;:&quot;MCTCT&quot;,&quot;id&quot;:&quot;model_doc/mctct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mctct&quot;},{&quot;title&quot;:&quot;MMS&quot;,&quot;id&quot;:&quot;model_doc/mms&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mms&quot;},{&quot;title&quot;:&quot;MusicGen&quot;,&quot;id&quot;:&quot;model_doc/musicgen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/musicgen&quot;},{&quot;title&quot;:&quot;Pop2Piano&quot;,&quot;id&quot;:&quot;model_doc/pop2piano&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pop2piano&quot;},{&quot;title&quot;:&quot;SEW&quot;,&quot;id&quot;:&quot;model_doc/sew&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew&quot;},{&quot;title&quot;:&quot;SEW-D&quot;,&quot;id&quot;:&quot;model_doc/sew-d&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew-d&quot;},{&quot;title&quot;:&quot;Speech2Text&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text&quot;},{&quot;title&quot;:&quot;Speech2Text2&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text_2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text_2&quot;},{&quot;title&quot;:&quot;SpeechT5&quot;,&quot;id&quot;:&quot;model_doc/speecht5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speecht5&quot;},{&quot;title&quot;:&quot;UniSpeech&quot;,&quot;id&quot;:&quot;model_doc/unispeech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech&quot;},{&quot;title&quot;:&quot;UniSpeech-SAT&quot;,&quot;id&quot;:&quot;model_doc/unispeech-sat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech-sat&quot;},{&quot;title&quot;:&quot;VITS&quot;,&quot;id&quot;:&quot;model_doc/vits&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vits&quot;},{&quot;title&quot;:&quot;Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2&quot;},{&quot;title&quot;:&quot;Wav2Vec2-Conformer&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2-conformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2-conformer&quot;},{&quot;title&quot;:&quot;Wav2Vec2Phoneme&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2_phoneme&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2_phoneme&quot;},{&quot;title&quot;:&quot;WavLM&quot;,&quot;id&quot;:&quot;model_doc/wavlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wavlm&quot;},{&quot;title&quot;:&quot;Whisper&quot;,&quot;id&quot;:&quot;model_doc/whisper&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/whisper&quot;},{&quot;title&quot;:&quot;XLS-R&quot;,&quot;id&quot;:&quot;model_doc/xls_r&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xls_r&quot;},{&quot;title&quot;:&quot;XLSR-Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/xlsr_wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlsr_wav2vec2&quot;}]},{&quot;title&quot;:&quot;Multimodal models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALIGN&quot;,&quot;id&quot;:&quot;model_doc/align&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/align&quot;},{&quot;title&quot;:&quot;AltCLIP&quot;,&quot;id&quot;:&quot;model_doc/altclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/altclip&quot;},{&quot;title&quot;:&quot;BLIP&quot;,&quot;id&quot;:&quot;model_doc/blip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip&quot;},{&quot;title&quot;:&quot;BLIP-2&quot;,&quot;id&quot;:&quot;model_doc/blip-2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip-2&quot;},{&quot;title&quot;:&quot;BridgeTower&quot;,&quot;id&quot;:&quot;model_doc/bridgetower&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bridgetower&quot;},{&quot;title&quot;:&quot;BROS&quot;,&quot;id&quot;:&quot;model_doc/bros&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bros&quot;},{&quot;title&quot;:&quot;Chinese-CLIP&quot;,&quot;id&quot;:&quot;model_doc/chinese_clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/chinese_clip&quot;},{&quot;title&quot;:&quot;CLIP&quot;,&quot;id&quot;:&quot;model_doc/clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clip&quot;},{&quot;title&quot;:&quot;CLIPSeg&quot;,&quot;id&quot;:&quot;model_doc/clipseg&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clipseg&quot;},{&quot;title&quot;:&quot;Data2Vec&quot;,&quot;id&quot;:&quot;model_doc/data2vec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/data2vec&quot;},{&quot;title&quot;:&quot;DePlot&quot;,&quot;id&quot;:&quot;model_doc/deplot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deplot&quot;},{&quot;title&quot;:&quot;Donut&quot;,&quot;id&quot;:&quot;model_doc/donut&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/donut&quot;},{&quot;title&quot;:&quot;FLAVA&quot;,&quot;id&quot;:&quot;model_doc/flava&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flava&quot;},{&quot;title&quot;:&quot;GIT&quot;,&quot;id&quot;:&quot;model_doc/git&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/git&quot;},{&quot;title&quot;:&quot;GroupViT&quot;,&quot;id&quot;:&quot;model_doc/groupvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/groupvit&quot;},{&quot;title&quot;:&quot;IDEFICS&quot;,&quot;id&quot;:&quot;model_doc/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/idefics&quot;},{&quot;title&quot;:&quot;InstructBLIP&quot;,&quot;id&quot;:&quot;model_doc/instructblip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/instructblip&quot;},{&quot;title&quot;:&quot;LayoutLM&quot;,&quot;id&quot;:&quot;model_doc/layoutlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlm&quot;},{&quot;title&quot;:&quot;LayoutLMV2&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv2&quot;},{&quot;title&quot;:&quot;LayoutLMV3&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv3&quot;},{&quot;title&quot;:&quot;LayoutXLM&quot;,&quot;id&quot;:&quot;model_doc/layoutxlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutxlm&quot;},{&quot;title&quot;:&quot;LiLT&quot;,&quot;id&quot;:&quot;model_doc/lilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lilt&quot;},{&quot;title&quot;:&quot;LXMERT&quot;,&quot;id&quot;:&quot;model_doc/lxmert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lxmert&quot;},{&quot;title&quot;:&quot;MatCha&quot;,&quot;id&quot;:&quot;model_doc/matcha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/matcha&quot;},{&quot;title&quot;:&quot;MGP-STR&quot;,&quot;id&quot;:&quot;model_doc/mgp-str&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mgp-str&quot;},{&quot;title&quot;:&quot;Nougat&quot;,&quot;id&quot;:&quot;model_doc/nougat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nougat&quot;},{&quot;title&quot;:&quot;OneFormer&quot;,&quot;id&quot;:&quot;model_doc/oneformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/oneformer&quot;},{&quot;title&quot;:&quot;OWL-ViT&quot;,&quot;id&quot;:&quot;model_doc/owlvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/owlvit&quot;},{&quot;title&quot;:&quot;Perceiver&quot;,&quot;id&quot;:&quot;model_doc/perceiver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/perceiver&quot;},{&quot;title&quot;:&quot;Pix2Struct&quot;,&quot;id&quot;:&quot;model_doc/pix2struct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pix2struct&quot;},{&quot;title&quot;:&quot;Segment Anything&quot;,&quot;id&quot;:&quot;model_doc/sam&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sam&quot;},{&quot;title&quot;:&quot;Speech Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/speech-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech-encoder-decoder&quot;},{&quot;title&quot;:&quot;TAPAS&quot;,&quot;id&quot;:&quot;model_doc/tapas&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapas&quot;},{&quot;title&quot;:&quot;TrOCR&quot;,&quot;id&quot;:&quot;model_doc/trocr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trocr&quot;},{&quot;title&quot;:&quot;TVLT&quot;,&quot;id&quot;:&quot;model_doc/tvlt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tvlt&quot;},{&quot;title&quot;:&quot;ViLT&quot;,&quot;id&quot;:&quot;model_doc/vilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vilt&quot;},{&quot;title&quot;:&quot;Vision Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/vision-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-encoder-decoder&quot;},{&quot;title&quot;:&quot;Vision Text Dual Encoder&quot;,&quot;id&quot;:&quot;model_doc/vision-text-dual-encoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-text-dual-encoder&quot;},{&quot;title&quot;:&quot;VisualBERT&quot;,&quot;id&quot;:&quot;model_doc/visual_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/visual_bert&quot;},{&quot;title&quot;:&quot;X-CLIP&quot;,&quot;id&quot;:&quot;model_doc/xclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xclip&quot;}]},{&quot;title&quot;:&quot;Reinforcement learning models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Decision Transformer&quot;,&quot;id&quot;:&quot;model_doc/decision_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/decision_transformer&quot;},{&quot;title&quot;:&quot;Trajectory Transformer&quot;,&quot;id&quot;:&quot;model_doc/trajectory_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trajectory_transformer&quot;}]},{&quot;title&quot;:&quot;Time series models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Autoformer&quot;,&quot;id&quot;:&quot;model_doc/autoformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/autoformer&quot;},{&quot;title&quot;:&quot;Informer&quot;,&quot;id&quot;:&quot;model_doc/informer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/informer&quot;},{&quot;title&quot;:&quot;Time Series Transformer&quot;,&quot;id&quot;:&quot;model_doc/time_series_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/time_series_transformer&quot;}]},{&quot;title&quot;:&quot;Graph models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Graphormer&quot;,&quot;id&quot;:&quot;model_doc/graphormer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/graphormer&quot;}]}]},{&quot;title&quot;:&quot;Internal Helpers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Custom Layers and Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/modeling_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/modeling_utils&quot;},{&quot;title&quot;:&quot;Utilities for pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/pipelines_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/pipelines_utils&quot;},{&quot;title&quot;:&quot;Utilities for Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/tokenization_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/tokenization_utils&quot;},{&quot;title&quot;:&quot;Utilities for Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/trainer_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/trainer_utils&quot;},{&quot;title&quot;:&quot;Utilities for Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/generation_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/generation_utils&quot;},{&quot;title&quot;:&quot;Utilities for Image Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/image_processing_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/image_processing_utils&quot;},{&quot;title&quot;:&quot;Utilities for Audio processing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/audio_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/audio_utils&quot;},{&quot;title&quot;:&quot;General Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/file_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/file_utils&quot;},{&quot;title&quot;:&quot;Utilities for Time Series&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/time_series_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/time_series_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;model_doc/poolformer&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;de&quot;,&quot;en&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;ko&quot;,&quot;pt&quot;,&quot;zh&quot;],&quot;library&quot;:&quot;transformers&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v4.34.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v4.34.0&quot;},{&quot;version&quot;:&quot;v4.33.3&quot;},{&quot;version&quot;:&quot;v4.33.2&quot;},{&quot;version&quot;:&quot;v4.33.0&quot;},{&quot;version&quot;:&quot;v4.32.1&quot;},{&quot;version&quot;:&quot;v4.32.0&quot;},{&quot;version&quot;:&quot;v4.31.0&quot;},{&quot;version&quot;:&quot;v4.30.0&quot;},{&quot;version&quot;:&quot;v4.29.1&quot;},{&quot;version&quot;:&quot;v4.29.0&quot;},{&quot;version&quot;:&quot;v4.28.1&quot;},{&quot;version&quot;:&quot;v4.28.0&quot;},{&quot;version&quot;:&quot;v4.27.2&quot;},{&quot;version&quot;:&quot;v4.27.1&quot;},{&quot;version&quot;:&quot;v4.27.0&quot;},{&quot;version&quot;:&quot;v4.26.1&quot;},{&quot;version&quot;:&quot;v4.26.0&quot;},{&quot;version&quot;:&quot;v4.25.1&quot;},{&quot;version&quot;:&quot;v4.24.0&quot;},{&quot;version&quot;:&quot;v4.23.1&quot;},{&quot;version&quot;:&quot;v4.23.0&quot;},{&quot;version&quot;:&quot;v4.22.2&quot;},{&quot;version&quot;:&quot;v4.22.1&quot;},{&quot;version&quot;:&quot;v4.22.0&quot;},{&quot;version&quot;:&quot;v4.21.3&quot;},{&quot;version&quot;:&quot;v4.21.2&quot;},{&quot;version&quot;:&quot;v4.21.1&quot;},{&quot;version&quot;:&quot;v4.21.0&quot;},{&quot;version&quot;:&quot;v4.20.1&quot;},{&quot;version&quot;:&quot;v4.20.0&quot;},{&quot;version&quot;:&quot;v4.19.4&quot;},{&quot;version&quot;:&quot;v4.19.3&quot;},{&quot;version&quot;:&quot;v4.19.2&quot;},{&quot;version&quot;:&quot;v4.19.0&quot;},{&quot;version&quot;:&quot;v4.18.0&quot;},{&quot;version&quot;:&quot;v4.17.0&quot;},{&quot;version&quot;:&quot;v4.16.2&quot;},{&quot;version&quot;:&quot;v4.16.1&quot;},{&quot;version&quot;:&quot;v4.16.0&quot;},{&quot;version&quot;:&quot;v4.15.0&quot;},{&quot;version&quot;:&quot;v4.14.1&quot;},{&quot;version&quot;:&quot;v4.13.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.5&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.4&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.0.0&quot;},{&quot;version&quot;:&quot;doc-builder-html&quot;}],&quot;title&quot;:&quot;PoolFormer&quot;}\" data-target=\"SideMenu\"> <div class=\"z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false\"><div class=\"shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden\"><div class=\"flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6\"><p class=\"text-sm text-gray-400 first-letter:capitalize\">Transformers documentation</p> <div class=\"flex items-center\"><p class=\"font-semibold\">PoolFormer</p> <svg class=\"text-xl false\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></div></div> <button class=\"hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2\"><svg class=\"text-gray-500 group-hover:text-gray-700\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg></button></div> <div class=\"hidden h-32 flex-col justify-between border-r border-b bg-white bg-gradient-to-r p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950\"><div class=\"relative \"><button class=\" \" type=\"button\"><h1 class=\"flex items-center text-lg font-bold leading-tight first-letter:capitalize\"><div class=\"mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none\"></div> Transformers <span><svg class=\"opacity-70 \" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></span></h1> </button> </div> <button class=\"shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500\"><svg class=\"flex-none mr-1.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> <div>Search documentation</div> <span class=\"ml-auto rounded border border-gray-200 bg-gray-100 px-0.5 text-xs dark:border-gray-800 dark:bg-gray-800\"><kbd class=\"font-sans\">⌘K</kbd></span></button> <div class=\"flex items-center\"><select class=\"form-input mr-1 !mt-0 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400\"><option value=\"0\">main</option><option value=\"1\">v4.34.0</option><option value=\"2\">v4.33.3</option><option value=\"3\">v4.32.1</option><option value=\"4\">v4.31.0</option><option value=\"5\">v4.30.0</option><option value=\"6\">v4.29.1</option><option value=\"7\">v4.28.1</option><option value=\"8\">v4.27.2</option><option value=\"9\">v4.26.1</option><option value=\"10\">v4.25.1</option><option value=\"11\">v4.24.0</option><option value=\"12\">v4.23.1</option><option value=\"13\">v4.22.2</option><option value=\"14\">v4.21.3</option><option value=\"15\">v4.20.1</option><option value=\"16\">v4.19.4</option><option value=\"17\">v4.18.0</option><option value=\"18\">v4.17.0</option><option value=\"19\">v4.16.2</option><option value=\"20\">v4.15.0</option><option value=\"21\">v4.14.1</option><option value=\"22\">v4.13.0</option><option value=\"23\">v4.12.5</option><option value=\"24\">v4.11.3</option><option value=\"25\">v4.10.1</option><option value=\"26\">v4.9.2</option><option value=\"27\">v4.8.2</option><option value=\"28\">v4.7.0</option><option value=\"29\">v4.6.0</option><option value=\"30\">v4.5.1</option><option value=\"31\">v4.4.2</option><option value=\"32\">v4.3.3</option><option value=\"33\">v4.2.2</option><option value=\"34\">v4.1.1</option><option value=\"35\">v4.0.1</option><option value=\"36\">v3.5.1</option><option value=\"37\">v3.4.0</option><option value=\"38\">v3.3.1</option><option value=\"39\">v3.2.0</option><option value=\"40\">v3.1.0</option><option value=\"41\">v3.0.2</option><option value=\"42\">v2.11.0</option><option value=\"43\">v2.10.0</option><option value=\"44\">v2.9.1</option><option value=\"45\">v2.8.0</option><option value=\"46\">v2.7.0</option><option value=\"47\">v2.6.0</option><option value=\"48\">v2.5.1</option><option value=\"49\">v2.4.1</option><option value=\"50\">v2.3.0</option><option value=\"51\">v2.2.2</option><option value=\"52\">v2.1.1</option><option value=\"53\">v2.0.0</option><option value=\"54\">v1.2.0</option><option value=\"55\">v1.1.0</option><option value=\"56\">v1.0.0</option><option value=\"57\">doc-builder-html</option></select> <select class=\"form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border\"><option value=\"de\">DE</option><option value=\"en\">EN</option><option value=\"es\">ES</option><option value=\"fr\">FR</option><option value=\"it\">IT</option><option value=\"ko\">KO</option><option value=\"pt\">PT</option><option value=\"zh\">ZH</option></select> <div class=\"relative inline-block\"><button class=\"rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 \" type=\"button\"><svg class=\"mr-1.5 text-yellow-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\" fill=\"currentColor\"><path d=\"M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z\"></path></svg>  </button> </div> <a href=\"https://github.com/huggingface/transformers\" class=\"group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300\"><svg class=\"inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1.03em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 250\"><path d=\"M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z\" fill=\"currentColor\"></path></svg> 112,792</a></div></div> <nav class=\"top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pt-3 pb-16 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]\"> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Get started</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/index\">🤗 Transformers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/quicktour\">Quick tour </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/installation\">Installation </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Tutorials</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_tutorial\">Run inference with pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/autoclass_tutorial\">Write portable code with AutoClass </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/preprocessing\">Preprocess data </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/training\">Fine-tune a pretrained model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/run_scripts\">Train with a script </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/accelerate\">Set up distributed training with 🤗 Accelerate </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/peft\">Load and train adapters with 🤗 PEFT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_sharing\">Share your model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/transformers_agents\">Agents </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/llm_tutorial\">Generation with LLMs </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Task Guides</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Natural Language Processing</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Computer Vision</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Generation</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Prompting</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Developer guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/fast_tokenizers\">Use fast tokenizers from 🤗 Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/multilingual\">Run inference with multilingual models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/create_a_model\">Use model-specific APIs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_models\">Share a custom model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/chat_templating\">Templates for chat models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/sagemaker\">Run training on Amazon SageMaker </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/serialization\">Export to ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tflite\">Export to TFLite </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/torchscript\">Export to TorchScript </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/benchmarks\">Benchmarks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/notebooks\">Notebooks with examples </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/community\">Community resources </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_tools\">Custom Tools and Prompts </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/troubleshooting\">Troubleshoot </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Performance and scalability</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/performance\">Overview </a><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Efficient training techniques</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_one\">Methods and tools for efficient training on a single GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_many\">Multiple GPUs and parallelism </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu\">Efficient training on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu_many\">Distributed CPU training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu\">Training on TPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu_tf\">Training on TPU with TensorFlow </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_special\">Training on Specialized Hardware </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_hardware\">Custom hardware for training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/hpo_train\">Hyperparameter Search using Trainer API </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Optimizing inference</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_cpu\">Inference on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_one\">Inference on one GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_many\">Inference on many GPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_special\">Inference on Specialized Hardware </a> </div><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/big_models\">Instantiating a big model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/debugging\">Troubleshooting </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tf_xla\">XLA Integration for TensorFlow Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perf_torch_compile\">Optimize inference using `torch.compile()` </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Contribute</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/contributing\">How to contribute to transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_model\">How to add a model to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_tensorflow_model\">How to convert a 🤗 Transformers model to TensorFlow? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_pipeline\">How to add a pipeline to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/testing\">Testing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pr_checks\">Checks on a Pull Request </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Conceptual guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/philosophy\">Philosophy </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/glossary\">Glossary </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/task_summary\">What 🤗 Transformers can do </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tasks_explained\">How 🤗 Transformers solve tasks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_summary\">The Transformer model family </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tokenizer_summary\">Summary of the tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/attention\">Attention mechanisms </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pad_truncation\">Padding and truncation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/bertology\">BERTology </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perplexity\">Perplexity of fixed-length models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_webserver\">Pipelines for webserver inference </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_memory_anatomy\">Model training anatomy </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>API</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Main Classes</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/agent\">Agents and Tools </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/model_doc/auto\">Auto Classes </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/callback\">Callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/configuration\">Configuration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/data_collator\">Data Collator </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/keras_callbacks\">Keras callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/logging\">Logging </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/model\">Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/text_generation\">Text Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/onnx\">ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules\">Optimization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/output\">Model outputs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/pipelines\">Pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/processors\">Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/quantization\">Quantization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer\">Tokenizer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/trainer\">Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/deepspeed\">DeepSpeed Integration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/feature_extractor\">Feature Extractor </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/image_processor\">Image Processor </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Models</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Text models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Vision models</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/beit\">BEiT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bit\">BiT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/conditional_detr\">Conditional DETR </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/convnext\">ConvNeXT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/convnextv2\">ConvNeXTV2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/cvt\">CvT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/deformable_detr\">Deformable DETR </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/deit\">DeiT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/deta\">DETA </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/detr\">DETR </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/dinat\">DiNAT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/dinov2\">DINO V2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/dit\">DiT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/dpt\">DPT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/efficientformer\">EfficientFormer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/efficientnet\">EfficientNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/focalnet\">FocalNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/glpn\">GLPN </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/imagegpt\">ImageGPT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/levit\">LeViT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mask2former\">Mask2Former </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/maskformer\">MaskFormer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mobilenet_v1\">MobileNetV1 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mobilenet_v2\">MobileNetV2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mobilevit\">MobileViT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mobilevitv2\">MobileViTV2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/nat\">NAT </a><a data-sveltekit-reload=\"\" class=\"rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pr-2 pl-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer\">PoolFormer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/pvt\">Pyramid Vision Transformer (PVT) </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/regnet\">RegNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/resnet\">ResNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/segformer\">SegFormer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/swiftformer\">SwiftFormer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/swin\">Swin Transformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/swinv2\">Swin Transformer V2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/swin2sr\">Swin2SR </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/table-transformer\">Table Transformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/timesformer\">TimeSformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/upernet\">UperNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/van\">VAN </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/videomae\">VideoMAE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vit\">Vision Transformer (ViT) </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vit_hybrid\">ViT Hybrid </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vitdet\">ViTDet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vit_mae\">ViTMAE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vitmatte\">ViTMatte </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vit_msn\">ViTMSN </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/vivit\">ViViT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/yolos\">YOLOS </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Reinforcement learning models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Time series models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Graph models</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Internal Helpers</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/modeling_utils\">Custom Layers and Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/pipelines_utils\">Utilities for pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/tokenization_utils\">Utilities for Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/trainer_utils\">Utilities for Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/generation_utils\">Utilities for Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/image_processing_utils\">Utilities for Image Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/audio_utils\">Utilities for Audio processing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/file_utils\">General Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/time_series_utils\">Utilities for Time Series </a> </div> </div></nav></div></div></div>\\n\\t\\t<div class=\"z-1 min-w-0 flex-1\">\\n\\t\\t\\t<div class=\"px-6 pt-6 md:px-12 md:pt-16 md:pb-16\"><div class=\"max-w-4xl mx-auto mb-10\"><div class=\"relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 py-5 px-4 ring-1 ring-orange-100/70 md:px-6 md:py-8\"><img alt=\"Hugging Face\\'s logo\" class=\"absolute -right-6 -bottom-6 w-28 -rotate-45 md:hidden\" src=\"/front/assets/huggingface_logo-noborder.svg\">\\n\\t\\t<div class=\"mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0\">Join the Hugging Face community</div>\\n\\t\\t<p class=\"mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8\">and get access to the augmented documentation experience\\n\\t\\t</p>\\n\\t\\t<div class=\"mb-8 hidden space-y-4 md:block xl:flex xl:space-y-0 xl:space-x-6\"><div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100\"><svg class=\"text-indigo-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Collaborate on models, datasets and Spaces\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"text-xl text-yellow-400\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M11 15H6l7-14v8h5l-7 14v-8z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Faster examples with accelerated inference\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5\"><svg class=\"text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Switch between documentation themes\\n\\t\\t\\t\\t</div></div></div>\\n\\t\\t<div class=\"flex items-center space-x-2.5\"><a href=\"/join\"><button class=\"rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 py-1.5 px-5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner\">Sign Up</button></a>\\n\\t\\t\\t<p class=\"text-gray-500 dark:text-gray-300\">to get started</p></div></div></div>\\n\\t\\t\\t\\t<div class=\"prose-doc prose relative mx-auto max-w-4xl break-words\"> <p></p> <h1 class=\"relative group\"><a id=\"poolformer\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#poolformer\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-xplu14\">PoolFormer</span></h1> <h2 class=\"relative group\"><a id=\"overview\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#overview\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1jsw1pg\">Overview</span></h2> <p data-svelte-h=\"svelte-uoy3hb\">The PoolFormer model was proposed in <a href=\"https://arxiv.org/abs/2111.11418\" rel=\"nofollow\">MetaFormer is Actually What You Need for Vision</a>  by Sea AI Labs. Instead of designing complicated token mixer to achieve SOTA performance, the target of this work is to demonstrate the competence of transformer models largely stem from the general architecture MetaFormer.</p> <p data-svelte-h=\"svelte-vfdo9a\">The abstract from the paper is the following:</p> <p data-svelte-h=\"svelte-11momc2\"><em>Transformers have shown great potential in computer vision tasks. A common belief is their attention-based token mixer module contributes most to their competence. However, recent works show the attention-based module in transformers can be replaced by spatial MLPs and the resulted models still perform quite well. Based on this observation, we hypothesize that the general architecture of the transformers, instead of the specific token mixer module, is more essential to the model’s performance. To verify this, we deliberately replace the attention module in transformers with an embarrassingly simple spatial pooling operator to conduct only the most basic token mixing. Surprisingly, we observe that the derived model, termed as PoolFormer, achieves competitive performance on multiple computer vision tasks. For example, on ImageNet-1K, PoolFormer achieves 82.1% top-1 accuracy, surpassing well-tuned vision transformer/MLP-like baselines DeiT-B/ResMLP-B24 by 0.3%/1.1% accuracy with 35%/52% fewer parameters and 48%/60% fewer MACs. The effectiveness of PoolFormer verifies our hypothesis and urges us to initiate the concept of “MetaFormer”, a general architecture abstracted from transformers without specifying the token mixer. Based on the extensive experiments, we argue that MetaFormer is the key player in achieving superior results for recent transformer and MLP-like models on vision tasks. This work calls for more future research dedicated to improving MetaFormer instead of focusing on the token mixer modules. Additionally, our proposed PoolFormer could serve as a starting baseline for future MetaFormer architecture design.</em></p> <p data-svelte-h=\"svelte-dr24j9\">The figure below illustrates the architecture of PoolFormer. Taken from the <a href=\"https://arxiv.org/abs/2111.11418\" rel=\"nofollow\">original paper</a>.</p> <img width=\"600\" src=\"https://user-images.githubusercontent.com/15921929/142746124-1ab7635d-2536-4a0e-ad43-b4fe2c5a525d.png\"> <p data-svelte-h=\"svelte-axv494\">Tips:</p> <ul data-svelte-h=\"svelte-ui3wak\"><li>PoolFormer has a hierarchical architecture, where instead of Attention, a simple Average Pooling layer is present. All checkpoints of the model can be found on the <a href=\"https://huggingface.co/models?other=poolformer\" rel=\"nofollow\">hub</a>.</li> <li>One can use <a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerImageProcessor\">PoolFormerImageProcessor</a> to prepare images for the model.</li> <li>As most models, PoolFormer comes in different sizes, the details of which can be found in the table below.</li></ul> <table data-svelte-h=\"svelte-ohzfem\"><thead><tr><th align=\"center\"><strong>Model variant</strong></th> <th><strong>Depths</strong></th> <th><strong>Hidden sizes</strong></th> <th align=\"center\"><strong>Params (M)</strong></th> <th align=\"center\"><strong>ImageNet-1k Top 1</strong></th></tr></thead> <tbody><tr><td align=\"center\">s12</td> <td>[2, 2, 6, 2]</td> <td>[64, 128, 320, 512]</td> <td align=\"center\">12</td> <td align=\"center\">77.2</td></tr> <tr><td align=\"center\">s24</td> <td>[4, 4, 12, 4]</td> <td>[64, 128, 320, 512]</td> <td align=\"center\">21</td> <td align=\"center\">80.3</td></tr> <tr><td align=\"center\">s36</td> <td>[6, 6, 18, 6]</td> <td>[64, 128, 320, 512]</td> <td align=\"center\">31</td> <td align=\"center\">81.4</td></tr> <tr><td align=\"center\">m36</td> <td>[6, 6, 18, 6]</td> <td>[96, 192, 384, 768]</td> <td align=\"center\">56</td> <td align=\"center\">82.1</td></tr> <tr><td align=\"center\">m48</td> <td>[8, 8, 24, 8]</td> <td>[96, 192, 384, 768]</td> <td align=\"center\">73</td> <td align=\"center\">82.5</td></tr></tbody></table> <p data-svelte-h=\"svelte-1vh5cee\">This model was contributed by <a href=\"https://huggingface.co/heytanay\" rel=\"nofollow\">heytanay</a>. The original code can be found <a href=\"https://github.com/sail-sg/poolformer\" rel=\"nofollow\">here</a>.</p> <h2 class=\"relative group\"><a id=\"resources\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#resources\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-w4zzv6\">Resources</span></h2> <p data-svelte-h=\"svelte-1somjfw\">A list of official Hugging Face and community (indicated by 🌎) resources to help you get started with PoolFormer.</p> <div class=\"inline-flex items-center border pr-1 rounded-xl \"><svg class=\"mr-1 tag-ico tag-ico-blue\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><polygon points=\"4 20 4 22 8.586 22 2 28.586 3.414 30 10 23.414 10 28 12 28 12 20 4 20\"></polygon><path d=\"M19,14a3,3,0,1,0-3-3A3,3,0,0,0,19,14Zm0-4a1,1,0,1,1-1,1A1,1,0,0,1,19,10Z\"></path><path d=\"M26,4H6A2,2,0,0,0,4,6V16H6V6H26V21.17l-3.59-3.59a2,2,0,0,0-2.82,0L18,19.17,11.8308,13l-1.4151,1.4155L14,18l2.59,2.59a2,2,0,0,0,2.82,0L21,19l5,5v2H16v2H26a2,2,0,0,0,2-2V6A2,2,0,0,0,26,4Z\"></path></svg> <span>Image Classification</span></div> <ul data-svelte-h=\"svelte-1amqfzc\"><li><a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerForImageClassification\">PoolFormerForImageClassification</a> is supported by this <a href=\"https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification\" rel=\"nofollow\">example script</a> and <a href=\"https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb\" rel=\"nofollow\">notebook</a>.</li> <li>See also: <a href=\"../tasks/image_classification\">Image classification task guide</a></li></ul> <p data-svelte-h=\"svelte-1xesile\">If you’re interested in submitting a resource to be included here, please feel free to open a Pull Request and we’ll review it! The resource should ideally demonstrate something new instead of duplicating an existing resource.</p> <h2 class=\"relative group\"><a id=\"transformers.PoolFormerConfig\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-8ub9d2\">PoolFormerConfig</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerConfig\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">PoolFormerConfig</span></span></h3> <a id=\"transformers.PoolFormerConfig\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerConfig\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/configuration_poolformer.py#L34\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_channels<span class=\"opacity-60\"> = 3</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">patch_size<span class=\"opacity-60\"> = 16</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">stride<span class=\"opacity-60\"> = 16</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">pool_size<span class=\"opacity-60\"> = 3</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mlp_ratio<span class=\"opacity-60\"> = 4.0</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">depths<span class=\"opacity-60\"> = [2, 2, 6, 2]</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">hidden_sizes<span class=\"opacity-60\"> = [64, 128, 320, 512]</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">patch_sizes<span class=\"opacity-60\"> = [7, 3, 3, 3]</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">strides<span class=\"opacity-60\"> = [4, 2, 2, 2]</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">padding<span class=\"opacity-60\"> = [2, 1, 1, 1]</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_encoder_blocks<span class=\"opacity-60\"> = 4</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">drop_path_rate<span class=\"opacity-60\"> = 0.0</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">hidden_act<span class=\"opacity-60\"> = \\'gelu\\'</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">use_layer_scale<span class=\"opacity-60\"> = True</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">layer_scale_init_value<span class=\"opacity-60\"> = 1e-05</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">initializer_range<span class=\"opacity-60\"> = 0.02</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">**kwargs<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 16 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.num_channels\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.num_channels\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>num_channels</strong> (<code>int</code>, <em>optional</em>, defaults to 3) —\\nThe number of channels in the input image.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.patch_size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.patch_size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>patch_size</strong> (<code>int</code>, <em>optional</em>, defaults to 16) —\\nThe size of the input patch.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.stride\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.stride\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>stride</strong> (<code>int</code>, <em>optional</em>, defaults to 16) —\\nThe stride of the input patch.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.pool_size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.pool_size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>pool_size</strong> (<code>int</code>, <em>optional</em>, defaults to 3) —\\nThe size of the pooling window.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.mlp_ratio\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.mlp_ratio\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>mlp_ratio</strong> (<code>float</code>, <em>optional</em>, defaults to 4.0) —\\nThe ratio of the number of channels in the output of the MLP to the number of channels in the input.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.depths\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.depths\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>depths</strong> (<code>list</code>, <em>optional</em>, defaults to <code>[2, 2, 6, 2]</code>) —\\nThe depth of each encoder block.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.hidden_sizes\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.hidden_sizes\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>hidden_sizes</strong> (<code>list</code>, <em>optional</em>, defaults to <code>[64, 128, 320, 512]</code>) —\\nThe hidden sizes of each encoder block.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.patch_sizes\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.patch_sizes\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>patch_sizes</strong> (<code>list</code>, <em>optional</em>, defaults to <code>[7, 3, 3, 3]</code>) —\\nThe size of the input patch for each encoder block.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.strides\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.strides\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>strides</strong> (<code>list</code>, <em>optional</em>, defaults to <code>[4, 2, 2, 2]</code>) —\\nThe stride of the input patch for each encoder block.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.padding\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.padding\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>padding</strong> (<code>list</code>, <em>optional</em>, defaults to <code>[2, 1, 1, 1]</code>) —\\nThe padding of the input patch for each encoder block.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.num_encoder_blocks\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.num_encoder_blocks\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>num_encoder_blocks</strong> (<code>int</code>, <em>optional</em>, defaults to 4) —\\nThe number of encoder blocks.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.drop_path_rate\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.drop_path_rate\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>drop_path_rate</strong> (<code>float</code>, <em>optional</em>, defaults to 0.0) —\\nThe dropout rate for the dropout layers.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.hidden_act\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.hidden_act\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>hidden_act</strong> (<code>str</code>, <em>optional</em>, defaults to <code>\"gelu\"</code>) —\\nThe activation function for the hidden layers.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.use_layer_scale\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.use_layer_scale\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>use_layer_scale</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether to use layer scale.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.layer_scale_init_value\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.layer_scale_init_value\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>layer_scale_init_value</strong> (<code>float</code>, <em>optional</em>, defaults to 1e-5) —\\nThe initial value for the layer scale.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerConfig.initializer_range\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.initializer_range\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>initializer_range</strong> (<code>float</code>, <em>optional</em>, defaults to 0.02) —\\nThe initializer range for the weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-1xq1rq9\">This is the configuration class to store the configuration of <a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerModel\">PoolFormerModel</a>. It is used to instantiate a\\nPoolFormer model according to the specified arguments, defining the model architecture. Instantiating a\\nconfiguration with the defaults will yield a similar configuration to that of the PoolFormer\\n<a href=\"https://huggingface.co/sail/poolformer_s12\" rel=\"nofollow\">sail/poolformer_s12</a> architecture.</p> <p data-svelte-h=\"svelte-10kqkkl\">Configuration objects inherit from <a href=\"/docs/transformers/v4.34.0/en/main_classes/configuration#transformers.PretrainedConfig\">PretrainedConfig</a> and can be used to control the model outputs. Read the\\ndocumentation from <a href=\"/docs/transformers/v4.34.0/en/main_classes/configuration#transformers.PretrainedConfig\">PretrainedConfig</a> for more information.</p> <div class=\"relative group rounded-md\"><a id=\"transformers.PoolFormerConfig.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerConfig.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-11lpom8\">Example:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> PoolFormerConfig, PoolFormerModel\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># Initializing a PoolFormer sail/poolformer_s12 style configuration</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>configuration = PoolFormerConfig()\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># Initializing a model (with random weights) from the sail/poolformer_s12 style configuration</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = PoolFormerModel(configuration)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># Accessing the model configuration</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>configuration = model.config</pre></div></div></div> <h2 class=\"relative group\"><a id=\"transformers.PoolFormerFeatureExtractor\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerFeatureExtractor\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-st2acq\">PoolFormerFeatureExtractor</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerFeatureExtractor\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">PoolFormerFeatureExtractor</span></span></h3> <a id=\"transformers.PoolFormerFeatureExtractor\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerFeatureExtractor\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/feature_extraction_poolformer.py#L26\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">*args<span class=\"opacity-60\"></span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">**kwargs<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \">    </div></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerFeatureExtractor.__call__\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>__call__</span></h4> <a id=\"transformers.PoolFormerFeatureExtractor.__call__\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerFeatureExtractor.__call__\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/image_processing_utils.py#L544\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">images<span class=\"opacity-60\"></span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">**kwargs<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \">    </div></div> <p data-svelte-h=\"svelte-khengj\">Preprocess an image or a batch of images.</p></div></div> <h2 class=\"relative group\"><a id=\"transformers.PoolFormerImageProcessor\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1k0thbp\">PoolFormerImageProcessor</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerImageProcessor\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">PoolFormerImageProcessor</span></span></h3> <a id=\"transformers.PoolFormerImageProcessor\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerImageProcessor\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/image_processing_poolformer.py#L49\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_resize<span class=\"opacity-60\">: bool = True</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">size<span class=\"opacity-60\">: typing.Dict[str, int] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">crop_pct<span class=\"opacity-60\">: int = 0.9</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">resample<span class=\"opacity-60\">: Resampling = &lt;Resampling.BICUBIC: 3&gt;</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_center_crop<span class=\"opacity-60\">: bool = True</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">crop_size<span class=\"opacity-60\">: typing.Dict[str, int] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">rescale_factor<span class=\"opacity-60\">: typing.Union[int, float] = 0.00392156862745098</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_rescale<span class=\"opacity-60\">: bool = True</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_normalize<span class=\"opacity-60\">: bool = True</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">image_mean<span class=\"opacity-60\">: typing.Union[float, typing.List[float], NoneType] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">image_std<span class=\"opacity-60\">: typing.Union[float, typing.List[float], NoneType] = None</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">**kwargs<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 11 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.do_resize\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.do_resize\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_resize</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether to resize the image’s (height, width) dimensions to the specified <code>size</code>. Can be overridden by\\n<code>do_resize</code> in the <code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>size</strong> (<code>Dict[str, int]</code> <em>optional</em>, defaults to <code>{\"shortest_edge\" -- 224}</code>):\\nSize of the image after resizing. Can be overridden by <code>size</code> in the <code>preprocess</code> method. If crop_pct is\\nunset:<p></p>\\n<ul>\\n<li>size is <code>{\"height\": h, \"width\": w}</code>: the image is resized to <code>(h, w)</code>.</li>\\n<li>size is <code>{\"shortest_edge\": s}</code>: the shortest edge of the image is resized to s whilst maintaining the\\naspect ratio.</li>\\n</ul>\\n<p>If crop_pct is set:</p>\\n<ul>\\n<li>size is <code>{\"height\": h, \"width\": w}</code>: the image is resized to <code>(int(floor(h/crop_pct)), int(floor(w/crop_pct)))</code></li>\\n<li>size is <code>{\"height\": c, \"width\": c}</code>: the shortest edge of the image is resized to <code>int(floor(c/crop_pct)</code>\\nwhilst maintaining the aspect ratio.</li>\\n<li>size is <code>{\"shortest_edge\": c}</code>: the shortest edge of the image is resized to <code>int(floor(c/crop_pct)</code>\\nwhilst maintaining the aspect ratio.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.crop_pct\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.crop_pct\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>crop_pct</strong> (<code>float</code>, <em>optional</em>, defaults to <code>0.9</code>) —\\nPercentage of the image to crop from the center. Can be overridden by <code>crop_pct</code> in the <code>preprocess</code>\\nmethod.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.resample\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.resample\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>resample</strong> (<code>PILImageResampling</code>, <em>optional</em>, defaults to <code>PILImageResampling.BICUBIC</code>) —\\nResampling filter to use if resizing the image. Can be overridden by <code>resample</code> in the <code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.do_center_crop\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.do_center_crop\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_center_crop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether to center crop the image. If the input size is smaller than <code>crop_size</code> along any edge, the image\\nis padded with 0’s and then center cropped. Can be overridden by <code>do_center_crop</code> in the <code>preprocess</code>\\nmethod.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.crop_size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.crop_size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>crop_size</strong> (<code>Dict[str, int]</code>, <em>optional</em>, defaults to <code>{\"height\" -- 224, \"width\": 224}</code>):\\nSize of the image after applying center crop. Only has an effect if <code>do_center_crop</code> is set to <code>True</code>. Can\\nbe overridden by the <code>crop_size</code> parameter in the <code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.do_rescale\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.do_rescale\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_rescale</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether to rescale the image by the specified scale <code>rescale_factor</code>. Can be overridden by the <code>do_rescale</code>\\nparameter in the <code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.rescale_factor\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.rescale_factor\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>rescale_factor</strong> (<code>int</code> or <code>float</code>, <em>optional</em>, defaults to <code>1/255</code>) —\\nScale factor to use if rescaling the image. Can be overridden by the <code>rescale_factor</code> parameter in the\\n<code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.do_normalize\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.do_normalize\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_normalize</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nControls whether to normalize the image. Can be overridden by the <code>do_normalize</code> parameter in the\\n<code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.image_mean\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.image_mean\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>image_mean</strong> (<code>float</code> or <code>List[float]</code>, <em>optional</em>, defaults to <code>IMAGENET_STANDARD_MEAN</code>) —\\nMean to use if normalizing the image. This is a float or list of floats the length of the number of\\nchannels in the image. Can be overridden by the <code>image_mean</code> parameter in the <code>preprocess</code> method.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.image_std\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.image_std\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>image_std</strong> (<code>float</code> or <code>List[float]</code>, <em>optional</em>, defaults to <code>IMAGENET_STANDARD_STD</code>) —\\nStandard deviation to use if normalizing the image. This is a float or list of floats the length of the\\nnumber of channels in the image. Can be overridden by the <code>image_std</code> parameter in the <code>preprocess</code> method.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-dhy8rj\">Constructs a PoolFormer image processor.</p> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerImageProcessor.preprocess\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>preprocess</span></h4> <a id=\"transformers.PoolFormerImageProcessor.preprocess\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerImageProcessor.preprocess\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/image_processing_poolformer.py#L211\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">images<span class=\"opacity-60\">: typing.Union[ForwardRef(\\'PIL.Image.Image\\'), numpy.ndarray, ForwardRef(\\'torch.Tensor\\'), typing.List[ForwardRef(\\'PIL.Image.Image\\')], typing.List[numpy.ndarray], typing.List[ForwardRef(\\'torch.Tensor\\')]]</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_resize<span class=\"opacity-60\">: bool = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">size<span class=\"opacity-60\">: typing.Dict[str, int] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">crop_pct<span class=\"opacity-60\">: int = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">resample<span class=\"opacity-60\">: Resampling = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_center_crop<span class=\"opacity-60\">: bool = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">crop_size<span class=\"opacity-60\">: typing.Dict[str, int] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_rescale<span class=\"opacity-60\">: bool = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">rescale_factor<span class=\"opacity-60\">: float = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">do_normalize<span class=\"opacity-60\">: bool = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">image_mean<span class=\"opacity-60\">: typing.Union[float, typing.List[float], NoneType] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">image_std<span class=\"opacity-60\">: typing.Union[float, typing.List[float], NoneType] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_tensors<span class=\"opacity-60\">: typing.Union[str, transformers.utils.generic.TensorType, NoneType] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">data_format<span class=\"opacity-60\">: ChannelDimension = &lt;ChannelDimension.FIRST: \\'channels_first\\'&gt;</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">input_data_format<span class=\"opacity-60\">: typing.Union[str, transformers.image_utils.ChannelDimension, NoneType] = None</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">**kwargs<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 15 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.images\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.images\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>images</strong> (<code>ImageInput</code>) —\\nImage to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If\\npassing in images with pixel values between 0 and 1, set <code>do_rescale=False</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.do_resize\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.do_resize\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_resize</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>self.do_resize</code>) —\\nWhether to resize the image.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>size</strong> (<code>Dict[str, int]</code>, <em>optional</em>, defaults to <code>self.size</code>) —\\nSize of the image after applying resize.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.crop_pct\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.crop_pct\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>crop_pct</strong> (<code>float</code>, <em>optional</em>, defaults to <code>self.crop_pct</code>) —\\nPercentage of the image to crop. Only has an effect if <code>do_resize</code> is set to <code>True</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.resample\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.resample\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>resample</strong> (<code>int</code>, <em>optional</em>, defaults to <code>self.resample</code>) —\\nResampling filter to use if resizing the image. This can be one of the enum <code>PILImageResampling</code>, Only\\nhas an effect if <code>do_resize</code> is set to <code>True</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.do_center_crop\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.do_center_crop\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_center_crop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>self.do_center_crop</code>) —\\nWhether to center crop the image.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.crop_size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.crop_size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>crop_size</strong> (<code>Dict[str, int]</code>, <em>optional</em>, defaults to <code>self.crop_size</code>) —\\nSize of the image after applying center crop.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.do_rescale\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.do_rescale\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_rescale</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>self.do_rescale</code>) —\\nWhether to rescale the image values between [0 - 1].</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.rescale_factor\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.rescale_factor\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>rescale_factor</strong> (<code>float</code>, <em>optional</em>, defaults to <code>self.rescale_factor</code>) —\\nRescale factor to rescale the image by if <code>do_rescale</code> is set to <code>True</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.do_normalize\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.do_normalize\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>do_normalize</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>self.do_normalize</code>) —\\nWhether to normalize the image.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.image_mean\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.image_mean\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>image_mean</strong> (<code>float</code> or <code>List[float]</code>, <em>optional</em>, defaults to <code>self.image_mean</code>) —\\nImage mean.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.image_std\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.image_std\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>image_std</strong> (<code>float</code> or <code>List[float]</code>, <em>optional</em>, defaults to <code>self.image_std</code>) —\\nImage standard deviation.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.return_tensors\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.return_tensors\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>return_tensors</strong> (<code>str</code> or <code>TensorType</code>, <em>optional</em>) —\\nThe type of tensors to return. Can be one of:<ul>\\n<li>Unset: Return a list of <code>np.ndarray</code>.</li>\\n<li><code>TensorType.TENSORFLOW</code> or <code>\\'tf\\'</code>: Return a batch of type <code>tf.Tensor</code>.</li>\\n<li><code>TensorType.PYTORCH</code> or <code>\\'pt\\'</code>: Return a batch of type <code>torch.Tensor</code>.</li>\\n<li><code>TensorType.NUMPY</code> or <code>\\'np\\'</code>: Return a batch of type <code>np.ndarray</code>.</li>\\n<li><code>TensorType.JAX</code> or <code>\\'jax\\'</code>: Return a batch of type <code>jax.numpy.ndarray</code>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.data_format\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.data_format\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>data_format</strong> (<code>ChannelDimension</code> or <code>str</code>, <em>optional</em>, defaults to <code>ChannelDimension.FIRST</code>) —\\nThe channel dimension format for the output image. Can be one of:<ul>\\n<li><code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>\\n<li><code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerImageProcessor.preprocess.input_data_format\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerImageProcessor.preprocess.input_data_format\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>input_data_format</strong> (<code>ChannelDimension</code> or <code>str</code>, <em>optional</em>) —\\nThe channel dimension format for the input image. If unset, the channel dimension format is inferred\\nfrom the input image. Can be one of:<ul>\\n<li><code>\"channels_first\"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>\\n<li><code>\"channels_last\"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>\\n<li><code>\"none\"</code> or <code>ChannelDimension.NONE</code>: image in (height, width) format.</li>\\n</ul></span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-1x3yxsa\">Preprocess an image or batch of images.</p></div></div> <h2 class=\"relative group\"><a id=\"transformers.PoolFormerModel\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerModel\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-bd594z\">PoolFormerModel</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerModel\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">PoolFormerModel</span></span></h3> <a id=\"transformers.PoolFormerModel\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerModel\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/modeling_poolformer.py#L313\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerModel.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerModel.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerConfig\">PoolFormerConfig</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-1bdtzc7\">The bare PoolFormer Model transformer outputting raw hidden-states without any specific head on top.\\nThis model is a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> sub-class. Use\\nit as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and\\nbehavior.</p> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerModel.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.PoolFormerModel.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerModel.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/modeling_poolformer.py#L326\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">pixel_values<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><code>transformers.modeling_outputs.BaseModelOutputWithNoAttention</code> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 1 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerModel.forward.pixel_values\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerModel.forward.pixel_values\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>pixel_values</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_channels, height, width)</code>) —\\nPixel values. Pixel values can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoImageProcessor\">AutoImageProcessor</a>. See\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/deit#transformers.DeiTFeatureExtractor.__call__\">PoolFormerImageProcessor.<strong>call</strong>()</a> for details.</span></span> </li></ul>  <div id=\"transformers.PoolFormerModel.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><code>transformers.modeling_outputs.BaseModelOutputWithNoAttention</code> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <code>transformers.modeling_outputs.BaseModelOutputWithNoAttention</code> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerConfig\">PoolFormerConfig</a>) and inputs.</p>\\n<ul>\\n<li>\\n<p><strong>last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_channels, height, width)</code>) — Sequence of hidden-states at the output of the last layer of the model.</p>\\n</li>\\n<li>\\n<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, num_channels, height, width)</code>.</p>\\n<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>\\n</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-l6pje2\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerModel\">PoolFormerModel</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div> <div class=\"relative group rounded-md\"><a id=\"transformers.PoolFormerModel.forward.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerModel.forward.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-11lpom8\">Example:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoImageProcessor, PoolFormerModel\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> torch\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>dataset = load_dataset(<span class=\"hljs-string\">\"huggingface/cats-image\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image = dataset[<span class=\"hljs-string\">\"test\"</span>][<span class=\"hljs-string\">\"image\"</span>][<span class=\"hljs-number\">0</span>]\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class=\"hljs-string\">\"sail/poolformer_s12\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = PoolFormerModel.from_pretrained(<span class=\"hljs-string\">\"sail/poolformer_s12\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>inputs = image_processor(image, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">with</span> torch.no_grad():\\n<span class=\"hljs-meta\">... </span>    outputs = model(**inputs)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-built_in\">list</span>(last_hidden_states.shape)\\n[<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">7</span>]</pre></div></div></div></div> <h2 class=\"relative group\"><a id=\"transformers.PoolFormerForImageClassification\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerForImageClassification\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1j2tkrs\">PoolFormerForImageClassification</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerForImageClassification\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">PoolFormerForImageClassification</span></span></h3> <a id=\"transformers.PoolFormerForImageClassification\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerForImageClassification\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/modeling_poolformer.py#L380\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerForImageClassification.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerForImageClassification.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerConfig\">PoolFormerConfig</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-7k9kh1\">PoolFormer Model transformer with an image classification head on top</p> <p data-svelte-h=\"svelte-68lg8f\">This model is a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> sub-class. Use\\nit as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and\\nbehavior.</p> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.PoolFormerForImageClassification.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.PoolFormerForImageClassification.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.PoolFormerForImageClassification.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/poolformer/modeling_poolformer.py#L396\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">pixel_values<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">labels<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention\">transformers.modeling_outputs.ImageClassifierOutputWithNoAttention</a> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 2 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerForImageClassification.forward.pixel_values\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerForImageClassification.forward.pixel_values\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>pixel_values</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_channels, height, width)</code>) —\\nPixel values. Pixel values can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoImageProcessor\">AutoImageProcessor</a>. See\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/deit#transformers.DeiTFeatureExtractor.__call__\">PoolFormerImageProcessor.<strong>call</strong>()</a> for details.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.PoolFormerForImageClassification.forward.labels\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerForImageClassification.forward.labels\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) —\\nLabels for computing the image classification/regression loss. Indices should be in <code>[0, ..., config.num_labels - 1]</code>. If <code>config.num_labels == 1</code> a regression loss is computed (Mean-Square loss), If\\n<code>config.num_labels &gt; 1</code> a classification loss is computed (Cross-Entropy).</span></span> </li></ul>  <div id=\"transformers.PoolFormerForImageClassification.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention\">transformers.modeling_outputs.ImageClassifierOutputWithNoAttention</a> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.ImageClassifierOutputWithNoAttention\">transformers.modeling_outputs.ImageClassifierOutputWithNoAttention</a> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerConfig\">PoolFormerConfig</a>) and inputs.</p>\\n<ul>\\n<li><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) — Classification (or regression if config.num_labels==1) loss.</li>\\n<li><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.num_labels)</code>) — Classification (or regression if config.num_labels==1) scores (before SoftMax).</li>\\n<li><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each stage) of shape <code>(batch_size, num_channels, height, width)</code>. Hidden-states (also\\ncalled feature maps) of the model at the output of each stage.</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-ta4zww\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/poolformer#transformers.PoolFormerForImageClassification\">PoolFormerForImageClassification</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div> <div class=\"relative group rounded-md\"><a id=\"transformers.PoolFormerForImageClassification.forward.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.PoolFormerForImageClassification.forward.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-11lpom8\">Example:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoImageProcessor, PoolFormerForImageClassification\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> torch\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>dataset = load_dataset(<span class=\"hljs-string\">\"huggingface/cats-image\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image = dataset[<span class=\"hljs-string\">\"test\"</span>][<span class=\"hljs-string\">\"image\"</span>][<span class=\"hljs-number\">0</span>]\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class=\"hljs-string\">\"sail/poolformer_s12\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = PoolFormerForImageClassification.from_pretrained(<span class=\"hljs-string\">\"sail/poolformer_s12\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>inputs = image_processor(image, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">with</span> torch.no_grad():\\n<span class=\"hljs-meta\">... </span>    logits = model(**inputs).logits\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># model predicts one of the 1000 ImageNet classes</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>predicted_label = logits.argmax(-<span class=\"hljs-number\">1</span>).item()\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-built_in\">print</span>(model.config.id2label[predicted_label])\\ntabby, tabby cat</pre></div></div></div></div> <p></p> <div id=\"svelte-announcer\" aria-live=\"assertive\" aria-atomic=\"true\" style=\"position: absolute; left: 0px; top: 0px; clip: rect(0px, 0px, 0px, 0px); clip-path: inset(50%); overflow: hidden; white-space: nowrap; width: 1px; height: 1px;\"></div></div>\\n\\t\\t\\t\\t<div class=\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\"><a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/model_doc/nat\" class=\"mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300\"><span class=\"mr-2 translate-y-px\">←</span>NAT</a>\\n\\t\\t\\t\\t\\t<a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/model_doc/pvt\" class=\"ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300\">Pyramid Vision Transformer (PVT)<span class=\"ml-2 translate-y-px\">→</span></a></div></div></div>\\n\\t\\t<div class=\"sticky top-0 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapter&quot;:{&quot;title&quot;:&quot;PoolFormer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;poolformer&quot;,&quot;url&quot;:&quot;#poolformer&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Overview&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;overview&quot;,&quot;url&quot;:&quot;#overview&quot;},{&quot;title&quot;:&quot;Resources&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;resources&quot;,&quot;url&quot;:&quot;#resources&quot;},{&quot;title&quot;:&quot;PoolFormerConfig&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.PoolFormerConfig&quot;,&quot;url&quot;:&quot;#transformers.PoolFormerConfig&quot;},{&quot;title&quot;:&quot;PoolFormerFeatureExtractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.PoolFormerFeatureExtractor&quot;,&quot;url&quot;:&quot;#transformers.PoolFormerFeatureExtractor&quot;},{&quot;title&quot;:&quot;PoolFormerImageProcessor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.PoolFormerImageProcessor&quot;,&quot;url&quot;:&quot;#transformers.PoolFormerImageProcessor&quot;},{&quot;title&quot;:&quot;PoolFormerModel&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.PoolFormerModel&quot;,&quot;url&quot;:&quot;#transformers.PoolFormerModel&quot;},{&quot;title&quot;:&quot;PoolFormerForImageClassification&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.PoolFormerForImageClassification&quot;,&quot;url&quot;:&quot;#transformers.PoolFormerForImageClassification&quot;}]}}\" data-target=\"SubSideMenu\"><nav class=\"hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pt-24 pl-6 pr-10 pb-16 text-sm lg:flex 2xl:w-[305px]\"><a href=\"#poolformer\" class=\" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-poolformer\"><wbr>Pool<wbr>Former</a> <a href=\"#overview\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-overview\"><wbr>Overview</a> <a href=\"#resources\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-resources\"><wbr>Resources</a> <a href=\"#transformers.PoolFormerConfig\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.PoolFormerConfig\"><wbr>Pool<wbr>Former<wbr>Config</a> <a href=\"#transformers.PoolFormerFeatureExtractor\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.PoolFormerFeatureExtractor\"><wbr>Pool<wbr>Former<wbr>Feature<wbr>Extractor</a> <a href=\"#transformers.PoolFormerImageProcessor\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.PoolFormerImageProcessor\"><wbr>Pool<wbr>Former<wbr>Image<wbr>Processor</a> <a href=\"#transformers.PoolFormerModel\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.PoolFormerModel\"><wbr>Pool<wbr>Former<wbr>Model</a> <a href=\"#transformers.PoolFormerForImageClassification\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.PoolFormerForImageClassification\"><wbr>Pool<wbr>Former<wbr>For<wbr>Image<wbr>Classification</a> </nav></div></div></div>\\n\\t<div id=\"doc-footer\"></div></main>\\n\\t</div>\\n\\n\\t\\t<script>\\n\\t\\t\\timport(\"/front/build/kube-b0520c1/index.js\");\\n\\t\\t\\twindow.moonSha = \"kube-b0520c1/\";\\n\\t\\t\\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\"}`);\\n\\t\\t</script>\\n\\n\\t\\t<!-- Stripe -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://js.stripe.com/v3/\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google analytics v4 -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\n\\t\\t\\t\\twindow.dataLayer = window.dataLayer || [];\\n\\t\\t\\t\\tfunction gtag() {\\n\\t\\t\\t\\t\\tif (window.dataLayer !== undefined) {\\n\\t\\t\\t\\t\\t\\twindow.dataLayer.push(arguments);\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tgtag(\"js\", new Date());\\n\\t\\t\\t\\tgtag(\"config\", \"G-8Q63TH4CSL\", { page_path: \"/docs/transformers/v4.34.0/en/model_doc/poolformer\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages\\n\\t\\t\\t\\tgtag(\"consent\", \"default\", { ad_storage: \"denied\", analytics_storage: \"denied\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent\\n\\t\\t\\t\\t/// TODO: ask the user for their consent and update this with gtag(\\'consent\\', \\'update\\')\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google Analytics v3 (deprecated) -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\t(function (i, s, o, g, r, a, m) {\\n\\t\\t\\t\\t\\ti[\"GoogleAnalyticsObject\"] = r;\\n\\t\\t\\t\\t\\t(i[r] =\\n\\t\\t\\t\\t\\t\\ti[r] ||\\n\\t\\t\\t\\t\\t\\tfunction () {\\n\\t\\t\\t\\t\\t\\t\\t(i[r].q = i[r].q || []).push(arguments);\\n\\t\\t\\t\\t\\t\\t}),\\n\\t\\t\\t\\t\\t\\t(i[r].l = 1 * new Date());\\n\\t\\t\\t\\t\\t(a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);\\n\\t\\t\\t\\t\\ta.async = 1;\\n\\t\\t\\t\\t\\ta.src = g;\\n\\t\\t\\t\\t\\tm.parentNode.insertBefore(a, m);\\n\\t\\t\\t\\t})(window, document, \"script\", \"https://www.google-analytics.com/analytics.js\", \"ganalytics\");\\n\\t\\t\\t\\tganalytics(\"create\", \"UA-83738774-2\", \"auto\");\\n\\t\\t\\t\\tganalytics(\"send\", \"pageview\", \"/docs/transformers/v4.34.0/en/model_doc/poolformer\");\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\t\\n\\n<iframe name=\"__privateStripeMetricsController7940\" frameborder=\"0\" allowtransparency=\"true\" scrolling=\"no\" role=\"presentation\" allow=\"payment *\" src=\"https://js.stripe.com/v3/m-outer-27c67c0d52761104439bb051c7856ab1.html#url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftransformers%2Fv4.34.0%2Fen%2Fmodel_doc%2Fpoolformer&amp;title=PoolFormer&amp;referrer=&amp;muid=cd39c264-a17a-440c-91b1-8b4f30f9f3cde5f588&amp;sid=f258a8bc-79d8-40b5-8e08-2ce94e9818e96ccd38&amp;version=6&amp;preview=false\" aria-hidden=\"true\" tabindex=\"-1\" style=\"border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;\"></iframe></body></html>',\n",
       "  'mime_type': 'text/plain',\n",
       "  'metadata': {}},\n",
       " {'document_id': '1',\n",
       "  'content': '<!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<meta charset=\"utf-8\">\\n\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\">\\n\\t\\t<meta name=\"description\" content=\"We’re on a journey to advance and democratize artificial intelligence through open source and open science.\">\\n\\t\\t<meta property=\"fb:app_id\" content=\"1321688464574422\">\\n\\t\\t<meta name=\"twitter:card\" content=\"summary_large_image\">\\n\\t\\t<meta name=\"twitter:site\" content=\"@huggingface\">\\n\\t\\t<meta property=\"og:title\" content=\"Object detection\">\\n\\t\\t<meta property=\"og:type\" content=\"website\">\\n\\t\\t<meta property=\"og:url\" content=\"https://huggingface.co/docs/transformers/v4.34.0/en/tasks/object_detection\">\\n\\t\\t<meta property=\"og:image\" content=\"https://huggingface.co/front/thumbnails/docs/transformers.png\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"/front/build/kube-5e23f38/style.css\">\\n\\n\\t\\t<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap\" rel=\"stylesheet\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap\" rel=\"stylesheet\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" as=\"style\" onload=\"this.onload=null;this.rel=\\'stylesheet\\'\">\\n\\t\\t<noscript>\\n\\t\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" />\\n\\t\\t</noscript>\\n\\n\\t\\t  \\n\\n\\t\\t<title>Object detection</title>\\n\\n\\t\\t<script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script defer=\"\" data-domain=\"huggingface.co\" src=\"/js/script.js\"></script>\\n\\t<script src=\"https://js.stripe.com/v3/\" async=\"\"></script><script src=\"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\" async=\"\"></script><meta http-equiv=\"origin-trial\" content=\"AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9\"><link rel=\"stylesheet\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/assets/0.e3b0c442.css\"><link rel=\"modulepreload\" as=\"script\" crossorigin=\"\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/nodes/1.38c5c2f6.js\"><meta name=\"hf:doc:metadata\" content=\"{&quot;local&quot;:&quot;object-detection&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;load-the-cppe5-dataset&quot;,&quot;title&quot;:&quot;Load the CPPE-5 dataset&quot;},{&quot;local&quot;:&quot;preprocess-the-data&quot;,&quot;title&quot;:&quot;Preprocess the data&quot;},{&quot;local&quot;:&quot;training-the-detr-model&quot;,&quot;title&quot;:&quot;Training the DETR model&quot;},{&quot;local&quot;:&quot;evaluate&quot;,&quot;title&quot;:&quot;Evaluate&quot;},{&quot;local&quot;:&quot;inference&quot;,&quot;title&quot;:&quot;Inference&quot;}],&quot;title&quot;:&quot;Object detection&quot;}\"></head>\\n\\t<body class=\"flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage\">\\n\\t\\t<div class=\"flex min-h-screen flex-col\">\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}\" data-target=\"MainHeader\"><header class=\"border-b border-gray-100 \"><div class=\"w-full px-4  flex h-16 items-center\"><div class=\"flex flex-1 items-center\"><a class=\"mr-5 flex flex-none items-center lg:mr-6\" href=\"/\"><img alt=\"Hugging Face\\'s logo\" class=\"w-7 md:mr-2\" src=\"/front/assets/huggingface_logo-noborder.svg\"> <span class=\"hidden whitespace-nowrap text-lg font-bold md:block\">Hugging Face</span></a> <div class=\"relative flex-1 lg:max-w-sm mr-2 sm:mr-4 lg:mr-6\"><input autocomplete=\"off\" class=\"w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl\" name=\"\" placeholder=\"Search models, datasets, users...\" spellcheck=\"false\" type=\"text\"> <svg class=\"absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> </div> <div class=\"flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden\"><button class=\"relative z-40 flex h-6 w-8 items-center justify-center\" type=\"button\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 10 10\" class=\"text-xl\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" preserveAspectRatio=\"xMidYMid meet\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\"></path></svg> </button> </div></div> <nav aria-label=\"Main\" class=\"ml-auto hidden lg:block\"><ul class=\"flex items-center space-x-2\"><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700\" href=\"/models\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg> Models</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700\" href=\"/datasets\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-red-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 25 25\"><ellipse cx=\"12.5\" cy=\"5\" fill=\"currentColor\" fill-opacity=\"0.25\" rx=\"7.5\" ry=\"2\"></ellipse><path d=\"M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z\" fill=\"currentColor\"></path></svg> Datasets</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700\" href=\"/spaces\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-blue-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 25 25\"><path opacity=\".5\" d=\"M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z\" fill=\"currentColor\"></path><path opacity=\".75\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z\" fill=\"currentColor\"></path><path opacity=\".25\" d=\"M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z\" fill=\"currentColor\"></path></svg> Spaces</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/docs\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path opacity=\"0.5\" d=\"M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z\" fill=\"currentColor\"></path><path d=\"M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z\" fill=\"currentColor\" fill-opacity=\"0.75\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z\" fill=\"currentColor\"></path><path opacity=\"0.5\" d=\"M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z\" fill=\"currentColor\"></path></svg> Docs</a></li> <li><div class=\"relative \"><button class=\"px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-green-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-tertiary\" d=\"M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z\" fill=\"currentColor\"></path></svg> Solutions </button> </div></li> <li><a class=\"group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/pricing\">Pricing</a></li> <li><div class=\"relative group\"><button class=\"px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 32 18\" preserveAspectRatio=\"xMidYMid meet\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z\" fill=\"currentColor\"></path></svg>  </button> </div></li> <li><hr class=\"h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800\"></li> <li><a class=\"block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/login\">Log In</a></li> <li><a class=\"rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black\" href=\"/join\">Sign Up</a></li></ul></nav></div></header></div>\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"GoogleAnalyticsTracker\"></div>\\n\\t\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"SSOBanner\"></div>\\n\\n\\t<main class=\"flex flex-1 flex-col\"><div class=\"relative lg:flex\"><div class=\"sticky top-0 z-20 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;🤗 Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/index&quot;},{&quot;title&quot;:&quot;Quick tour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;installation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/installation&quot;}]},{&quot;title&quot;:&quot;Tutorials&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Run inference with pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_tutorial&quot;},{&quot;title&quot;:&quot;Write portable code with AutoClass&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;autoclass_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/autoclass_tutorial&quot;},{&quot;title&quot;:&quot;Preprocess data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocessing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/preprocessing&quot;},{&quot;title&quot;:&quot;Fine-tune a pretrained model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/training&quot;},{&quot;title&quot;:&quot;Train with a script&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;run_scripts&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/run_scripts&quot;},{&quot;title&quot;:&quot;Set up distributed training with 🤗 Accelerate&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/accelerate&quot;},{&quot;title&quot;:&quot;Load and train adapters with 🤗 PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;peft&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/peft&quot;},{&quot;title&quot;:&quot;Share your model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_sharing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_sharing&quot;},{&quot;title&quot;:&quot;Agents&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers_agents&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/transformers_agents&quot;},{&quot;title&quot;:&quot;Generation with LLMs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;llm_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/llm_tutorial&quot;}]},{&quot;title&quot;:&quot;Task Guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Natural Language Processing&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text classification&quot;,&quot;id&quot;:&quot;tasks/sequence_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/sequence_classification&quot;},{&quot;title&quot;:&quot;Token classification&quot;,&quot;id&quot;:&quot;tasks/token_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/token_classification&quot;},{&quot;title&quot;:&quot;Question answering&quot;,&quot;id&quot;:&quot;tasks/question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/question_answering&quot;},{&quot;title&quot;:&quot;Causal language modeling&quot;,&quot;id&quot;:&quot;tasks/language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/language_modeling&quot;},{&quot;title&quot;:&quot;Masked language modeling&quot;,&quot;id&quot;:&quot;tasks/masked_language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/masked_language_modeling&quot;},{&quot;title&quot;:&quot;Translation&quot;,&quot;id&quot;:&quot;tasks/translation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/translation&quot;},{&quot;title&quot;:&quot;Summarization&quot;,&quot;id&quot;:&quot;tasks/summarization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/summarization&quot;},{&quot;title&quot;:&quot;Multiple choice&quot;,&quot;id&quot;:&quot;tasks/multiple_choice&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/multiple_choice&quot;}]},{&quot;title&quot;:&quot;Audio&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio classification&quot;,&quot;id&quot;:&quot;tasks/audio_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/audio_classification&quot;},{&quot;title&quot;:&quot;Automatic speech recognition&quot;,&quot;id&quot;:&quot;tasks/asr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/asr&quot;}]},{&quot;title&quot;:&quot;Computer Vision&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image classification&quot;,&quot;id&quot;:&quot;tasks/image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_classification&quot;},{&quot;title&quot;:&quot;Semantic segmentation&quot;,&quot;id&quot;:&quot;tasks/semantic_segmentation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/semantic_segmentation&quot;},{&quot;title&quot;:&quot;Video classification&quot;,&quot;id&quot;:&quot;tasks/video_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/video_classification&quot;},{&quot;title&quot;:&quot;Object detection&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tasks/object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot object detection&quot;,&quot;id&quot;:&quot;tasks/zero_shot_object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot image classification&quot;,&quot;id&quot;:&quot;tasks/zero_shot_image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_image_classification&quot;},{&quot;title&quot;:&quot;Depth estimation&quot;,&quot;id&quot;:&quot;tasks/monocular_depth_estimation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/monocular_depth_estimation&quot;}]},{&quot;title&quot;:&quot;Multimodal&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image captioning&quot;,&quot;id&quot;:&quot;tasks/image_captioning&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_captioning&quot;},{&quot;title&quot;:&quot;Document Question Answering&quot;,&quot;id&quot;:&quot;tasks/document_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/document_question_answering&quot;},{&quot;title&quot;:&quot;Visual Question Answering&quot;,&quot;id&quot;:&quot;tasks/visual_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/visual_question_answering&quot;},{&quot;title&quot;:&quot;Text to speech&quot;,&quot;id&quot;:&quot;tasks/text-to-speech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/text-to-speech&quot;}]},{&quot;title&quot;:&quot;Generation&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Customize the generation strategy&quot;,&quot;id&quot;:&quot;generation_strategies&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/generation_strategies&quot;}]},{&quot;title&quot;:&quot;Prompting&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image tasks with IDEFICS&quot;,&quot;id&quot;:&quot;tasks/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/idefics&quot;}]}]},{&quot;title&quot;:&quot;Developer guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Use fast tokenizers from 🤗 Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/fast_tokenizers&quot;},{&quot;title&quot;:&quot;Run inference with multilingual models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multilingual&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/multilingual&quot;},{&quot;title&quot;:&quot;Use model-specific APIs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;create_a_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/create_a_model&quot;},{&quot;title&quot;:&quot;Share a custom model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_models&quot;},{&quot;title&quot;:&quot;Templates for chat models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;chat_templating&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/chat_templating&quot;},{&quot;title&quot;:&quot;Run training on Amazon SageMaker&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sagemaker&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/sagemaker&quot;},{&quot;title&quot;:&quot;Export to ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;serialization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/serialization&quot;},{&quot;title&quot;:&quot;Export to TFLite&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tflite&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tflite&quot;},{&quot;title&quot;:&quot;Export to TorchScript&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;torchscript&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/torchscript&quot;},{&quot;title&quot;:&quot;Benchmarks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;benchmarks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/benchmarks&quot;},{&quot;title&quot;:&quot;Notebooks with examples&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;notebooks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/notebooks&quot;},{&quot;title&quot;:&quot;Community resources&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;community&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/community&quot;},{&quot;title&quot;:&quot;Custom Tools and Prompts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_tools&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_tools&quot;},{&quot;title&quot;:&quot;Troubleshoot&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;troubleshooting&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/troubleshooting&quot;}]},{&quot;title&quot;:&quot;Performance and scalability&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Overview&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/performance&quot;},{&quot;title&quot;:&quot;Efficient training techniques&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Methods and tools for efficient training on a single GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_one&quot;},{&quot;title&quot;:&quot;Multiple GPUs and parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_many&quot;},{&quot;title&quot;:&quot;Efficient training on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu&quot;},{&quot;title&quot;:&quot;Distributed CPU training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu_many&quot;},{&quot;title&quot;:&quot;Training on TPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu&quot;},{&quot;title&quot;:&quot;Training on TPU with TensorFlow&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu_tf&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu_tf&quot;},{&quot;title&quot;:&quot;Training on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_special&quot;},{&quot;title&quot;:&quot;Custom hardware for training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_hardware&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_hardware&quot;},{&quot;title&quot;:&quot;Hyperparameter Search using Trainer API&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;hpo_train&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/hpo_train&quot;}]},{&quot;title&quot;:&quot;Optimizing inference&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Inference on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_cpu&quot;},{&quot;title&quot;:&quot;Inference on one GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_one&quot;},{&quot;title&quot;:&quot;Inference on many GPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_many&quot;},{&quot;title&quot;:&quot;Inference on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_special&quot;}]},{&quot;title&quot;:&quot;Instantiating a big model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;big_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/big_models&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;debugging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/debugging&quot;},{&quot;title&quot;:&quot;XLA Integration for TensorFlow Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tf_xla&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tf_xla&quot;},{&quot;title&quot;:&quot;Optimize inference using `torch.compile()`&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_torch_compile&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_torch_compile&quot;}]},{&quot;title&quot;:&quot;Contribute&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;How to contribute to transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contributing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/contributing&quot;},{&quot;title&quot;:&quot;How to add a model to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_model&quot;},{&quot;title&quot;:&quot;How to convert a 🤗 Transformers model to TensorFlow?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_tensorflow_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_tensorflow_model&quot;},{&quot;title&quot;:&quot;How to add a pipeline to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_pipeline&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_pipeline&quot;},{&quot;title&quot;:&quot;Testing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;testing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/testing&quot;},{&quot;title&quot;:&quot;Checks on a Pull Request&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pr_checks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pr_checks&quot;}]},{&quot;title&quot;:&quot;Conceptual guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Philosophy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;philosophy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/philosophy&quot;},{&quot;title&quot;:&quot;Glossary&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;glossary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/glossary&quot;},{&quot;title&quot;:&quot;What 🤗 Transformers can do&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/task_summary&quot;},{&quot;title&quot;:&quot;How 🤗 Transformers solve tasks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tasks_explained&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks_explained&quot;},{&quot;title&quot;:&quot;The Transformer model family&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_summary&quot;},{&quot;title&quot;:&quot;Summary of the tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tokenizer_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tokenizer_summary&quot;},{&quot;title&quot;:&quot;Attention mechanisms&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;attention&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/attention&quot;},{&quot;title&quot;:&quot;Padding and truncation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pad_truncation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pad_truncation&quot;},{&quot;title&quot;:&quot;BERTology&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bertology&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/bertology&quot;},{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perplexity&quot;},{&quot;title&quot;:&quot;Pipelines for webserver inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_webserver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_webserver&quot;},{&quot;title&quot;:&quot;Model training anatomy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_memory_anatomy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_memory_anatomy&quot;}]},{&quot;title&quot;:&quot;API&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main Classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Agents and Tools&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/agent&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/agent&quot;},{&quot;title&quot;:&quot;Auto Classes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/auto&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/auto&quot;},{&quot;title&quot;:&quot;Callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/callback&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/callback&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/configuration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/configuration&quot;},{&quot;title&quot;:&quot;Data Collator&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/data_collator&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/data_collator&quot;},{&quot;title&quot;:&quot;Keras callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/keras_callbacks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/keras_callbacks&quot;},{&quot;title&quot;:&quot;Logging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/logging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/logging&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/model&quot;},{&quot;title&quot;:&quot;Text Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/text_generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/text_generation&quot;},{&quot;title&quot;:&quot;ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/onnx&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/onnx&quot;},{&quot;title&quot;:&quot;Optimization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/optimizer_schedules&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules&quot;},{&quot;title&quot;:&quot;Model outputs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/output&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/output&quot;},{&quot;title&quot;:&quot;Pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/pipelines&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/pipelines&quot;},{&quot;title&quot;:&quot;Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/processors&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/processors&quot;},{&quot;title&quot;:&quot;Quantization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/quantization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/quantization&quot;},{&quot;title&quot;:&quot;Tokenizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/tokenizer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/tokenizer&quot;},{&quot;title&quot;:&quot;Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/trainer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/trainer&quot;},{&quot;title&quot;:&quot;DeepSpeed Integration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/deepspeed&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/deepspeed&quot;},{&quot;title&quot;:&quot;Feature Extractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/feature_extractor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/feature_extractor&quot;},{&quot;title&quot;:&quot;Image Processor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/image_processor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/image_processor&quot;}]},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALBERT&quot;,&quot;id&quot;:&quot;model_doc/albert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/albert&quot;},{&quot;title&quot;:&quot;BART&quot;,&quot;id&quot;:&quot;model_doc/bart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bart&quot;},{&quot;title&quot;:&quot;BARThez&quot;,&quot;id&quot;:&quot;model_doc/barthez&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/barthez&quot;},{&quot;title&quot;:&quot;BARTpho&quot;,&quot;id&quot;:&quot;model_doc/bartpho&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bartpho&quot;},{&quot;title&quot;:&quot;BERT&quot;,&quot;id&quot;:&quot;model_doc/bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert&quot;},{&quot;title&quot;:&quot;BertGeneration&quot;,&quot;id&quot;:&quot;model_doc/bert-generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-generation&quot;},{&quot;title&quot;:&quot;BertJapanese&quot;,&quot;id&quot;:&quot;model_doc/bert-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-japanese&quot;},{&quot;title&quot;:&quot;Bertweet&quot;,&quot;id&quot;:&quot;model_doc/bertweet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bertweet&quot;},{&quot;title&quot;:&quot;BigBird&quot;,&quot;id&quot;:&quot;model_doc/big_bird&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/big_bird&quot;},{&quot;title&quot;:&quot;BigBirdPegasus&quot;,&quot;id&quot;:&quot;model_doc/bigbird_pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bigbird_pegasus&quot;},{&quot;title&quot;:&quot;BioGpt&quot;,&quot;id&quot;:&quot;model_doc/biogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/biogpt&quot;},{&quot;title&quot;:&quot;Blenderbot&quot;,&quot;id&quot;:&quot;model_doc/blenderbot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot&quot;},{&quot;title&quot;:&quot;Blenderbot Small&quot;,&quot;id&quot;:&quot;model_doc/blenderbot-small&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot-small&quot;},{&quot;title&quot;:&quot;BLOOM&quot;,&quot;id&quot;:&quot;model_doc/bloom&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bloom&quot;},{&quot;title&quot;:&quot;BORT&quot;,&quot;id&quot;:&quot;model_doc/bort&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bort&quot;},{&quot;title&quot;:&quot;ByT5&quot;,&quot;id&quot;:&quot;model_doc/byt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/byt5&quot;},{&quot;title&quot;:&quot;CamemBERT&quot;,&quot;id&quot;:&quot;model_doc/camembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/camembert&quot;},{&quot;title&quot;:&quot;CANINE&quot;,&quot;id&quot;:&quot;model_doc/canine&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/canine&quot;},{&quot;title&quot;:&quot;CodeGen&quot;,&quot;id&quot;:&quot;model_doc/codegen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/codegen&quot;},{&quot;title&quot;:&quot;CodeLlama&quot;,&quot;id&quot;:&quot;model_doc/code_llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/code_llama&quot;},{&quot;title&quot;:&quot;ConvBERT&quot;,&quot;id&quot;:&quot;model_doc/convbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convbert&quot;},{&quot;title&quot;:&quot;CPM&quot;,&quot;id&quot;:&quot;model_doc/cpm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpm&quot;},{&quot;title&quot;:&quot;CPMANT&quot;,&quot;id&quot;:&quot;model_doc/cpmant&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpmant&quot;},{&quot;title&quot;:&quot;CTRL&quot;,&quot;id&quot;:&quot;model_doc/ctrl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ctrl&quot;},{&quot;title&quot;:&quot;DeBERTa&quot;,&quot;id&quot;:&quot;model_doc/deberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta&quot;},{&quot;title&quot;:&quot;DeBERTa-v2&quot;,&quot;id&quot;:&quot;model_doc/deberta-v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta-v2&quot;},{&quot;title&quot;:&quot;DialoGPT&quot;,&quot;id&quot;:&quot;model_doc/dialogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dialogpt&quot;},{&quot;title&quot;:&quot;DistilBERT&quot;,&quot;id&quot;:&quot;model_doc/distilbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/distilbert&quot;},{&quot;title&quot;:&quot;DPR&quot;,&quot;id&quot;:&quot;model_doc/dpr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpr&quot;},{&quot;title&quot;:&quot;ELECTRA&quot;,&quot;id&quot;:&quot;model_doc/electra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/electra&quot;},{&quot;title&quot;:&quot;Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encoder-decoder&quot;},{&quot;title&quot;:&quot;ERNIE&quot;,&quot;id&quot;:&quot;model_doc/ernie&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie&quot;},{&quot;title&quot;:&quot;ErnieM&quot;,&quot;id&quot;:&quot;model_doc/ernie_m&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie_m&quot;},{&quot;title&quot;:&quot;ESM&quot;,&quot;id&quot;:&quot;model_doc/esm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/esm&quot;},{&quot;title&quot;:&quot;Falcon&quot;,&quot;id&quot;:&quot;model_doc/falcon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/falcon&quot;},{&quot;title&quot;:&quot;FLAN-T5&quot;,&quot;id&quot;:&quot;model_doc/flan-t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-t5&quot;},{&quot;title&quot;:&quot;FLAN-UL2&quot;,&quot;id&quot;:&quot;model_doc/flan-ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-ul2&quot;},{&quot;title&quot;:&quot;FlauBERT&quot;,&quot;id&quot;:&quot;model_doc/flaubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flaubert&quot;},{&quot;title&quot;:&quot;FNet&quot;,&quot;id&quot;:&quot;model_doc/fnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fnet&quot;},{&quot;title&quot;:&quot;FSMT&quot;,&quot;id&quot;:&quot;model_doc/fsmt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fsmt&quot;},{&quot;title&quot;:&quot;Funnel Transformer&quot;,&quot;id&quot;:&quot;model_doc/funnel&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/funnel&quot;},{&quot;title&quot;:&quot;GPT&quot;,&quot;id&quot;:&quot;model_doc/openai-gpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/openai-gpt&quot;},{&quot;title&quot;:&quot;GPT Neo&quot;,&quot;id&quot;:&quot;model_doc/gpt_neo&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neo&quot;},{&quot;title&quot;:&quot;GPT NeoX&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox&quot;},{&quot;title&quot;:&quot;GPT NeoX Japanese&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox_japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox_japanese&quot;},{&quot;title&quot;:&quot;GPT-J&quot;,&quot;id&quot;:&quot;model_doc/gptj&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptj&quot;},{&quot;title&quot;:&quot;GPT2&quot;,&quot;id&quot;:&quot;model_doc/gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt2&quot;},{&quot;title&quot;:&quot;GPTBigCode&quot;,&quot;id&quot;:&quot;model_doc/gpt_bigcode&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_bigcode&quot;},{&quot;title&quot;:&quot;GPTSAN Japanese&quot;,&quot;id&quot;:&quot;model_doc/gptsan-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptsan-japanese&quot;},{&quot;title&quot;:&quot;GPTSw3&quot;,&quot;id&quot;:&quot;model_doc/gpt-sw3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt-sw3&quot;},{&quot;title&quot;:&quot;HerBERT&quot;,&quot;id&quot;:&quot;model_doc/herbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/herbert&quot;},{&quot;title&quot;:&quot;I-BERT&quot;,&quot;id&quot;:&quot;model_doc/ibert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ibert&quot;},{&quot;title&quot;:&quot;Jukebox&quot;,&quot;id&quot;:&quot;model_doc/jukebox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/jukebox&quot;},{&quot;title&quot;:&quot;LED&quot;,&quot;id&quot;:&quot;model_doc/led&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/led&quot;},{&quot;title&quot;:&quot;LLaMA&quot;,&quot;id&quot;:&quot;model_doc/llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama&quot;},{&quot;title&quot;:&quot;Llama2&quot;,&quot;id&quot;:&quot;model_doc/llama2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama2&quot;},{&quot;title&quot;:&quot;Longformer&quot;,&quot;id&quot;:&quot;model_doc/longformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longformer&quot;},{&quot;title&quot;:&quot;LongT5&quot;,&quot;id&quot;:&quot;model_doc/longt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longt5&quot;},{&quot;title&quot;:&quot;LUKE&quot;,&quot;id&quot;:&quot;model_doc/luke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/luke&quot;},{&quot;title&quot;:&quot;M2M100&quot;,&quot;id&quot;:&quot;model_doc/m2m_100&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/m2m_100&quot;},{&quot;title&quot;:&quot;MarianMT&quot;,&quot;id&quot;:&quot;model_doc/marian&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/marian&quot;},{&quot;title&quot;:&quot;MarkupLM&quot;,&quot;id&quot;:&quot;model_doc/markuplm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/markuplm&quot;},{&quot;title&quot;:&quot;MBart and MBart-50&quot;,&quot;id&quot;:&quot;model_doc/mbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mbart&quot;},{&quot;title&quot;:&quot;MEGA&quot;,&quot;id&quot;:&quot;model_doc/mega&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mega&quot;},{&quot;title&quot;:&quot;MegatronBERT&quot;,&quot;id&quot;:&quot;model_doc/megatron-bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron-bert&quot;},{&quot;title&quot;:&quot;MegatronGPT2&quot;,&quot;id&quot;:&quot;model_doc/megatron_gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron_gpt2&quot;},{&quot;title&quot;:&quot;Mistral&quot;,&quot;id&quot;:&quot;model_doc/mistral&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mistral&quot;},{&quot;title&quot;:&quot;mLUKE&quot;,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MobileBERT&quot;,&quot;id&quot;:&quot;model_doc/mobilebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilebert&quot;},{&quot;title&quot;:&quot;MPNet&quot;,&quot;id&quot;:&quot;model_doc/mpnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpnet&quot;},{&quot;title&quot;:&quot;MPT&quot;,&quot;id&quot;:&quot;model_doc/mpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpt&quot;},{&quot;title&quot;:&quot;MRA&quot;,&quot;id&quot;:&quot;model_doc/mra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mra&quot;},{&quot;title&quot;:&quot;MT5&quot;,&quot;id&quot;:&quot;model_doc/mt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mt5&quot;},{&quot;title&quot;:&quot;MVP&quot;,&quot;id&quot;:&quot;model_doc/mvp&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mvp&quot;},{&quot;title&quot;:&quot;NEZHA&quot;,&quot;id&quot;:&quot;model_doc/nezha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nezha&quot;},{&quot;title&quot;:&quot;NLLB&quot;,&quot;id&quot;:&quot;model_doc/nllb&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb&quot;},{&quot;title&quot;:&quot;NLLB-MoE&quot;,&quot;id&quot;:&quot;model_doc/nllb-moe&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb-moe&quot;},{&quot;title&quot;:&quot;Nyströmformer&quot;,&quot;id&quot;:&quot;model_doc/nystromformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nystromformer&quot;},{&quot;title&quot;:&quot;Open-Llama&quot;,&quot;id&quot;:&quot;model_doc/open-llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/open-llama&quot;},{&quot;title&quot;:&quot;OPT&quot;,&quot;id&quot;:&quot;model_doc/opt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/opt&quot;},{&quot;title&quot;:&quot;Pegasus&quot;,&quot;id&quot;:&quot;model_doc/pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus&quot;},{&quot;title&quot;:&quot;PEGASUS-X&quot;,&quot;id&quot;:&quot;model_doc/pegasus_x&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus_x&quot;},{&quot;title&quot;:&quot;Persimmon&quot;,&quot;id&quot;:&quot;model_doc/persimmon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/persimmon&quot;},{&quot;title&quot;:&quot;PhoBERT&quot;,&quot;id&quot;:&quot;model_doc/phobert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/phobert&quot;},{&quot;title&quot;:&quot;PLBart&quot;,&quot;id&quot;:&quot;model_doc/plbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/plbart&quot;},{&quot;title&quot;:&quot;ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/prophetnet&quot;},{&quot;title&quot;:&quot;QDQBert&quot;,&quot;id&quot;:&quot;model_doc/qdqbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/qdqbert&quot;},{&quot;title&quot;:&quot;RAG&quot;,&quot;id&quot;:&quot;model_doc/rag&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rag&quot;},{&quot;title&quot;:&quot;REALM&quot;,&quot;id&quot;:&quot;model_doc/realm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/realm&quot;},{&quot;title&quot;:&quot;Reformer&quot;,&quot;id&quot;:&quot;model_doc/reformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/reformer&quot;},{&quot;title&quot;:&quot;RemBERT&quot;,&quot;id&quot;:&quot;model_doc/rembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rembert&quot;},{&quot;title&quot;:&quot;RetriBERT&quot;,&quot;id&quot;:&quot;model_doc/retribert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/retribert&quot;},{&quot;title&quot;:&quot;RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta&quot;},{&quot;title&quot;:&quot;RoBERTa-PreLayerNorm&quot;,&quot;id&quot;:&quot;model_doc/roberta-prelayernorm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta-prelayernorm&quot;},{&quot;title&quot;:&quot;RoCBert&quot;,&quot;id&quot;:&quot;model_doc/roc_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roc_bert&quot;},{&quot;title&quot;:&quot;RoFormer&quot;,&quot;id&quot;:&quot;model_doc/roformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roformer&quot;},{&quot;title&quot;:&quot;RWKV&quot;,&quot;id&quot;:&quot;model_doc/rwkv&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rwkv&quot;},{&quot;title&quot;:&quot;Splinter&quot;,&quot;id&quot;:&quot;model_doc/splinter&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/splinter&quot;},{&quot;title&quot;:&quot;SqueezeBERT&quot;,&quot;id&quot;:&quot;model_doc/squeezebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/squeezebert&quot;},{&quot;title&quot;:&quot;SwitchTransformers&quot;,&quot;id&quot;:&quot;model_doc/switch_transformers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/switch_transformers&quot;},{&quot;title&quot;:&quot;T5&quot;,&quot;id&quot;:&quot;model_doc/t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5&quot;},{&quot;title&quot;:&quot;T5v1.1&quot;,&quot;id&quot;:&quot;model_doc/t5v1.1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5v1.1&quot;},{&quot;title&quot;:&quot;TAPEX&quot;,&quot;id&quot;:&quot;model_doc/tapex&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapex&quot;},{&quot;title&quot;:&quot;Transformer XL&quot;,&quot;id&quot;:&quot;model_doc/transfo-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/transfo-xl&quot;},{&quot;title&quot;:&quot;UL2&quot;,&quot;id&quot;:&quot;model_doc/ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ul2&quot;},{&quot;title&quot;:&quot;UMT5&quot;,&quot;id&quot;:&quot;model_doc/umt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/umt5&quot;},{&quot;title&quot;:&quot;X-MOD&quot;,&quot;id&quot;:&quot;model_doc/xmod&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xmod&quot;},{&quot;title&quot;:&quot;XGLM&quot;,&quot;id&quot;:&quot;model_doc/xglm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xglm&quot;},{&quot;title&quot;:&quot;XLM&quot;,&quot;id&quot;:&quot;model_doc/xlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm&quot;},{&quot;title&quot;:&quot;XLM-ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/xlm-prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-prophetnet&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa-XL&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta-xl&quot;},{&quot;title&quot;:&quot;XLM-V&quot;,&quot;id&quot;:&quot;model_doc/xlm-v&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-v&quot;},{&quot;title&quot;:&quot;XLNet&quot;,&quot;id&quot;:&quot;model_doc/xlnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlnet&quot;},{&quot;title&quot;:&quot;YOSO&quot;,&quot;id&quot;:&quot;model_doc/yoso&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yoso&quot;}]},{&quot;title&quot;:&quot;Vision models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;BEiT&quot;,&quot;id&quot;:&quot;model_doc/beit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/beit&quot;},{&quot;title&quot;:&quot;BiT&quot;,&quot;id&quot;:&quot;model_doc/bit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bit&quot;},{&quot;title&quot;:&quot;Conditional DETR&quot;,&quot;id&quot;:&quot;model_doc/conditional_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/conditional_detr&quot;},{&quot;title&quot;:&quot;ConvNeXT&quot;,&quot;id&quot;:&quot;model_doc/convnext&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnext&quot;},{&quot;title&quot;:&quot;ConvNeXTV2&quot;,&quot;id&quot;:&quot;model_doc/convnextv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnextv2&quot;},{&quot;title&quot;:&quot;CvT&quot;,&quot;id&quot;:&quot;model_doc/cvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cvt&quot;},{&quot;title&quot;:&quot;Deformable DETR&quot;,&quot;id&quot;:&quot;model_doc/deformable_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deformable_detr&quot;},{&quot;title&quot;:&quot;DeiT&quot;,&quot;id&quot;:&quot;model_doc/deit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deit&quot;},{&quot;title&quot;:&quot;DETA&quot;,&quot;id&quot;:&quot;model_doc/deta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deta&quot;},{&quot;title&quot;:&quot;DETR&quot;,&quot;id&quot;:&quot;model_doc/detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/detr&quot;},{&quot;title&quot;:&quot;DiNAT&quot;,&quot;id&quot;:&quot;model_doc/dinat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinat&quot;},{&quot;title&quot;:&quot;DINO V2&quot;,&quot;id&quot;:&quot;model_doc/dinov2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinov2&quot;},{&quot;title&quot;:&quot;DiT&quot;,&quot;id&quot;:&quot;model_doc/dit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dit&quot;},{&quot;title&quot;:&quot;DPT&quot;,&quot;id&quot;:&quot;model_doc/dpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpt&quot;},{&quot;title&quot;:&quot;EfficientFormer&quot;,&quot;id&quot;:&quot;model_doc/efficientformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientformer&quot;},{&quot;title&quot;:&quot;EfficientNet&quot;,&quot;id&quot;:&quot;model_doc/efficientnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientnet&quot;},{&quot;title&quot;:&quot;FocalNet&quot;,&quot;id&quot;:&quot;model_doc/focalnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/focalnet&quot;},{&quot;title&quot;:&quot;GLPN&quot;,&quot;id&quot;:&quot;model_doc/glpn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/glpn&quot;},{&quot;title&quot;:&quot;ImageGPT&quot;,&quot;id&quot;:&quot;model_doc/imagegpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/imagegpt&quot;},{&quot;title&quot;:&quot;LeViT&quot;,&quot;id&quot;:&quot;model_doc/levit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/levit&quot;},{&quot;title&quot;:&quot;Mask2Former&quot;,&quot;id&quot;:&quot;model_doc/mask2former&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mask2former&quot;},{&quot;title&quot;:&quot;MaskFormer&quot;,&quot;id&quot;:&quot;model_doc/maskformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/maskformer&quot;},{&quot;title&quot;:&quot;MobileNetV1&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v1&quot;},{&quot;title&quot;:&quot;MobileNetV2&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v2&quot;},{&quot;title&quot;:&quot;MobileViT&quot;,&quot;id&quot;:&quot;model_doc/mobilevit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevit&quot;},{&quot;title&quot;:&quot;MobileViTV2&quot;,&quot;id&quot;:&quot;model_doc/mobilevitv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevitv2&quot;},{&quot;title&quot;:&quot;NAT&quot;,&quot;id&quot;:&quot;model_doc/nat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nat&quot;},{&quot;title&quot;:&quot;PoolFormer&quot;,&quot;id&quot;:&quot;model_doc/poolformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/poolformer&quot;},{&quot;title&quot;:&quot;Pyramid Vision Transformer (PVT)&quot;,&quot;id&quot;:&quot;model_doc/pvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pvt&quot;},{&quot;title&quot;:&quot;RegNet&quot;,&quot;id&quot;:&quot;model_doc/regnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/regnet&quot;},{&quot;title&quot;:&quot;ResNet&quot;,&quot;id&quot;:&quot;model_doc/resnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/resnet&quot;},{&quot;title&quot;:&quot;SegFormer&quot;,&quot;id&quot;:&quot;model_doc/segformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/segformer&quot;},{&quot;title&quot;:&quot;SwiftFormer&quot;,&quot;id&quot;:&quot;model_doc/swiftformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swiftformer&quot;},{&quot;title&quot;:&quot;Swin Transformer&quot;,&quot;id&quot;:&quot;model_doc/swin&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin&quot;},{&quot;title&quot;:&quot;Swin Transformer V2&quot;,&quot;id&quot;:&quot;model_doc/swinv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swinv2&quot;},{&quot;title&quot;:&quot;Swin2SR&quot;,&quot;id&quot;:&quot;model_doc/swin2sr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin2sr&quot;},{&quot;title&quot;:&quot;Table Transformer&quot;,&quot;id&quot;:&quot;model_doc/table-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/table-transformer&quot;},{&quot;title&quot;:&quot;TimeSformer&quot;,&quot;id&quot;:&quot;model_doc/timesformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/timesformer&quot;},{&quot;title&quot;:&quot;UperNet&quot;,&quot;id&quot;:&quot;model_doc/upernet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/upernet&quot;},{&quot;title&quot;:&quot;VAN&quot;,&quot;id&quot;:&quot;model_doc/van&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/van&quot;},{&quot;title&quot;:&quot;VideoMAE&quot;,&quot;id&quot;:&quot;model_doc/videomae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/videomae&quot;},{&quot;title&quot;:&quot;Vision Transformer (ViT)&quot;,&quot;id&quot;:&quot;model_doc/vit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit&quot;},{&quot;title&quot;:&quot;ViT Hybrid&quot;,&quot;id&quot;:&quot;model_doc/vit_hybrid&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_hybrid&quot;},{&quot;title&quot;:&quot;ViTDet&quot;,&quot;id&quot;:&quot;model_doc/vitdet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitdet&quot;},{&quot;title&quot;:&quot;ViTMAE&quot;,&quot;id&quot;:&quot;model_doc/vit_mae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_mae&quot;},{&quot;title&quot;:&quot;ViTMatte&quot;,&quot;id&quot;:&quot;model_doc/vitmatte&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitmatte&quot;},{&quot;title&quot;:&quot;ViTMSN&quot;,&quot;id&quot;:&quot;model_doc/vit_msn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_msn&quot;},{&quot;title&quot;:&quot;ViViT&quot;,&quot;id&quot;:&quot;model_doc/vivit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vivit&quot;},{&quot;title&quot;:&quot;YOLOS&quot;,&quot;id&quot;:&quot;model_doc/yolos&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yolos&quot;}]},{&quot;title&quot;:&quot;Audio models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio Spectrogram Transformer&quot;,&quot;id&quot;:&quot;model_doc/audio-spectrogram-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/audio-spectrogram-transformer&quot;},{&quot;title&quot;:&quot;Bark&quot;,&quot;id&quot;:&quot;model_doc/bark&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bark&quot;},{&quot;title&quot;:&quot;CLAP&quot;,&quot;id&quot;:&quot;model_doc/clap&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clap&quot;},{&quot;title&quot;:&quot;EnCodec&quot;,&quot;id&quot;:&quot;model_doc/encodec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encodec&quot;},{&quot;title&quot;:&quot;Hubert&quot;,&quot;id&quot;:&quot;model_doc/hubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/hubert&quot;},{&quot;title&quot;:&quot;MCTCT&quot;,&quot;id&quot;:&quot;model_doc/mctct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mctct&quot;},{&quot;title&quot;:&quot;MMS&quot;,&quot;id&quot;:&quot;model_doc/mms&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mms&quot;},{&quot;title&quot;:&quot;MusicGen&quot;,&quot;id&quot;:&quot;model_doc/musicgen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/musicgen&quot;},{&quot;title&quot;:&quot;Pop2Piano&quot;,&quot;id&quot;:&quot;model_doc/pop2piano&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pop2piano&quot;},{&quot;title&quot;:&quot;SEW&quot;,&quot;id&quot;:&quot;model_doc/sew&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew&quot;},{&quot;title&quot;:&quot;SEW-D&quot;,&quot;id&quot;:&quot;model_doc/sew-d&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew-d&quot;},{&quot;title&quot;:&quot;Speech2Text&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text&quot;},{&quot;title&quot;:&quot;Speech2Text2&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text_2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text_2&quot;},{&quot;title&quot;:&quot;SpeechT5&quot;,&quot;id&quot;:&quot;model_doc/speecht5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speecht5&quot;},{&quot;title&quot;:&quot;UniSpeech&quot;,&quot;id&quot;:&quot;model_doc/unispeech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech&quot;},{&quot;title&quot;:&quot;UniSpeech-SAT&quot;,&quot;id&quot;:&quot;model_doc/unispeech-sat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech-sat&quot;},{&quot;title&quot;:&quot;VITS&quot;,&quot;id&quot;:&quot;model_doc/vits&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vits&quot;},{&quot;title&quot;:&quot;Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2&quot;},{&quot;title&quot;:&quot;Wav2Vec2-Conformer&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2-conformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2-conformer&quot;},{&quot;title&quot;:&quot;Wav2Vec2Phoneme&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2_phoneme&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2_phoneme&quot;},{&quot;title&quot;:&quot;WavLM&quot;,&quot;id&quot;:&quot;model_doc/wavlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wavlm&quot;},{&quot;title&quot;:&quot;Whisper&quot;,&quot;id&quot;:&quot;model_doc/whisper&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/whisper&quot;},{&quot;title&quot;:&quot;XLS-R&quot;,&quot;id&quot;:&quot;model_doc/xls_r&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xls_r&quot;},{&quot;title&quot;:&quot;XLSR-Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/xlsr_wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlsr_wav2vec2&quot;}]},{&quot;title&quot;:&quot;Multimodal models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALIGN&quot;,&quot;id&quot;:&quot;model_doc/align&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/align&quot;},{&quot;title&quot;:&quot;AltCLIP&quot;,&quot;id&quot;:&quot;model_doc/altclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/altclip&quot;},{&quot;title&quot;:&quot;BLIP&quot;,&quot;id&quot;:&quot;model_doc/blip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip&quot;},{&quot;title&quot;:&quot;BLIP-2&quot;,&quot;id&quot;:&quot;model_doc/blip-2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip-2&quot;},{&quot;title&quot;:&quot;BridgeTower&quot;,&quot;id&quot;:&quot;model_doc/bridgetower&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bridgetower&quot;},{&quot;title&quot;:&quot;BROS&quot;,&quot;id&quot;:&quot;model_doc/bros&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bros&quot;},{&quot;title&quot;:&quot;Chinese-CLIP&quot;,&quot;id&quot;:&quot;model_doc/chinese_clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/chinese_clip&quot;},{&quot;title&quot;:&quot;CLIP&quot;,&quot;id&quot;:&quot;model_doc/clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clip&quot;},{&quot;title&quot;:&quot;CLIPSeg&quot;,&quot;id&quot;:&quot;model_doc/clipseg&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clipseg&quot;},{&quot;title&quot;:&quot;Data2Vec&quot;,&quot;id&quot;:&quot;model_doc/data2vec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/data2vec&quot;},{&quot;title&quot;:&quot;DePlot&quot;,&quot;id&quot;:&quot;model_doc/deplot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deplot&quot;},{&quot;title&quot;:&quot;Donut&quot;,&quot;id&quot;:&quot;model_doc/donut&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/donut&quot;},{&quot;title&quot;:&quot;FLAVA&quot;,&quot;id&quot;:&quot;model_doc/flava&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flava&quot;},{&quot;title&quot;:&quot;GIT&quot;,&quot;id&quot;:&quot;model_doc/git&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/git&quot;},{&quot;title&quot;:&quot;GroupViT&quot;,&quot;id&quot;:&quot;model_doc/groupvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/groupvit&quot;},{&quot;title&quot;:&quot;IDEFICS&quot;,&quot;id&quot;:&quot;model_doc/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/idefics&quot;},{&quot;title&quot;:&quot;InstructBLIP&quot;,&quot;id&quot;:&quot;model_doc/instructblip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/instructblip&quot;},{&quot;title&quot;:&quot;LayoutLM&quot;,&quot;id&quot;:&quot;model_doc/layoutlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlm&quot;},{&quot;title&quot;:&quot;LayoutLMV2&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv2&quot;},{&quot;title&quot;:&quot;LayoutLMV3&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv3&quot;},{&quot;title&quot;:&quot;LayoutXLM&quot;,&quot;id&quot;:&quot;model_doc/layoutxlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutxlm&quot;},{&quot;title&quot;:&quot;LiLT&quot;,&quot;id&quot;:&quot;model_doc/lilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lilt&quot;},{&quot;title&quot;:&quot;LXMERT&quot;,&quot;id&quot;:&quot;model_doc/lxmert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lxmert&quot;},{&quot;title&quot;:&quot;MatCha&quot;,&quot;id&quot;:&quot;model_doc/matcha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/matcha&quot;},{&quot;title&quot;:&quot;MGP-STR&quot;,&quot;id&quot;:&quot;model_doc/mgp-str&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mgp-str&quot;},{&quot;title&quot;:&quot;Nougat&quot;,&quot;id&quot;:&quot;model_doc/nougat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nougat&quot;},{&quot;title&quot;:&quot;OneFormer&quot;,&quot;id&quot;:&quot;model_doc/oneformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/oneformer&quot;},{&quot;title&quot;:&quot;OWL-ViT&quot;,&quot;id&quot;:&quot;model_doc/owlvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/owlvit&quot;},{&quot;title&quot;:&quot;Perceiver&quot;,&quot;id&quot;:&quot;model_doc/perceiver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/perceiver&quot;},{&quot;title&quot;:&quot;Pix2Struct&quot;,&quot;id&quot;:&quot;model_doc/pix2struct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pix2struct&quot;},{&quot;title&quot;:&quot;Segment Anything&quot;,&quot;id&quot;:&quot;model_doc/sam&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sam&quot;},{&quot;title&quot;:&quot;Speech Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/speech-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech-encoder-decoder&quot;},{&quot;title&quot;:&quot;TAPAS&quot;,&quot;id&quot;:&quot;model_doc/tapas&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapas&quot;},{&quot;title&quot;:&quot;TrOCR&quot;,&quot;id&quot;:&quot;model_doc/trocr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trocr&quot;},{&quot;title&quot;:&quot;TVLT&quot;,&quot;id&quot;:&quot;model_doc/tvlt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tvlt&quot;},{&quot;title&quot;:&quot;ViLT&quot;,&quot;id&quot;:&quot;model_doc/vilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vilt&quot;},{&quot;title&quot;:&quot;Vision Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/vision-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-encoder-decoder&quot;},{&quot;title&quot;:&quot;Vision Text Dual Encoder&quot;,&quot;id&quot;:&quot;model_doc/vision-text-dual-encoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-text-dual-encoder&quot;},{&quot;title&quot;:&quot;VisualBERT&quot;,&quot;id&quot;:&quot;model_doc/visual_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/visual_bert&quot;},{&quot;title&quot;:&quot;X-CLIP&quot;,&quot;id&quot;:&quot;model_doc/xclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xclip&quot;}]},{&quot;title&quot;:&quot;Reinforcement learning models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Decision Transformer&quot;,&quot;id&quot;:&quot;model_doc/decision_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/decision_transformer&quot;},{&quot;title&quot;:&quot;Trajectory Transformer&quot;,&quot;id&quot;:&quot;model_doc/trajectory_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trajectory_transformer&quot;}]},{&quot;title&quot;:&quot;Time series models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Autoformer&quot;,&quot;id&quot;:&quot;model_doc/autoformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/autoformer&quot;},{&quot;title&quot;:&quot;Informer&quot;,&quot;id&quot;:&quot;model_doc/informer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/informer&quot;},{&quot;title&quot;:&quot;Time Series Transformer&quot;,&quot;id&quot;:&quot;model_doc/time_series_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/time_series_transformer&quot;}]},{&quot;title&quot;:&quot;Graph models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Graphormer&quot;,&quot;id&quot;:&quot;model_doc/graphormer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/graphormer&quot;}]}]},{&quot;title&quot;:&quot;Internal Helpers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Custom Layers and Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/modeling_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/modeling_utils&quot;},{&quot;title&quot;:&quot;Utilities for pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/pipelines_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/pipelines_utils&quot;},{&quot;title&quot;:&quot;Utilities for Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/tokenization_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/tokenization_utils&quot;},{&quot;title&quot;:&quot;Utilities for Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/trainer_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/trainer_utils&quot;},{&quot;title&quot;:&quot;Utilities for Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/generation_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/generation_utils&quot;},{&quot;title&quot;:&quot;Utilities for Image Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/image_processing_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/image_processing_utils&quot;},{&quot;title&quot;:&quot;Utilities for Audio processing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/audio_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/audio_utils&quot;},{&quot;title&quot;:&quot;General Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/file_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/file_utils&quot;},{&quot;title&quot;:&quot;Utilities for Time Series&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/time_series_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/time_series_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;tasks/object_detection&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;de&quot;,&quot;en&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;ko&quot;,&quot;pt&quot;,&quot;zh&quot;],&quot;library&quot;:&quot;transformers&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v4.34.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v4.34.0&quot;},{&quot;version&quot;:&quot;v4.33.3&quot;},{&quot;version&quot;:&quot;v4.33.2&quot;},{&quot;version&quot;:&quot;v4.33.0&quot;},{&quot;version&quot;:&quot;v4.32.1&quot;},{&quot;version&quot;:&quot;v4.32.0&quot;},{&quot;version&quot;:&quot;v4.31.0&quot;},{&quot;version&quot;:&quot;v4.30.0&quot;},{&quot;version&quot;:&quot;v4.29.1&quot;},{&quot;version&quot;:&quot;v4.29.0&quot;},{&quot;version&quot;:&quot;v4.28.1&quot;},{&quot;version&quot;:&quot;v4.28.0&quot;},{&quot;version&quot;:&quot;v4.27.2&quot;},{&quot;version&quot;:&quot;v4.27.1&quot;},{&quot;version&quot;:&quot;v4.27.0&quot;},{&quot;version&quot;:&quot;v4.26.1&quot;},{&quot;version&quot;:&quot;v4.26.0&quot;},{&quot;version&quot;:&quot;v4.25.1&quot;},{&quot;version&quot;:&quot;v4.24.0&quot;},{&quot;version&quot;:&quot;v4.23.1&quot;},{&quot;version&quot;:&quot;v4.23.0&quot;},{&quot;version&quot;:&quot;v4.22.2&quot;},{&quot;version&quot;:&quot;v4.22.1&quot;},{&quot;version&quot;:&quot;v4.22.0&quot;},{&quot;version&quot;:&quot;v4.21.3&quot;},{&quot;version&quot;:&quot;v4.21.2&quot;},{&quot;version&quot;:&quot;v4.21.1&quot;},{&quot;version&quot;:&quot;v4.21.0&quot;},{&quot;version&quot;:&quot;v4.20.1&quot;},{&quot;version&quot;:&quot;v4.20.0&quot;},{&quot;version&quot;:&quot;v4.19.4&quot;},{&quot;version&quot;:&quot;v4.19.3&quot;},{&quot;version&quot;:&quot;v4.19.2&quot;},{&quot;version&quot;:&quot;v4.19.0&quot;},{&quot;version&quot;:&quot;v4.18.0&quot;},{&quot;version&quot;:&quot;v4.17.0&quot;},{&quot;version&quot;:&quot;v4.16.2&quot;},{&quot;version&quot;:&quot;v4.16.1&quot;},{&quot;version&quot;:&quot;v4.16.0&quot;},{&quot;version&quot;:&quot;v4.15.0&quot;},{&quot;version&quot;:&quot;v4.14.1&quot;},{&quot;version&quot;:&quot;v4.13.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.5&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.4&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.0.0&quot;},{&quot;version&quot;:&quot;doc-builder-html&quot;}],&quot;title&quot;:&quot;Object detection&quot;}\" data-target=\"SideMenu\"> <div class=\"z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false\"><div class=\"shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden\"><div class=\"flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6\"><p class=\"text-sm text-gray-400 first-letter:capitalize\">Transformers documentation</p> <div class=\"flex items-center\"><p class=\"font-semibold\">Object detection</p> <svg class=\"text-xl false\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></div></div> <button class=\"hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2\"><svg class=\"text-gray-500 group-hover:text-gray-700\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg></button></div> <div class=\"hidden h-32 flex-col justify-between border-r border-b bg-white bg-gradient-to-r p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950\"><div class=\"relative \"><button class=\" \" type=\"button\"><h1 class=\"flex items-center text-lg font-bold leading-tight first-letter:capitalize\"><div class=\"mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none\"></div> Transformers <span><svg class=\"opacity-70 \" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></span></h1> </button> </div> <button class=\"shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500\"><svg class=\"flex-none mr-1.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> <div>Search documentation</div> <span class=\"ml-auto rounded border border-gray-200 bg-gray-100 px-0.5 text-xs dark:border-gray-800 dark:bg-gray-800\"><kbd class=\"font-sans\">⌘K</kbd></span></button> <div class=\"flex items-center\"><select class=\"form-input mr-1 !mt-0 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400\"><option value=\"0\">main</option><option value=\"1\">v4.34.0</option><option value=\"2\">v4.33.3</option><option value=\"3\">v4.32.1</option><option value=\"4\">v4.31.0</option><option value=\"5\">v4.30.0</option><option value=\"6\">v4.29.1</option><option value=\"7\">v4.28.1</option><option value=\"8\">v4.27.2</option><option value=\"9\">v4.26.1</option><option value=\"10\">v4.25.1</option><option value=\"11\">v4.24.0</option><option value=\"12\">v4.23.1</option><option value=\"13\">v4.22.2</option><option value=\"14\">v4.21.3</option><option value=\"15\">v4.20.1</option><option value=\"16\">v4.19.4</option><option value=\"17\">v4.18.0</option><option value=\"18\">v4.17.0</option><option value=\"19\">v4.16.2</option><option value=\"20\">v4.15.0</option><option value=\"21\">v4.14.1</option><option value=\"22\">v4.13.0</option><option value=\"23\">v4.12.5</option><option value=\"24\">v4.11.3</option><option value=\"25\">v4.10.1</option><option value=\"26\">v4.9.2</option><option value=\"27\">v4.8.2</option><option value=\"28\">v4.7.0</option><option value=\"29\">v4.6.0</option><option value=\"30\">v4.5.1</option><option value=\"31\">v4.4.2</option><option value=\"32\">v4.3.3</option><option value=\"33\">v4.2.2</option><option value=\"34\">v4.1.1</option><option value=\"35\">v4.0.1</option><option value=\"36\">v3.5.1</option><option value=\"37\">v3.4.0</option><option value=\"38\">v3.3.1</option><option value=\"39\">v3.2.0</option><option value=\"40\">v3.1.0</option><option value=\"41\">v3.0.2</option><option value=\"42\">v2.11.0</option><option value=\"43\">v2.10.0</option><option value=\"44\">v2.9.1</option><option value=\"45\">v2.8.0</option><option value=\"46\">v2.7.0</option><option value=\"47\">v2.6.0</option><option value=\"48\">v2.5.1</option><option value=\"49\">v2.4.1</option><option value=\"50\">v2.3.0</option><option value=\"51\">v2.2.2</option><option value=\"52\">v2.1.1</option><option value=\"53\">v2.0.0</option><option value=\"54\">v1.2.0</option><option value=\"55\">v1.1.0</option><option value=\"56\">v1.0.0</option><option value=\"57\">doc-builder-html</option></select> <select class=\"form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border\"><option value=\"de\">DE</option><option value=\"en\">EN</option><option value=\"es\">ES</option><option value=\"fr\">FR</option><option value=\"it\">IT</option><option value=\"ko\">KO</option><option value=\"pt\">PT</option><option value=\"zh\">ZH</option></select> <div class=\"relative inline-block\"><button class=\"rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 \" type=\"button\"><svg class=\"mr-1.5 text-yellow-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\" fill=\"currentColor\"><path d=\"M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z\"></path></svg>  </button> </div> <a href=\"https://github.com/huggingface/transformers\" class=\"group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300\"><svg class=\"inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1.03em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 250\"><path d=\"M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z\" fill=\"currentColor\"></path></svg> 112,792</a></div></div> <nav class=\"top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pt-3 pb-16 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]\"> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Get started</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/index\">🤗 Transformers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/quicktour\">Quick tour </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/installation\">Installation </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Tutorials</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_tutorial\">Run inference with pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/autoclass_tutorial\">Write portable code with AutoClass </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/preprocessing\">Preprocess data </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/training\">Fine-tune a pretrained model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/run_scripts\">Train with a script </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/accelerate\">Set up distributed training with 🤗 Accelerate </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/peft\">Load and train adapters with 🤗 PEFT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_sharing\">Share your model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/transformers_agents\">Agents </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/llm_tutorial\">Generation with LLMs </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Task Guides</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Natural Language Processing</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Computer Vision</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/image_classification\">Image classification </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/semantic_segmentation\">Semantic segmentation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/video_classification\">Video classification </a><a data-sveltekit-reload=\"\" class=\"rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pr-2 pl-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/object_detection\">Object detection </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection\">Zero-shot object detection </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/zero_shot_image_classification\">Zero-shot image classification </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/tasks/monocular_depth_estimation\">Depth estimation </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Generation</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Prompting</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Developer guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/fast_tokenizers\">Use fast tokenizers from 🤗 Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/multilingual\">Run inference with multilingual models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/create_a_model\">Use model-specific APIs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_models\">Share a custom model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/chat_templating\">Templates for chat models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/sagemaker\">Run training on Amazon SageMaker </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/serialization\">Export to ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tflite\">Export to TFLite </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/torchscript\">Export to TorchScript </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/benchmarks\">Benchmarks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/notebooks\">Notebooks with examples </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/community\">Community resources </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_tools\">Custom Tools and Prompts </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/troubleshooting\">Troubleshoot </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Performance and scalability</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/performance\">Overview </a><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Efficient training techniques</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_one\">Methods and tools for efficient training on a single GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_many\">Multiple GPUs and parallelism </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu\">Efficient training on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu_many\">Distributed CPU training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu\">Training on TPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu_tf\">Training on TPU with TensorFlow </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_special\">Training on Specialized Hardware </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_hardware\">Custom hardware for training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/hpo_train\">Hyperparameter Search using Trainer API </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Optimizing inference</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_cpu\">Inference on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_one\">Inference on one GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_many\">Inference on many GPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_special\">Inference on Specialized Hardware </a> </div><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/big_models\">Instantiating a big model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/debugging\">Troubleshooting </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tf_xla\">XLA Integration for TensorFlow Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perf_torch_compile\">Optimize inference using `torch.compile()` </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Contribute</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/contributing\">How to contribute to transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_model\">How to add a model to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_tensorflow_model\">How to convert a 🤗 Transformers model to TensorFlow? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_pipeline\">How to add a pipeline to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/testing\">Testing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pr_checks\">Checks on a Pull Request </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Conceptual guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/philosophy\">Philosophy </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/glossary\">Glossary </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/task_summary\">What 🤗 Transformers can do </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tasks_explained\">How 🤗 Transformers solve tasks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_summary\">The Transformer model family </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tokenizer_summary\">Summary of the tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/attention\">Attention mechanisms </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pad_truncation\">Padding and truncation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/bertology\">BERTology </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perplexity\">Perplexity of fixed-length models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_webserver\">Pipelines for webserver inference </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_memory_anatomy\">Model training anatomy </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>API</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Main Classes</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/agent\">Agents and Tools </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/model_doc/auto\">Auto Classes </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/callback\">Callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/configuration\">Configuration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/data_collator\">Data Collator </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/keras_callbacks\">Keras callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/logging\">Logging </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/model\">Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/text_generation\">Text Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/onnx\">ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules\">Optimization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/output\">Model outputs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/pipelines\">Pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/processors\">Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/quantization\">Quantization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer\">Tokenizer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/trainer\">Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/deepspeed\">DeepSpeed Integration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/feature_extractor\">Feature Extractor </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/image_processor\">Image Processor </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Models</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Text models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Vision models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Reinforcement learning models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Time series models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Graph models</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Internal Helpers</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/modeling_utils\">Custom Layers and Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/pipelines_utils\">Utilities for pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/tokenization_utils\">Utilities for Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/trainer_utils\">Utilities for Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/generation_utils\">Utilities for Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/image_processing_utils\">Utilities for Image Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/audio_utils\">Utilities for Audio processing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/file_utils\">General Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/time_series_utils\">Utilities for Time Series </a> </div> </div></nav></div></div></div>\\n\\t\\t<div class=\"z-1 min-w-0 flex-1\">\\n\\t\\t\\t<div class=\"px-6 pt-6 md:px-12 md:pt-16 md:pb-16\"><div class=\"max-w-4xl mx-auto mb-10\"><div class=\"relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 py-5 px-4 ring-1 ring-orange-100/70 md:px-6 md:py-8\"><img alt=\"Hugging Face\\'s logo\" class=\"absolute -right-6 -bottom-6 w-28 -rotate-45 md:hidden\" src=\"/front/assets/huggingface_logo-noborder.svg\">\\n\\t\\t<div class=\"mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0\">Join the Hugging Face community</div>\\n\\t\\t<p class=\"mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8\">and get access to the augmented documentation experience\\n\\t\\t</p>\\n\\t\\t<div class=\"mb-8 hidden space-y-4 md:block xl:flex xl:space-y-0 xl:space-x-6\"><div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100\"><svg class=\"text-indigo-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Collaborate on models, datasets and Spaces\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"text-xl text-yellow-400\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M11 15H6l7-14v8h5l-7 14v-8z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Faster examples with accelerated inference\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5\"><svg class=\"text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Switch between documentation themes\\n\\t\\t\\t\\t</div></div></div>\\n\\t\\t<div class=\"flex items-center space-x-2.5\"><a href=\"/join\"><button class=\"rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 py-1.5 px-5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner\">Sign Up</button></a>\\n\\t\\t\\t<p class=\"text-gray-500 dark:text-gray-300\">to get started</p></div></div></div>\\n\\t\\t\\t\\t<div class=\"prose-doc prose relative mx-auto max-w-4xl break-words\"> <p></p> <h1 class=\"relative group\"><a id=\"object-detection\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#object-detection\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-sdfyw1\">Object detection</span></h1> <div class=\"flex space-x-1 absolute z-10 right-0 top-0\"> <div class=\"relative colab-dropdown \"><button class=\"  \" type=\"button\"><img alt=\"Open In Colab\" class=\"!m-0\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></button> </div> <div class=\"relative colab-dropdown \"><button class=\"  \" type=\"button\"><img alt=\"Open In Studio Lab\" class=\"!m-0\" src=\"https://studiolab.sagemaker.aws/studiolab.svg\"></button> </div></div> <p data-svelte-h=\"svelte-18pt6j0\">Object detection is the computer vision task of detecting instances (such as humans, buildings, or cars) in an image. Object detection models receive an image as input and output\\ncoordinates of the bounding boxes and associated labels of the detected objects. An image can contain multiple objects,\\neach with its own bounding box and a label (e.g. it can have a car and a building), and each object can\\nbe present in different parts of an image (e.g. the image can have several cars).\\nThis task is commonly used in autonomous driving for detecting things like pedestrians, road signs, and traffic lights.\\nOther applications include counting objects in images, image search, and more.</p> <p data-svelte-h=\"svelte-1xy9go1\">In this guide, you will learn how to:</p> <ol data-svelte-h=\"svelte-6qcuz8\"><li>Finetune <a href=\"https://huggingface.co/docs/transformers/model_doc/detr\" rel=\"nofollow\">DETR</a>, a model that combines a convolutional\\nbackbone with an encoder-decoder Transformer, on the <a href=\"https://huggingface.co/datasets/cppe-5\" rel=\"nofollow\">CPPE-5</a>\\ndataset.</li> <li>Use your finetuned model for inference.</li></ol> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\">The task illustrated in this tutorial is supported by the following model architectures:\\n\\n<p data-svelte-h=\"svelte-1cb65l9\"><a href=\"../model_doc/conditional_detr\">Conditional DETR</a>, <a href=\"../model_doc/deformable_detr\">Deformable DETR</a>, <a href=\"../model_doc/deta\">DETA</a>, <a href=\"../model_doc/detr\">DETR</a>, <a href=\"../model_doc/table-transformer\">Table Transformer</a>, <a href=\"../model_doc/yolos\">YOLOS</a></p></div> <p data-svelte-h=\"svelte-1c9nexd\">Before you begin, make sure you have all the necessary libraries installed:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\">pip install -q datasets transformers evaluate timm albumentations</pre></div> <p data-svelte-h=\"svelte-8eui7r\">You’ll use 🤗 Datasets to load a dataset from the Hugging Face Hub, 🤗 Transformers to train your model,\\nand <code>albumentations</code> to augment the data. <code>timm</code> is currently required to load a convolutional backbone for the DETR model.</p> <p data-svelte-h=\"svelte-1oee7b1\">We encourage you to share your model with the community. Log in to your Hugging Face account to upload it to the Hub.\\nWhen prompted, enter your token to log in:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> huggingface_hub <span class=\"hljs-keyword\">import</span> notebook_login\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>notebook_login()</pre></div> <h2 class=\"relative group\"><a id=\"load-the-cppe5-dataset\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#load-the-cppe5-dataset\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-mdnhj4\">Load the CPPE-5 dataset</span></h2> <p data-svelte-h=\"svelte-9es7uf\">The <a href=\"https://huggingface.co/datasets/cppe-5\" rel=\"nofollow\">CPPE-5 dataset</a> contains images with\\nannotations identifying medical personal protective equipment (PPE) in the context of the COVID-19 pandemic.</p> <p data-svelte-h=\"svelte-kvqzlo\">Start by loading the dataset:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>cppe5 = load_dataset(<span class=\"hljs-string\">\"cppe-5\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>cppe5\\nDatasetDict({\\n    train: Dataset({\\n        features: [<span class=\"hljs-string\">\\'image_id\\'</span>, <span class=\"hljs-string\">\\'image\\'</span>, <span class=\"hljs-string\">\\'width\\'</span>, <span class=\"hljs-string\">\\'height\\'</span>, <span class=\"hljs-string\">\\'objects\\'</span>],\\n        num_rows: <span class=\"hljs-number\">1000</span>\\n    })\\n    test: Dataset({\\n        features: [<span class=\"hljs-string\">\\'image_id\\'</span>, <span class=\"hljs-string\">\\'image\\'</span>, <span class=\"hljs-string\">\\'width\\'</span>, <span class=\"hljs-string\">\\'height\\'</span>, <span class=\"hljs-string\">\\'objects\\'</span>],\\n        num_rows: <span class=\"hljs-number\">29</span>\\n    })\\n})</pre></div> <p data-svelte-h=\"svelte-1f9ettc\">You’ll see that this dataset already comes with a training set containing 1000 images and a test set with 29 images.</p> <p data-svelte-h=\"svelte-4bevpw\">To get familiar with the data, explore what the examples look like.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span>cppe5[<span class=\"hljs-string\">\"train\"</span>][<span class=\"hljs-number\">0</span>]\\n{<span class=\"hljs-string\">\\'image_id\\'</span>: <span class=\"hljs-number\">15</span>,\\n <span class=\"hljs-string\">\\'image\\'</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=943x663 at <span class=\"hljs-number\">0x7F9EC9E77C10</span>&gt;,\\n <span class=\"hljs-string\">\\'width\\'</span>: <span class=\"hljs-number\">943</span>,\\n <span class=\"hljs-string\">\\'height\\'</span>: <span class=\"hljs-number\">663</span>,\\n <span class=\"hljs-string\">\\'objects\\'</span>: {<span class=\"hljs-string\">\\'id\\'</span>: [<span class=\"hljs-number\">114</span>, <span class=\"hljs-number\">115</span>, <span class=\"hljs-number\">116</span>, <span class=\"hljs-number\">117</span>],\\n  <span class=\"hljs-string\">\\'area\\'</span>: [<span class=\"hljs-number\">3796</span>, <span class=\"hljs-number\">1596</span>, <span class=\"hljs-number\">152768</span>, <span class=\"hljs-number\">81002</span>],\\n  <span class=\"hljs-string\">\\'bbox\\'</span>: [[<span class=\"hljs-number\">302.0</span>, <span class=\"hljs-number\">109.0</span>, <span class=\"hljs-number\">73.0</span>, <span class=\"hljs-number\">52.0</span>],\\n   [<span class=\"hljs-number\">810.0</span>, <span class=\"hljs-number\">100.0</span>, <span class=\"hljs-number\">57.0</span>, <span class=\"hljs-number\">28.0</span>],\\n   [<span class=\"hljs-number\">160.0</span>, <span class=\"hljs-number\">31.0</span>, <span class=\"hljs-number\">248.0</span>, <span class=\"hljs-number\">616.0</span>],\\n   [<span class=\"hljs-number\">741.0</span>, <span class=\"hljs-number\">68.0</span>, <span class=\"hljs-number\">202.0</span>, <span class=\"hljs-number\">401.0</span>]],\\n  <span class=\"hljs-string\">\\'category\\'</span>: [<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>]}}</pre></div> <p data-svelte-h=\"svelte-m0t76z\">The examples in the dataset have the following fields:</p> <ul data-svelte-h=\"svelte-1tn0avh\"><li><code>image_id</code>: the example image id</li> <li><code>image</code>: a <code>PIL.Image.Image</code> object containing the image</li> <li><code>width</code>: width of the image</li> <li><code>height</code>: height of the image</li> <li><code>objects</code>: a dictionary containing bounding box metadata for the objects in the image:<ul><li><code>id</code>: the annotation id</li> <li><code>area</code>: the area of the bounding box</li> <li><code>bbox</code>: the object’s bounding box (in the <a href=\"https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/#coco\" rel=\"nofollow\">COCO format</a> )</li> <li><code>category</code>: the object’s category, with possible values including <code>Coverall (0)</code>, <code>Face_Shield (1)</code>, <code>Gloves (2)</code>, <code>Goggles (3)</code> and <code>Mask (4)</code></li></ul></li></ul> <p data-svelte-h=\"svelte-edp0uk\">You may notice that the <code>bbox</code> field follows the COCO format, which is the format that the DETR model expects.\\nHowever, the grouping of the fields inside <code>objects</code> differs from the annotation format DETR requires. You will\\nneed to apply some preprocessing transformations before using this data for training.</p> <p data-svelte-h=\"svelte-1o4zzv7\">To get an even better understanding of the data, visualize an example in the dataset.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> os\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\">import</span> Image, ImageDraw\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image = cppe5[<span class=\"hljs-string\">\"train\"</span>][<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">\"image\"</span>]\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>annotations = cppe5[<span class=\"hljs-string\">\"train\"</span>][<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">\"objects\"</span>]\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>draw = ImageDraw.Draw(image)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>categories = cppe5[<span class=\"hljs-string\">\"train\"</span>].features[<span class=\"hljs-string\">\"objects\"</span>].feature[<span class=\"hljs-string\">\"category\"</span>].names\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>id2label = {index: x <span class=\"hljs-keyword\">for</span> index, x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(categories, start=<span class=\"hljs-number\">0</span>)}\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>label2id = {v: k <span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> id2label.items()}\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(annotations[<span class=\"hljs-string\">\"id\"</span>])):\\n<span class=\"hljs-meta\">... </span>    box = annotations[<span class=\"hljs-string\">\"bbox\"</span>][i]\\n<span class=\"hljs-meta\">... </span>    class_idx = annotations[<span class=\"hljs-string\">\"category\"</span>][i]\\n<span class=\"hljs-meta\">... </span>    x, y, w, h = <span class=\"hljs-built_in\">tuple</span>(box)\\n<span class=\"hljs-meta\">... </span>    draw.rectangle((x, y, x + w, y + h), outline=<span class=\"hljs-string\">\"red\"</span>, width=<span class=\"hljs-number\">1</span>)\\n<span class=\"hljs-meta\">... </span>    draw.text((x, y), id2label[class_idx], fill=<span class=\"hljs-string\">\"white\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image</pre></div> <div class=\"flex justify-center\" data-svelte-h=\"svelte-1mkaz8h\"><img src=\"https://i.imgur.com/TdaqPJO.png\" alt=\"CPPE-5 Image Example\"></div> <p data-svelte-h=\"svelte-8e05io\">To visualize the bounding boxes with associated labels, you can get the labels from the dataset’s metadata, specifically\\nthe <code>category</code> field.\\nYou’ll also want to create dictionaries that map a label id to a label class (<code>id2label</code>) and the other way around (<code>label2id</code>).\\nYou can use them later when setting up the model. Including these maps will make your model reusable by others if you share\\nit on the Hugging Face Hub.</p> <p data-svelte-h=\"svelte-34dvp0\">As a final step of getting familiar with the data, explore it for potential issues. One common problem with datasets for\\nobject detection is bounding boxes that “stretch” beyond the edge of the image. Such “runaway” bounding boxes can raise\\nerrors during training and should be addressed at this stage. There are a few examples with this issue in this dataset.\\nTo keep things simple in this guide, we remove these images from the data.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span>remove_idx = [<span class=\"hljs-number\">590</span>, <span class=\"hljs-number\">821</span>, <span class=\"hljs-number\">822</span>, <span class=\"hljs-number\">875</span>, <span class=\"hljs-number\">876</span>, <span class=\"hljs-number\">878</span>, <span class=\"hljs-number\">879</span>]\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>keep = [i <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(cppe5[<span class=\"hljs-string\">\"train\"</span>])) <span class=\"hljs-keyword\">if</span> i <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> remove_idx]\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>cppe5[<span class=\"hljs-string\">\"train\"</span>] = cppe5[<span class=\"hljs-string\">\"train\"</span>].select(keep)</pre></div> <h2 class=\"relative group\"><a id=\"preprocess-the-data\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#preprocess-the-data\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-171xy48\">Preprocess the data</span></h2> <p data-svelte-h=\"svelte-5a7bjj\">To finetune a model, you must preprocess the data you plan to use to match precisely the approach used for the pre-trained model.\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoImageProcessor\">AutoImageProcessor</a> takes care of processing image data to create <code>pixel_values</code>, <code>pixel_mask</code>, and\\n<code>labels</code> that a DETR model can train with. The image processor has some attributes that you won’t have to worry about:</p> <ul data-svelte-h=\"svelte-9xz2l6\"><li><code>image_mean = [0.485, 0.456, 0.406 ]</code></li> <li><code>image_std = [0.229, 0.224, 0.225]</code></li></ul> <p data-svelte-h=\"svelte-1uiy3io\">These are the mean and standard deviation used to normalize images during the model pre-training. These values are crucial\\nto replicate when doing inference or finetuning a pre-trained image model.</p> <p data-svelte-h=\"svelte-1ipxopl\">Instantiate the image processor from the same checkpoint as the model you want to finetune.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoImageProcessor\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>checkpoint = <span class=\"hljs-string\">\"facebook/detr-resnet-50\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(checkpoint)</pre></div> <p data-svelte-h=\"svelte-16qnm9y\">Before passing the images to the <code>image_processor</code>, apply two preprocessing transformations to the dataset:</p> <ul data-svelte-h=\"svelte-pqfhzt\"><li>Augmenting images</li> <li>Reformatting annotations to meet DETR expectations</li></ul> <p data-svelte-h=\"svelte-1p8vci\">First, to make sure the model does not overfit on the training data, you can apply image augmentation with any data augmentation library. Here we use <a href=\"https://albumentations.ai/docs/\" rel=\"nofollow\">Albumentations</a> …\\nThis library ensures that transformations affect the image and update the bounding boxes accordingly.\\nThe 🤗 Datasets library documentation has a detailed <a href=\"https://huggingface.co/docs/datasets/object_detection\" rel=\"nofollow\">guide on how to augment images for object detection</a>,\\nand it uses the exact same dataset as an example. Apply the same approach here, resize each image to (480, 480),\\nflip it horizontally, and brighten it:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> albumentations\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> torch\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>transform = albumentations.Compose(\\n<span class=\"hljs-meta\">... </span>    [\\n<span class=\"hljs-meta\">... </span>        albumentations.Resize(<span class=\"hljs-number\">480</span>, <span class=\"hljs-number\">480</span>),\\n<span class=\"hljs-meta\">... </span>        albumentations.HorizontalFlip(p=<span class=\"hljs-number\">1.0</span>),\\n<span class=\"hljs-meta\">... </span>        albumentations.RandomBrightnessContrast(p=<span class=\"hljs-number\">1.0</span>),\\n<span class=\"hljs-meta\">... </span>    ],\\n<span class=\"hljs-meta\">... </span>    bbox_params=albumentations.BboxParams(<span class=\"hljs-built_in\">format</span>=<span class=\"hljs-string\">\"coco\"</span>, label_fields=[<span class=\"hljs-string\">\"category\"</span>]),\\n<span class=\"hljs-meta\">... </span>)</pre></div> <p data-svelte-h=\"svelte-bsjzql\">The <code>image_processor</code> expects the annotations to be in the following format: <code>{\\'image_id\\': int, \\'annotations\\': List[Dict]}</code>,\\nwhere each dictionary is a COCO object annotation. Let’s add a function to reformat annotations for a single example:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">formatted_anns</span>(<span class=\"hljs-params\">image_id, category, area, bbox</span>):\\n<span class=\"hljs-meta\">... </span>    annotations = []\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(category)):\\n<span class=\"hljs-meta\">... </span>        new_ann = {\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"image_id\"</span>: image_id,\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"category_id\"</span>: category[i],\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"isCrowd\"</span>: <span class=\"hljs-number\">0</span>,\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"area\"</span>: area[i],\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"bbox\"</span>: <span class=\"hljs-built_in\">list</span>(bbox[i]),\\n<span class=\"hljs-meta\">... </span>        }\\n<span class=\"hljs-meta\">... </span>        annotations.append(new_ann)\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">return</span> annotations</pre></div> <p data-svelte-h=\"svelte-16yruro\">Now you can combine the image and annotation transformations to use on a batch of examples:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># transforming a batch</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">transform_aug_ann</span>(<span class=\"hljs-params\">examples</span>):\\n<span class=\"hljs-meta\">... </span>    image_ids = examples[<span class=\"hljs-string\">\"image_id\"</span>]\\n<span class=\"hljs-meta\">... </span>    images, bboxes, area, categories = [], [], [], []\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">for</span> image, objects <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(examples[<span class=\"hljs-string\">\"image\"</span>], examples[<span class=\"hljs-string\">\"objects\"</span>]):\\n<span class=\"hljs-meta\">... </span>        image = np.array(image.convert(<span class=\"hljs-string\">\"RGB\"</span>))[:, :, ::-<span class=\"hljs-number\">1</span>]\\n<span class=\"hljs-meta\">... </span>        out = transform(image=image, bboxes=objects[<span class=\"hljs-string\">\"bbox\"</span>], category=objects[<span class=\"hljs-string\">\"category\"</span>])\\n\\n<span class=\"hljs-meta\">... </span>        area.append(objects[<span class=\"hljs-string\">\"area\"</span>])\\n<span class=\"hljs-meta\">... </span>        images.append(out[<span class=\"hljs-string\">\"image\"</span>])\\n<span class=\"hljs-meta\">... </span>        bboxes.append(out[<span class=\"hljs-string\">\"bboxes\"</span>])\\n<span class=\"hljs-meta\">... </span>        categories.append(out[<span class=\"hljs-string\">\"category\"</span>])\\n\\n<span class=\"hljs-meta\">... </span>    targets = [\\n<span class=\"hljs-meta\">... </span>        {<span class=\"hljs-string\">\"image_id\"</span>: id_, <span class=\"hljs-string\">\"annotations\"</span>: formatted_anns(id_, cat_, ar_, box_)}\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-keyword\">for</span> id_, cat_, ar_, box_ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(image_ids, categories, area, bboxes)\\n<span class=\"hljs-meta\">... </span>    ]\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">return</span> image_processor(images=images, annotations=targets, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)</pre></div> <p data-svelte-h=\"svelte-gc4auf\">Apply this preprocessing function to the entire dataset using 🤗 Datasets <a href=\"https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes#datasets.Dataset.with_transform\" rel=\"nofollow\">with_transform</a> method. This method applies\\ntransformations on the fly when you load an element of the dataset.</p> <p data-svelte-h=\"svelte-1o4lbgk\">At this point, you can check what an example from the dataset looks like after the transformations. You should see a tensor\\nwith <code>pixel_values</code>, a tensor with <code>pixel_mask</code>, and <code>labels</code>.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span>cppe5[<span class=\"hljs-string\">\"train\"</span>] = cppe5[<span class=\"hljs-string\">\"train\"</span>].with_transform(transform_aug_ann)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>cppe5[<span class=\"hljs-string\">\"train\"</span>][<span class=\"hljs-number\">15</span>]\\n{<span class=\"hljs-string\">\\'pixel_values\\'</span>: tensor([[[ <span class=\"hljs-number\">0.9132</span>,  <span class=\"hljs-number\">0.9132</span>,  <span class=\"hljs-number\">0.9132</span>,  ..., -<span class=\"hljs-number\">1.9809</span>, -<span class=\"hljs-number\">1.9809</span>, -<span class=\"hljs-number\">1.9809</span>],\\n          [ <span class=\"hljs-number\">0.9132</span>,  <span class=\"hljs-number\">0.9132</span>,  <span class=\"hljs-number\">0.9132</span>,  ..., -<span class=\"hljs-number\">1.9809</span>, -<span class=\"hljs-number\">1.9809</span>, -<span class=\"hljs-number\">1.9809</span>],\\n          [ <span class=\"hljs-number\">0.9132</span>,  <span class=\"hljs-number\">0.9132</span>,  <span class=\"hljs-number\">0.9132</span>,  ..., -<span class=\"hljs-number\">1.9638</span>, -<span class=\"hljs-number\">1.9638</span>, -<span class=\"hljs-number\">1.9638</span>],\\n          ...,\\n          [-<span class=\"hljs-number\">1.5699</span>, -<span class=\"hljs-number\">1.5699</span>, -<span class=\"hljs-number\">1.5699</span>,  ..., -<span class=\"hljs-number\">1.9980</span>, -<span class=\"hljs-number\">1.9980</span>, -<span class=\"hljs-number\">1.9980</span>],\\n          [-<span class=\"hljs-number\">1.5528</span>, -<span class=\"hljs-number\">1.5528</span>, -<span class=\"hljs-number\">1.5528</span>,  ..., -<span class=\"hljs-number\">1.9980</span>, -<span class=\"hljs-number\">1.9809</span>, -<span class=\"hljs-number\">1.9809</span>],\\n          [-<span class=\"hljs-number\">1.5528</span>, -<span class=\"hljs-number\">1.5528</span>, -<span class=\"hljs-number\">1.5528</span>,  ..., -<span class=\"hljs-number\">1.9980</span>, -<span class=\"hljs-number\">1.9809</span>, -<span class=\"hljs-number\">1.9809</span>]],\\n\\n         [[ <span class=\"hljs-number\">1.3081</span>,  <span class=\"hljs-number\">1.3081</span>,  <span class=\"hljs-number\">1.3081</span>,  ..., -<span class=\"hljs-number\">1.8431</span>, -<span class=\"hljs-number\">1.8431</span>, -<span class=\"hljs-number\">1.8431</span>],\\n          [ <span class=\"hljs-number\">1.3081</span>,  <span class=\"hljs-number\">1.3081</span>,  <span class=\"hljs-number\">1.3081</span>,  ..., -<span class=\"hljs-number\">1.8431</span>, -<span class=\"hljs-number\">1.8431</span>, -<span class=\"hljs-number\">1.8431</span>],\\n          [ <span class=\"hljs-number\">1.3081</span>,  <span class=\"hljs-number\">1.3081</span>,  <span class=\"hljs-number\">1.3081</span>,  ..., -<span class=\"hljs-number\">1.8256</span>, -<span class=\"hljs-number\">1.8256</span>, -<span class=\"hljs-number\">1.8256</span>],\\n          ...,\\n          [-<span class=\"hljs-number\">1.3179</span>, -<span class=\"hljs-number\">1.3179</span>, -<span class=\"hljs-number\">1.3179</span>,  ..., -<span class=\"hljs-number\">1.8606</span>, -<span class=\"hljs-number\">1.8606</span>, -<span class=\"hljs-number\">1.8606</span>],\\n          [-<span class=\"hljs-number\">1.3004</span>, -<span class=\"hljs-number\">1.3004</span>, -<span class=\"hljs-number\">1.3004</span>,  ..., -<span class=\"hljs-number\">1.8606</span>, -<span class=\"hljs-number\">1.8431</span>, -<span class=\"hljs-number\">1.8431</span>],\\n          [-<span class=\"hljs-number\">1.3004</span>, -<span class=\"hljs-number\">1.3004</span>, -<span class=\"hljs-number\">1.3004</span>,  ..., -<span class=\"hljs-number\">1.8606</span>, -<span class=\"hljs-number\">1.8431</span>, -<span class=\"hljs-number\">1.8431</span>]],\\n\\n         [[ <span class=\"hljs-number\">1.4200</span>,  <span class=\"hljs-number\">1.4200</span>,  <span class=\"hljs-number\">1.4200</span>,  ..., -<span class=\"hljs-number\">1.6476</span>, -<span class=\"hljs-number\">1.6476</span>, -<span class=\"hljs-number\">1.6476</span>],\\n          [ <span class=\"hljs-number\">1.4200</span>,  <span class=\"hljs-number\">1.4200</span>,  <span class=\"hljs-number\">1.4200</span>,  ..., -<span class=\"hljs-number\">1.6476</span>, -<span class=\"hljs-number\">1.6476</span>, -<span class=\"hljs-number\">1.6476</span>],\\n          [ <span class=\"hljs-number\">1.4200</span>,  <span class=\"hljs-number\">1.4200</span>,  <span class=\"hljs-number\">1.4200</span>,  ..., -<span class=\"hljs-number\">1.6302</span>, -<span class=\"hljs-number\">1.6302</span>, -<span class=\"hljs-number\">1.6302</span>],\\n          ...,\\n          [-<span class=\"hljs-number\">1.0201</span>, -<span class=\"hljs-number\">1.0201</span>, -<span class=\"hljs-number\">1.0201</span>,  ..., -<span class=\"hljs-number\">1.5604</span>, -<span class=\"hljs-number\">1.5604</span>, -<span class=\"hljs-number\">1.5604</span>],\\n          [-<span class=\"hljs-number\">1.0027</span>, -<span class=\"hljs-number\">1.0027</span>, -<span class=\"hljs-number\">1.0027</span>,  ..., -<span class=\"hljs-number\">1.5604</span>, -<span class=\"hljs-number\">1.5430</span>, -<span class=\"hljs-number\">1.5430</span>],\\n          [-<span class=\"hljs-number\">1.0027</span>, -<span class=\"hljs-number\">1.0027</span>, -<span class=\"hljs-number\">1.0027</span>,  ..., -<span class=\"hljs-number\">1.5604</span>, -<span class=\"hljs-number\">1.5430</span>, -<span class=\"hljs-number\">1.5430</span>]]]),\\n <span class=\"hljs-string\">\\'pixel_mask\\'</span>: tensor([[<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,  ..., <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>],\\n         [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,  ..., <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>],\\n         [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,  ..., <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>],\\n         ...,\\n         [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,  ..., <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>],\\n         [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,  ..., <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>],\\n         [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,  ..., <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>]]),\\n <span class=\"hljs-string\">\\'labels\\'</span>: {<span class=\"hljs-string\">\\'size\\'</span>: tensor([<span class=\"hljs-number\">800</span>, <span class=\"hljs-number\">800</span>]), <span class=\"hljs-string\">\\'image_id\\'</span>: tensor([<span class=\"hljs-number\">756</span>]), <span class=\"hljs-string\">\\'class_labels\\'</span>: tensor([<span class=\"hljs-number\">4</span>]), <span class=\"hljs-string\">\\'boxes\\'</span>: tensor([[<span class=\"hljs-number\">0.7340</span>, <span class=\"hljs-number\">0.6986</span>, <span class=\"hljs-number\">0.3414</span>, <span class=\"hljs-number\">0.5944</span>]]), <span class=\"hljs-string\">\\'area\\'</span>: tensor([<span class=\"hljs-number\">519544.4375</span>]), <span class=\"hljs-string\">\\'iscrowd\\'</span>: tensor([<span class=\"hljs-number\">0</span>]), <span class=\"hljs-string\">\\'orig_size\\'</span>: tensor([<span class=\"hljs-number\">480</span>, <span class=\"hljs-number\">480</span>])}}</pre></div> <p data-svelte-h=\"svelte-1ghsv74\">You have successfully augmented the individual images and prepared their annotations. However, preprocessing isn’t\\ncomplete yet. In the final step, create a custom <code>collate_fn</code> to batch images together.\\nPad images (which are now <code>pixel_values</code>) to the largest image in a batch, and create a corresponding <code>pixel_mask</code>\\nto indicate which pixels are real (1) and which are padding (0).</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">collate_fn</span>(<span class=\"hljs-params\">batch</span>):\\n<span class=\"hljs-meta\">... </span>    pixel_values = [item[<span class=\"hljs-string\">\"pixel_values\"</span>] <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> batch]\\n<span class=\"hljs-meta\">... </span>    encoding = image_processor.pad(pixel_values, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n<span class=\"hljs-meta\">... </span>    labels = [item[<span class=\"hljs-string\">\"labels\"</span>] <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> batch]\\n<span class=\"hljs-meta\">... </span>    batch = {}\\n<span class=\"hljs-meta\">... </span>    batch[<span class=\"hljs-string\">\"pixel_values\"</span>] = encoding[<span class=\"hljs-string\">\"pixel_values\"</span>]\\n<span class=\"hljs-meta\">... </span>    batch[<span class=\"hljs-string\">\"pixel_mask\"</span>] = encoding[<span class=\"hljs-string\">\"pixel_mask\"</span>]\\n<span class=\"hljs-meta\">... </span>    batch[<span class=\"hljs-string\">\"labels\"</span>] = labels\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">return</span> batch</pre></div> <h2 class=\"relative group\"><a id=\"training-the-detr-model\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#training-the-detr-model\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-pihf6o\">Training the DETR model</span></h2>\\n\\n\\nYou have done most of the heavy lifting in the previous sections, so now you are ready to train your model!\\nThe images in this dataset are still quite large, even after resizing. This means that finetuning this model will\\nrequire at least one GPU.\\n<p data-svelte-h=\"svelte-qp7n2l\">Training involves the following steps:</p> <ol data-svelte-h=\"svelte-pn8cxf\"><li>Load the model with <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoModelForObjectDetection\">AutoModelForObjectDetection</a> using the same checkpoint as in the preprocessing.</li> <li>Define your training hyperparameters in <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments\">TrainingArguments</a>.</li> <li>Pass the training arguments to <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer\">Trainer</a> along with the model, dataset, image processor, and data collator.</li> <li>Call <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer.train\">train()</a> to finetune your model.</li></ol> <p data-svelte-h=\"svelte-3tgt16\">When loading the model from the same checkpoint that you used for the preprocessing, remember to pass the <code>label2id</code>\\nand <code>id2label</code> maps that you created earlier from the dataset’s metadata. Additionally, we specify <code>ignore_mismatched_sizes=True</code> to replace the existing classification head with a new one.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForObjectDetection\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(\\n<span class=\"hljs-meta\">... </span>    checkpoint,\\n<span class=\"hljs-meta\">... </span>    id2label=id2label,\\n<span class=\"hljs-meta\">... </span>    label2id=label2id,\\n<span class=\"hljs-meta\">... </span>    ignore_mismatched_sizes=<span class=\"hljs-literal\">True</span>,\\n<span class=\"hljs-meta\">... </span>)</pre></div> <p data-svelte-h=\"svelte-6fy4ua\">In the <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments\">TrainingArguments</a> use <code>output_dir</code> to specify where to save your model, then configure hyperparameters as you see fit.\\nIt is important you do not remove unused columns because this will drop the image column. Without the image column, you\\ncan’t create <code>pixel_values</code>. For this reason, set <code>remove_unused_columns</code> to <code>False</code>.\\nIf you wish to share your model by pushing to the Hub, set <code>push_to_hub</code> to <code>True</code> (you must be signed in to Hugging\\nFace to upload your model).</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> TrainingArguments\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>training_args = TrainingArguments(\\n<span class=\"hljs-meta\">... </span>    output_dir=<span class=\"hljs-string\">\"detr-resnet-50_finetuned_cppe5\"</span>,\\n<span class=\"hljs-meta\">... </span>    per_device_train_batch_size=<span class=\"hljs-number\">8</span>,\\n<span class=\"hljs-meta\">... </span>    num_train_epochs=<span class=\"hljs-number\">10</span>,\\n<span class=\"hljs-meta\">... </span>    fp16=<span class=\"hljs-literal\">True</span>,\\n<span class=\"hljs-meta\">... </span>    save_steps=<span class=\"hljs-number\">200</span>,\\n<span class=\"hljs-meta\">... </span>    logging_steps=<span class=\"hljs-number\">50</span>,\\n<span class=\"hljs-meta\">... </span>    learning_rate=<span class=\"hljs-number\">1e-5</span>,\\n<span class=\"hljs-meta\">... </span>    weight_decay=<span class=\"hljs-number\">1e-4</span>,\\n<span class=\"hljs-meta\">... </span>    save_total_limit=<span class=\"hljs-number\">2</span>,\\n<span class=\"hljs-meta\">... </span>    remove_unused_columns=<span class=\"hljs-literal\">False</span>,\\n<span class=\"hljs-meta\">... </span>    push_to_hub=<span class=\"hljs-literal\">True</span>,\\n<span class=\"hljs-meta\">... </span>)</pre></div> <p data-svelte-h=\"svelte-1990uzx\">Finally, bring everything together, and call <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer.train\">train()</a>:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> Trainer\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>trainer = Trainer(\\n<span class=\"hljs-meta\">... </span>    model=model,\\n<span class=\"hljs-meta\">... </span>    args=training_args,\\n<span class=\"hljs-meta\">... </span>    data_collator=collate_fn,\\n<span class=\"hljs-meta\">... </span>    train_dataset=cppe5[<span class=\"hljs-string\">\"train\"</span>],\\n<span class=\"hljs-meta\">... </span>    tokenizer=image_processor,\\n<span class=\"hljs-meta\">... </span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>trainer.train()</pre></div> <p data-svelte-h=\"svelte-7n417q\">If you have set <code>push_to_hub</code> to <code>True</code> in the <code>training_args</code>, the training checkpoints are pushed to the\\nHugging Face Hub. Upon training completion, push the final model to the Hub as well by calling the <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer.push_to_hub\">push_to_hub()</a> method.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span>trainer.push_to_hub()</pre></div> <h2 class=\"relative group\"><a id=\"evaluate\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#evaluate\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-sh8s6s\">Evaluate</span></h2>\\n\\n\\nObject detection models are commonly evaluated with a set of <a href=\"https://cocodataset.org/#detection-eval\" data-svelte-h=\"svelte-6plsj8\">COCO-style metrics</a>.\\nYou can use one of the existing metrics implementations, but here you\\'ll use the one from `torchvision` to evaluate the final\\nmodel that you pushed to the Hub.\\n<p data-svelte-h=\"svelte-1gyi24o\">To use the <code>torchvision</code> evaluator, you’ll need to prepare a ground truth COCO dataset. The API to build a COCO dataset\\nrequires the data to be stored in a certain format, so you’ll need to save images and annotations to disk first. Just like\\nwhen you prepared your data for training, the annotations from the <code>cppe5[\"test\"]</code> need to be formatted. However, images\\nshould stay as they are.</p> <p data-svelte-h=\"svelte-1egi90u\">The evaluation step requires a bit of work, but it can be split in three major steps.\\nFirst, prepare the <code>cppe5[\"test\"]</code> set: format the annotations and save the data to disk.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> json\\n\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># format annotations the same as for training, no need for data augmentation</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">val_formatted_anns</span>(<span class=\"hljs-params\">image_id, objects</span>):\\n<span class=\"hljs-meta\">... </span>    annotations = []\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(objects[<span class=\"hljs-string\">\"id\"</span>])):\\n<span class=\"hljs-meta\">... </span>        new_ann = {\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"id\"</span>: objects[<span class=\"hljs-string\">\"id\"</span>][i],\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"category_id\"</span>: objects[<span class=\"hljs-string\">\"category\"</span>][i],\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"iscrowd\"</span>: <span class=\"hljs-number\">0</span>,\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"image_id\"</span>: image_id,\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"area\"</span>: objects[<span class=\"hljs-string\">\"area\"</span>][i],\\n<span class=\"hljs-meta\">... </span>            <span class=\"hljs-string\">\"bbox\"</span>: objects[<span class=\"hljs-string\">\"bbox\"</span>][i],\\n<span class=\"hljs-meta\">... </span>        }\\n<span class=\"hljs-meta\">... </span>        annotations.append(new_ann)\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">return</span> annotations\\n\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># Save images and annotations into the files torchvision.datasets.CocoDetection expects</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">save_cppe5_annotation_file_images</span>(<span class=\"hljs-params\">cppe5</span>):\\n<span class=\"hljs-meta\">... </span>    output_json = {}\\n<span class=\"hljs-meta\">... </span>    path_output_cppe5 = <span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{os.getcwd()}</span>/cppe5/\"</span>\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(path_output_cppe5):\\n<span class=\"hljs-meta\">... </span>        os.makedirs(path_output_cppe5)\\n\\n<span class=\"hljs-meta\">... </span>    path_anno = os.path.join(path_output_cppe5, <span class=\"hljs-string\">\"cppe5_ann.json\"</span>)\\n<span class=\"hljs-meta\">... </span>    categories_json = [{<span class=\"hljs-string\">\"supercategory\"</span>: <span class=\"hljs-string\">\"none\"</span>, <span class=\"hljs-string\">\"id\"</span>: <span class=\"hljs-built_in\">id</span>, <span class=\"hljs-string\">\"name\"</span>: id2label[<span class=\"hljs-built_in\">id</span>]} <span class=\"hljs-keyword\">for</span> <span class=\"hljs-built_in\">id</span> <span class=\"hljs-keyword\">in</span> id2label]\\n<span class=\"hljs-meta\">... </span>    output_json[<span class=\"hljs-string\">\"images\"</span>] = []\\n<span class=\"hljs-meta\">... </span>    output_json[<span class=\"hljs-string\">\"annotations\"</span>] = []\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">for</span> example <span class=\"hljs-keyword\">in</span> cppe5:\\n<span class=\"hljs-meta\">... </span>        ann = val_formatted_anns(example[<span class=\"hljs-string\">\"image_id\"</span>], example[<span class=\"hljs-string\">\"objects\"</span>])\\n<span class=\"hljs-meta\">... </span>        output_json[<span class=\"hljs-string\">\"images\"</span>].append(\\n<span class=\"hljs-meta\">... </span>            {\\n<span class=\"hljs-meta\">... </span>                <span class=\"hljs-string\">\"id\"</span>: example[<span class=\"hljs-string\">\"image_id\"</span>],\\n<span class=\"hljs-meta\">... </span>                <span class=\"hljs-string\">\"width\"</span>: example[<span class=\"hljs-string\">\"image\"</span>].width,\\n<span class=\"hljs-meta\">... </span>                <span class=\"hljs-string\">\"height\"</span>: example[<span class=\"hljs-string\">\"image\"</span>].height,\\n<span class=\"hljs-meta\">... </span>                <span class=\"hljs-string\">\"file_name\"</span>: <span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{example[<span class=\"hljs-string\">\\'image_id\\'</span>]}</span>.png\"</span>,\\n<span class=\"hljs-meta\">... </span>            }\\n<span class=\"hljs-meta\">... </span>        )\\n<span class=\"hljs-meta\">... </span>        output_json[<span class=\"hljs-string\">\"annotations\"</span>].extend(ann)\\n<span class=\"hljs-meta\">... </span>    output_json[<span class=\"hljs-string\">\"categories\"</span>] = categories_json\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(path_anno, <span class=\"hljs-string\">\"w\"</span>) <span class=\"hljs-keyword\">as</span> file:\\n<span class=\"hljs-meta\">... </span>        json.dump(output_json, file, ensure_ascii=<span class=\"hljs-literal\">False</span>, indent=<span class=\"hljs-number\">4</span>)\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">for</span> im, img_id <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(cppe5[<span class=\"hljs-string\">\"image\"</span>], cppe5[<span class=\"hljs-string\">\"image_id\"</span>]):\\n<span class=\"hljs-meta\">... </span>        path_img = os.path.join(path_output_cppe5, <span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{img_id}</span>.png\"</span>)\\n<span class=\"hljs-meta\">... </span>        im.save(path_img)\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">return</span> path_output_cppe5, path_anno</pre></div> <p data-svelte-h=\"svelte-4e01dv\">Next, prepare an instance of a <code>CocoDetection</code> class that can be used with <code>cocoevaluator</code>.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> torchvision\\n\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CocoDetection</span>(torchvision.datasets.CocoDetection):\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, img_folder, image_processor, ann_file</span>):\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-built_in\">super</span>().__init__(img_folder, ann_file)\\n<span class=\"hljs-meta\">... </span>        self.image_processor = image_processor\\n\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx</span>):\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-comment\"># read in PIL image and target in COCO format</span>\\n<span class=\"hljs-meta\">... </span>        img, target = <span class=\"hljs-built_in\">super</span>(CocoDetection, self).__getitem__(idx)\\n\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-comment\"># preprocess image and target: converting target to DETR format,</span>\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-comment\"># resizing + normalization of both image and target)</span>\\n<span class=\"hljs-meta\">... </span>        image_id = self.ids[idx]\\n<span class=\"hljs-meta\">... </span>        target = {<span class=\"hljs-string\">\"image_id\"</span>: image_id, <span class=\"hljs-string\">\"annotations\"</span>: target}\\n<span class=\"hljs-meta\">... </span>        encoding = self.image_processor(images=img, annotations=target, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n<span class=\"hljs-meta\">... </span>        pixel_values = encoding[<span class=\"hljs-string\">\"pixel_values\"</span>].squeeze()  <span class=\"hljs-comment\"># remove batch dimension</span>\\n<span class=\"hljs-meta\">... </span>        target = encoding[<span class=\"hljs-string\">\"labels\"</span>][<span class=\"hljs-number\">0</span>]  <span class=\"hljs-comment\"># remove batch dimension</span>\\n\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">\"pixel_values\"</span>: pixel_values, <span class=\"hljs-string\">\"labels\"</span>: target}\\n\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>im_processor = AutoImageProcessor.from_pretrained(<span class=\"hljs-string\">\"devonho/detr-resnet-50_finetuned_cppe5\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>path_output_cppe5, path_anno = save_cppe5_annotation_file_images(cppe5[<span class=\"hljs-string\">\"test\"</span>])\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>test_ds_coco_format = CocoDetection(path_output_cppe5, im_processor, path_anno)</pre></div> <p data-svelte-h=\"svelte-xiphfy\">Finally, load the metrics and run the evaluation.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> evaluate\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class=\"hljs-string\">\"devonho/detr-resnet-50_finetuned_cppe5\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>module = evaluate.load(<span class=\"hljs-string\">\"ybelkada/cocoevaluate\"</span>, coco=test_ds_coco_format.coco)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>val_dataloader = torch.utils.data.DataLoader(\\n<span class=\"hljs-meta\">... </span>    test_ds_coco_format, batch_size=<span class=\"hljs-number\">8</span>, shuffle=<span class=\"hljs-literal\">False</span>, num_workers=<span class=\"hljs-number\">4</span>, collate_fn=collate_fn\\n<span class=\"hljs-meta\">... </span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">with</span> torch.no_grad():\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-keyword\">for</span> idx, batch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(tqdm(val_dataloader)):\\n<span class=\"hljs-meta\">... </span>        pixel_values = batch[<span class=\"hljs-string\">\"pixel_values\"</span>]\\n<span class=\"hljs-meta\">... </span>        pixel_mask = batch[<span class=\"hljs-string\">\"pixel_mask\"</span>]\\n\\n<span class=\"hljs-meta\">... </span>        labels = [\\n<span class=\"hljs-meta\">... </span>            {k: v <span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> t.items()} <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> batch[<span class=\"hljs-string\">\"labels\"</span>]\\n<span class=\"hljs-meta\">... </span>        ]  <span class=\"hljs-comment\"># these are in DETR format, resized + normalized</span>\\n\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-comment\"># forward pass</span>\\n<span class=\"hljs-meta\">... </span>        outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\\n\\n<span class=\"hljs-meta\">... </span>        orig_target_sizes = torch.stack([target[<span class=\"hljs-string\">\"orig_size\"</span>] <span class=\"hljs-keyword\">for</span> target <span class=\"hljs-keyword\">in</span> labels], dim=<span class=\"hljs-number\">0</span>)\\n<span class=\"hljs-meta\">... </span>        results = im_processor.post_process(outputs, orig_target_sizes)  <span class=\"hljs-comment\"># convert outputs of model to COCO api</span>\\n\\n<span class=\"hljs-meta\">... </span>        module.add(prediction=results, reference=labels)\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-keyword\">del</span> batch\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>results = module.compute()\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-built_in\">print</span>(results)\\nAccumulating evaluation results...\\nDONE (t=<span class=\"hljs-number\">0.08</span>s).\\nIoU metric: bbox\\n Average Precision  (AP) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area=   <span class=\"hljs-built_in\">all</span> | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.352</span>\\n Average Precision  (AP) @[ IoU=<span class=\"hljs-number\">0.50</span>      | area=   <span class=\"hljs-built_in\">all</span> | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.681</span>\\n Average Precision  (AP) @[ IoU=<span class=\"hljs-number\">0.75</span>      | area=   <span class=\"hljs-built_in\">all</span> | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.292</span>\\n Average Precision  (AP) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area= small | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.168</span>\\n Average Precision  (AP) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area=medium | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.208</span>\\n Average Precision  (AP) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area= large | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.429</span>\\n Average Recall     (AR) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area=   <span class=\"hljs-built_in\">all</span> | maxDets=  <span class=\"hljs-number\">1</span> ] = <span class=\"hljs-number\">0.274</span>\\n Average Recall     (AR) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area=   <span class=\"hljs-built_in\">all</span> | maxDets= <span class=\"hljs-number\">10</span> ] = <span class=\"hljs-number\">0.484</span>\\n Average Recall     (AR) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area=   <span class=\"hljs-built_in\">all</span> | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.501</span>\\n Average Recall     (AR) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area= small | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.191</span>\\n Average Recall     (AR) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area=medium | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.323</span>\\n Average Recall     (AR) @[ IoU=<span class=\"hljs-number\">0.50</span>:<span class=\"hljs-number\">0.95</span> | area= large | maxDets=<span class=\"hljs-number\">100</span> ] = <span class=\"hljs-number\">0.590</span></pre></div> <p data-svelte-h=\"svelte-ds72iu\">These results can be further improved by adjusting the hyperparameters in <a href=\"/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments\">TrainingArguments</a>. Give it a go!</p> <h2 class=\"relative group\"><a id=\"inference\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#inference\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-199uz7g\">Inference</span></h2>\\n\\n\\nNow that you have finetuned a DETR model, evaluated it, and uploaded it to the Hugging Face Hub, you can use it for inference.\\nThe simplest way to try out your finetuned model for inference is to use it in a [Pipeline](/docs/transformers/v4.34.0/en/main_classes/pipelines#transformers.Pipeline). Instantiate a pipeline\\nfor object detection with your model, and pass an image to it:\\n\\n\\t<div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> pipeline\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">import</span> requests\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>url = <span class=\"hljs-string\">\"https://i.imgur.com/2lnWoly.jpg\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image = Image.<span class=\"hljs-built_in\">open</span>(requests.get(url, stream=<span class=\"hljs-literal\">True</span>).raw)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>obj_detector = pipeline(<span class=\"hljs-string\">\"object-detection\"</span>, model=<span class=\"hljs-string\">\"devonho/detr-resnet-50_finetuned_cppe5\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>obj_detector(image)</pre></div> <p data-svelte-h=\"svelte-o6117l\">You can also manually replicate the results of the pipeline if you’d like:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class=\"hljs-string\">\"devonho/detr-resnet-50_finetuned_cppe5\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class=\"hljs-string\">\"devonho/detr-resnet-50_finetuned_cppe5\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">with</span> torch.no_grad():\\n<span class=\"hljs-meta\">... </span>    inputs = image_processor(images=image, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n<span class=\"hljs-meta\">... </span>    outputs = model(**inputs)\\n<span class=\"hljs-meta\">... </span>    target_sizes = torch.tensor([image.size[::-<span class=\"hljs-number\">1</span>]])\\n<span class=\"hljs-meta\">... </span>    results = image_processor.post_process_object_detection(outputs, threshold=<span class=\"hljs-number\">0.5</span>, target_sizes=target_sizes)[<span class=\"hljs-number\">0</span>]\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">for</span> score, label, box <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(results[<span class=\"hljs-string\">\"scores\"</span>], results[<span class=\"hljs-string\">\"labels\"</span>], results[<span class=\"hljs-string\">\"boxes\"</span>]):\\n<span class=\"hljs-meta\">... </span>    box = [<span class=\"hljs-built_in\">round</span>(i, <span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> box.tolist()]\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-built_in\">print</span>(\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-string\">f\"Detected <span class=\"hljs-subst\">{model.config.id2label[label.item()]}</span> with confidence \"</span>\\n<span class=\"hljs-meta\">... </span>        <span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{<span class=\"hljs-built_in\">round</span>(score.item(), <span class=\"hljs-number\">3</span>)}</span> at location <span class=\"hljs-subst\">{box}</span>\"</span>\\n<span class=\"hljs-meta\">... </span>    )\\nDetected Coverall <span class=\"hljs-keyword\">with</span> confidence <span class=\"hljs-number\">0.566</span> at location [<span class=\"hljs-number\">1215.32</span>, <span class=\"hljs-number\">147.38</span>, <span class=\"hljs-number\">4401.81</span>, <span class=\"hljs-number\">3227.08</span>]\\nDetected Mask <span class=\"hljs-keyword\">with</span> confidence <span class=\"hljs-number\">0.584</span> at location [<span class=\"hljs-number\">2449.06</span>, <span class=\"hljs-number\">823.19</span>, <span class=\"hljs-number\">3256.43</span>, <span class=\"hljs-number\">1413.9</span>]</pre></div> <p data-svelte-h=\"svelte-7zeucu\">Let’s plot the result:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span>draw = ImageDraw.Draw(image)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">for</span> score, label, box <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(results[<span class=\"hljs-string\">\"scores\"</span>], results[<span class=\"hljs-string\">\"labels\"</span>], results[<span class=\"hljs-string\">\"boxes\"</span>]):\\n<span class=\"hljs-meta\">... </span>    box = [<span class=\"hljs-built_in\">round</span>(i, <span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> box.tolist()]\\n<span class=\"hljs-meta\">... </span>    x, y, x2, y2 = <span class=\"hljs-built_in\">tuple</span>(box)\\n<span class=\"hljs-meta\">... </span>    draw.rectangle((x, y, x2, y2), outline=<span class=\"hljs-string\">\"red\"</span>, width=<span class=\"hljs-number\">1</span>)\\n<span class=\"hljs-meta\">... </span>    draw.text((x, y), model.config.id2label[label.item()], fill=<span class=\"hljs-string\">\"white\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>image</pre></div> <div class=\"flex justify-center\" data-svelte-h=\"svelte-16oi5q2\"><img src=\"https://i.imgur.com/4QZnf9A.png\" alt=\"Object detection result on a new image\"></div> <p></p> <div id=\"svelte-announcer\" aria-live=\"assertive\" aria-atomic=\"true\" style=\"position: absolute; left: 0px; top: 0px; clip: rect(0px, 0px, 0px, 0px); clip-path: inset(50%); overflow: hidden; white-space: nowrap; width: 1px; height: 1px;\"></div></div>\\n\\t\\t\\t\\t<div class=\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\"><a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/tasks/video_classification\" class=\"mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300\"><span class=\"mr-2 translate-y-px\">←</span>Video classification</a>\\n\\t\\t\\t\\t\\t<a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection\" class=\"ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300\">Zero-shot object detection<span class=\"ml-2 translate-y-px\">→</span></a></div></div></div>\\n\\t\\t<div class=\"sticky top-0 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapter&quot;:{&quot;title&quot;:&quot;Object detection&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;object-detection&quot;,&quot;url&quot;:&quot;#object-detection&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Load the CPPE-5 dataset&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;load-the-cppe5-dataset&quot;,&quot;url&quot;:&quot;#load-the-cppe5-dataset&quot;},{&quot;title&quot;:&quot;Preprocess the data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocess-the-data&quot;,&quot;url&quot;:&quot;#preprocess-the-data&quot;},{&quot;title&quot;:&quot;Training the DETR model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training-the-detr-model&quot;,&quot;url&quot;:&quot;#training-the-detr-model&quot;},{&quot;title&quot;:&quot;Evaluate&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;evaluate&quot;,&quot;url&quot;:&quot;#evaluate&quot;},{&quot;title&quot;:&quot;Inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;inference&quot;,&quot;url&quot;:&quot;#inference&quot;}]}}\" data-target=\"SubSideMenu\"><nav class=\"hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pt-24 pl-6 pr-10 pb-16 text-sm lg:flex 2xl:w-[305px]\"><a href=\"#object-detection\" class=\" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-object-detection\"><wbr>Object detection</a> <a href=\"#load-the-cppe5-dataset\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-load-the-cppe5-dataset\"><wbr>Load the CPP<wbr>E-5 dataset</a> <a href=\"#preprocess-the-data\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-preprocess-the-data\"><wbr>Preprocess the data</a> <a href=\"#training-the-detr-model\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-training-the-detr-model\"><wbr>Training the DET<wbr>R model</a> <a href=\"#evaluate\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-evaluate\"><wbr>Evaluate</a> <a href=\"#inference\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-inference\"><wbr>Inference</a> </nav></div></div></div>\\n\\t<div id=\"doc-footer\"></div></main>\\n\\t</div>\\n\\n\\t\\t<script>\\n\\t\\t\\timport(\"/front/build/kube-5e23f38/index.js\");\\n\\t\\t\\twindow.moonSha = \"kube-5e23f38/\";\\n\\t\\t\\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\"}`);\\n\\t\\t</script>\\n\\n\\t\\t<!-- Stripe -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://js.stripe.com/v3/\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google analytics v4 -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\n\\t\\t\\t\\twindow.dataLayer = window.dataLayer || [];\\n\\t\\t\\t\\tfunction gtag() {\\n\\t\\t\\t\\t\\tif (window.dataLayer !== undefined) {\\n\\t\\t\\t\\t\\t\\twindow.dataLayer.push(arguments);\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tgtag(\"js\", new Date());\\n\\t\\t\\t\\tgtag(\"config\", \"G-8Q63TH4CSL\", { page_path: \"/docs/transformers/v4.34.0/en/tasks/object_detection\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages\\n\\t\\t\\t\\tgtag(\"consent\", \"default\", { ad_storage: \"denied\", analytics_storage: \"denied\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent\\n\\t\\t\\t\\t/// TODO: ask the user for their consent and update this with gtag(\\'consent\\', \\'update\\')\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google Analytics v3 (deprecated) -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\t(function (i, s, o, g, r, a, m) {\\n\\t\\t\\t\\t\\ti[\"GoogleAnalyticsObject\"] = r;\\n\\t\\t\\t\\t\\t(i[r] =\\n\\t\\t\\t\\t\\t\\ti[r] ||\\n\\t\\t\\t\\t\\t\\tfunction () {\\n\\t\\t\\t\\t\\t\\t\\t(i[r].q = i[r].q || []).push(arguments);\\n\\t\\t\\t\\t\\t\\t}),\\n\\t\\t\\t\\t\\t\\t(i[r].l = 1 * new Date());\\n\\t\\t\\t\\t\\t(a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);\\n\\t\\t\\t\\t\\ta.async = 1;\\n\\t\\t\\t\\t\\ta.src = g;\\n\\t\\t\\t\\t\\tm.parentNode.insertBefore(a, m);\\n\\t\\t\\t\\t})(window, document, \"script\", \"https://www.google-analytics.com/analytics.js\", \"ganalytics\");\\n\\t\\t\\t\\tganalytics(\"create\", \"UA-83738774-2\", \"auto\");\\n\\t\\t\\t\\tganalytics(\"send\", \"pageview\", \"/docs/transformers/v4.34.0/en/tasks/object_detection\");\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\t\\n\\n<iframe name=\"__privateStripeMetricsController6900\" frameborder=\"0\" allowtransparency=\"true\" scrolling=\"no\" role=\"presentation\" allow=\"payment *\" src=\"https://js.stripe.com/v3/m-outer-27c67c0d52761104439bb051c7856ab1.html#url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftransformers%2Fv4.34.0%2Fen%2Ftasks%2Fobject_detection&amp;title=Object%20detection&amp;referrer=&amp;muid=NA&amp;sid=NA&amp;version=6&amp;preview=false\" aria-hidden=\"true\" tabindex=\"-1\" style=\"border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;\"></iframe></body></html>',\n",
       "  'mime_type': 'text/plain',\n",
       "  'metadata': {}},\n",
       " {'document_id': '2',\n",
       "  'content': '<!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<meta charset=\"utf-8\">\\n\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\">\\n\\t\\t<meta name=\"description\" content=\"We’re on a journey to advance and democratize artificial intelligence through open source and open science.\">\\n\\t\\t<meta property=\"fb:app_id\" content=\"1321688464574422\">\\n\\t\\t<meta name=\"twitter:card\" content=\"summary_large_image\">\\n\\t\\t<meta name=\"twitter:site\" content=\"@huggingface\">\\n\\t\\t<meta property=\"og:title\" content=\"Utilities for `FeatureExtractors`\">\\n\\t\\t<meta property=\"og:type\" content=\"website\">\\n\\t\\t<meta property=\"og:url\" content=\"https://huggingface.co/docs/transformers/v4.34.0/en/internal/audio_utils\">\\n\\t\\t<meta property=\"og:image\" content=\"https://huggingface.co/front/thumbnails/docs/transformers.png\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"/front/build/kube-b0520c1/style.css\">\\n\\n\\t\\t<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap\" rel=\"stylesheet\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap\" rel=\"stylesheet\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" as=\"style\" onload=\"this.onload=null;this.rel=\\'stylesheet\\'\">\\n\\t\\t<noscript>\\n\\t\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" />\\n\\t\\t</noscript>\\n\\n\\t\\t  \\n\\n\\t\\t<title>Utilities for `FeatureExtractors`</title>\\n\\n\\t\\t<script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script defer=\"\" data-domain=\"huggingface.co\" src=\"/js/script.js\"></script>\\n\\t<script src=\"https://js.stripe.com/v3/\" async=\"\"></script><script src=\"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\" async=\"\"></script><meta http-equiv=\"origin-trial\" content=\"AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9\"></head>\\n\\t<body class=\"flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage\">\\n\\t\\t<div class=\"flex min-h-screen flex-col\">\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}\" data-target=\"MainHeader\"><header class=\"border-b border-gray-100 \"><div class=\"w-full px-4  flex h-16 items-center\"><div class=\"flex flex-1 items-center\"><a class=\"mr-5 flex flex-none items-center lg:mr-6\" href=\"/\"><img alt=\"Hugging Face\\'s logo\" class=\"w-7 md:mr-2\" src=\"/front/assets/huggingface_logo-noborder.svg\">\\n\\t\\t\\t\\t<span class=\"hidden whitespace-nowrap text-lg font-bold md:block\">Hugging Face</span></a>\\n\\t\\t\\t<div class=\"relative flex-1 lg:max-w-sm mr-2 sm:mr-4 lg:mr-6\"><input autocomplete=\"off\" class=\"w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl\" name=\"\" placeholder=\"Search models, datasets, users...\" spellcheck=\"false\" type=\"text\" value=\"\">\\n\\t<svg class=\"absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg>\\n\\t</div>\\n\\t\\t\\t<div class=\"flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden\"><button class=\"relative z-40 flex h-6 w-8 items-center justify-center\" type=\"button\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 10 10\" class=\"text-xl\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" preserveAspectRatio=\"xMidYMid meet\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\"></path></svg>\\n\\t\\t</button>\\n\\n\\t</div></div>\\n\\t\\t<nav aria-label=\"Main\" class=\"ml-auto hidden lg:block\"><ul class=\"flex items-center space-x-2\"><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700\" href=\"/models\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t\\t\\tModels</a>\\n\\t\\t\\t</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700\" href=\"/datasets\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-red-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 25 25\"><ellipse cx=\"12.5\" cy=\"5\" fill=\"currentColor\" fill-opacity=\"0.25\" rx=\"7.5\" ry=\"2\"></ellipse><path d=\"M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t\\t\\tDatasets</a>\\n\\t\\t\\t</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700\" href=\"/spaces\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-blue-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 25 25\"><path opacity=\".5\" d=\"M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z\" fill=\"currentColor\"></path><path opacity=\".75\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z\" fill=\"currentColor\"></path><path opacity=\".25\" d=\"M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t\\t\\tSpaces</a>\\n\\t\\t\\t</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/docs\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path opacity=\"0.5\" d=\"M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z\" fill=\"currentColor\"></path><path d=\"M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z\" fill=\"currentColor\" fill-opacity=\"0.75\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z\" fill=\"currentColor\"></path><path opacity=\"0.5\" d=\"M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t\\t\\tDocs</a>\\n\\t\\t\\t</li>\\n\\t\\t<li><div class=\"relative \">\\n\\t<button class=\"px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center \" type=\"button\">\\n\\t\\t<svg class=\"mr-1.5 text-gray-400 group-hover:text-green-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-tertiary\" d=\"M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\tSolutions\\n\\t\\t</button>\\n\\t\\n\\t\\n\\t\\n\\t</div></li>\\n\\t\\t<li><a class=\"group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/pricing\">Pricing\\n\\t\\t\\t</a></li>\\n\\n\\t\\t<li><div class=\"relative group\">\\n\\t<button class=\"px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center \" type=\"button\">\\n\\t\\t<svg class=\"mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 32 18\" preserveAspectRatio=\"xMidYMid meet\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t\\n\\t\\t</button>\\n\\t\\n\\t\\n\\t\\n\\t</div></li>\\n\\t\\t<li><hr class=\"h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800\"></li>\\n\\t\\t<li><a class=\"block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/login\">Log In\\n\\t\\t\\t\\t</a></li>\\n\\t\\t\\t<li><a class=\"rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black\" href=\"/join\">Sign Up\\n\\t\\t\\t\\t\\t</a></li></ul></nav></div></header></div>\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"GoogleAnalyticsTracker\"></div>\\n\\t\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"SSOBanner\"></div>\\n\\n\\t<main class=\"flex flex-1 flex-col\"><div class=\"relative lg:flex\"><div class=\"sticky top-0 z-20 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;🤗 Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/index&quot;},{&quot;title&quot;:&quot;Quick tour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;installation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/installation&quot;}]},{&quot;title&quot;:&quot;Tutorials&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Run inference with pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_tutorial&quot;},{&quot;title&quot;:&quot;Write portable code with AutoClass&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;autoclass_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/autoclass_tutorial&quot;},{&quot;title&quot;:&quot;Preprocess data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocessing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/preprocessing&quot;},{&quot;title&quot;:&quot;Fine-tune a pretrained model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/training&quot;},{&quot;title&quot;:&quot;Train with a script&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;run_scripts&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/run_scripts&quot;},{&quot;title&quot;:&quot;Set up distributed training with 🤗 Accelerate&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/accelerate&quot;},{&quot;title&quot;:&quot;Load and train adapters with 🤗 PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;peft&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/peft&quot;},{&quot;title&quot;:&quot;Share your model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_sharing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_sharing&quot;},{&quot;title&quot;:&quot;Agents&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers_agents&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/transformers_agents&quot;},{&quot;title&quot;:&quot;Generation with LLMs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;llm_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/llm_tutorial&quot;}]},{&quot;title&quot;:&quot;Task Guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Natural Language Processing&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text classification&quot;,&quot;id&quot;:&quot;tasks/sequence_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/sequence_classification&quot;},{&quot;title&quot;:&quot;Token classification&quot;,&quot;id&quot;:&quot;tasks/token_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/token_classification&quot;},{&quot;title&quot;:&quot;Question answering&quot;,&quot;id&quot;:&quot;tasks/question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/question_answering&quot;},{&quot;title&quot;:&quot;Causal language modeling&quot;,&quot;id&quot;:&quot;tasks/language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/language_modeling&quot;},{&quot;title&quot;:&quot;Masked language modeling&quot;,&quot;id&quot;:&quot;tasks/masked_language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/masked_language_modeling&quot;},{&quot;title&quot;:&quot;Translation&quot;,&quot;id&quot;:&quot;tasks/translation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/translation&quot;},{&quot;title&quot;:&quot;Summarization&quot;,&quot;id&quot;:&quot;tasks/summarization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/summarization&quot;},{&quot;title&quot;:&quot;Multiple choice&quot;,&quot;id&quot;:&quot;tasks/multiple_choice&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/multiple_choice&quot;}]},{&quot;title&quot;:&quot;Audio&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio classification&quot;,&quot;id&quot;:&quot;tasks/audio_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/audio_classification&quot;},{&quot;title&quot;:&quot;Automatic speech recognition&quot;,&quot;id&quot;:&quot;tasks/asr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/asr&quot;}]},{&quot;title&quot;:&quot;Computer Vision&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image classification&quot;,&quot;id&quot;:&quot;tasks/image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_classification&quot;},{&quot;title&quot;:&quot;Semantic segmentation&quot;,&quot;id&quot;:&quot;tasks/semantic_segmentation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/semantic_segmentation&quot;},{&quot;title&quot;:&quot;Video classification&quot;,&quot;id&quot;:&quot;tasks/video_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/video_classification&quot;},{&quot;title&quot;:&quot;Object detection&quot;,&quot;id&quot;:&quot;tasks/object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot object detection&quot;,&quot;id&quot;:&quot;tasks/zero_shot_object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot image classification&quot;,&quot;id&quot;:&quot;tasks/zero_shot_image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_image_classification&quot;},{&quot;title&quot;:&quot;Depth estimation&quot;,&quot;id&quot;:&quot;tasks/monocular_depth_estimation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/monocular_depth_estimation&quot;}]},{&quot;title&quot;:&quot;Multimodal&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image captioning&quot;,&quot;id&quot;:&quot;tasks/image_captioning&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_captioning&quot;},{&quot;title&quot;:&quot;Document Question Answering&quot;,&quot;id&quot;:&quot;tasks/document_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/document_question_answering&quot;},{&quot;title&quot;:&quot;Visual Question Answering&quot;,&quot;id&quot;:&quot;tasks/visual_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/visual_question_answering&quot;},{&quot;title&quot;:&quot;Text to speech&quot;,&quot;id&quot;:&quot;tasks/text-to-speech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/text-to-speech&quot;}]},{&quot;title&quot;:&quot;Generation&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Customize the generation strategy&quot;,&quot;id&quot;:&quot;generation_strategies&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/generation_strategies&quot;}]},{&quot;title&quot;:&quot;Prompting&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image tasks with IDEFICS&quot;,&quot;id&quot;:&quot;tasks/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/idefics&quot;}]}]},{&quot;title&quot;:&quot;Developer guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Use fast tokenizers from 🤗 Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/fast_tokenizers&quot;},{&quot;title&quot;:&quot;Run inference with multilingual models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multilingual&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/multilingual&quot;},{&quot;title&quot;:&quot;Use model-specific APIs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;create_a_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/create_a_model&quot;},{&quot;title&quot;:&quot;Share a custom model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_models&quot;},{&quot;title&quot;:&quot;Templates for chat models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;chat_templating&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/chat_templating&quot;},{&quot;title&quot;:&quot;Run training on Amazon SageMaker&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sagemaker&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/sagemaker&quot;},{&quot;title&quot;:&quot;Export to ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;serialization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/serialization&quot;},{&quot;title&quot;:&quot;Export to TFLite&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tflite&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tflite&quot;},{&quot;title&quot;:&quot;Export to TorchScript&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;torchscript&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/torchscript&quot;},{&quot;title&quot;:&quot;Benchmarks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;benchmarks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/benchmarks&quot;},{&quot;title&quot;:&quot;Notebooks with examples&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;notebooks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/notebooks&quot;},{&quot;title&quot;:&quot;Community resources&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;community&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/community&quot;},{&quot;title&quot;:&quot;Custom Tools and Prompts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_tools&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_tools&quot;},{&quot;title&quot;:&quot;Troubleshoot&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;troubleshooting&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/troubleshooting&quot;}]},{&quot;title&quot;:&quot;Performance and scalability&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Overview&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/performance&quot;},{&quot;title&quot;:&quot;Efficient training techniques&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Methods and tools for efficient training on a single GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_one&quot;},{&quot;title&quot;:&quot;Multiple GPUs and parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_many&quot;},{&quot;title&quot;:&quot;Efficient training on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu&quot;},{&quot;title&quot;:&quot;Distributed CPU training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu_many&quot;},{&quot;title&quot;:&quot;Training on TPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu&quot;},{&quot;title&quot;:&quot;Training on TPU with TensorFlow&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu_tf&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu_tf&quot;},{&quot;title&quot;:&quot;Training on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_special&quot;},{&quot;title&quot;:&quot;Custom hardware for training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_hardware&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_hardware&quot;},{&quot;title&quot;:&quot;Hyperparameter Search using Trainer API&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;hpo_train&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/hpo_train&quot;}]},{&quot;title&quot;:&quot;Optimizing inference&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Inference on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_cpu&quot;},{&quot;title&quot;:&quot;Inference on one GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_one&quot;},{&quot;title&quot;:&quot;Inference on many GPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_many&quot;},{&quot;title&quot;:&quot;Inference on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_special&quot;}]},{&quot;title&quot;:&quot;Instantiating a big model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;big_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/big_models&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;debugging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/debugging&quot;},{&quot;title&quot;:&quot;XLA Integration for TensorFlow Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tf_xla&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tf_xla&quot;},{&quot;title&quot;:&quot;Optimize inference using `torch.compile()`&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_torch_compile&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_torch_compile&quot;}]},{&quot;title&quot;:&quot;Contribute&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;How to contribute to transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contributing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/contributing&quot;},{&quot;title&quot;:&quot;How to add a model to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_model&quot;},{&quot;title&quot;:&quot;How to convert a 🤗 Transformers model to TensorFlow?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_tensorflow_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_tensorflow_model&quot;},{&quot;title&quot;:&quot;How to add a pipeline to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_pipeline&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_pipeline&quot;},{&quot;title&quot;:&quot;Testing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;testing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/testing&quot;},{&quot;title&quot;:&quot;Checks on a Pull Request&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pr_checks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pr_checks&quot;}]},{&quot;title&quot;:&quot;Conceptual guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Philosophy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;philosophy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/philosophy&quot;},{&quot;title&quot;:&quot;Glossary&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;glossary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/glossary&quot;},{&quot;title&quot;:&quot;What 🤗 Transformers can do&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/task_summary&quot;},{&quot;title&quot;:&quot;How 🤗 Transformers solve tasks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tasks_explained&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks_explained&quot;},{&quot;title&quot;:&quot;The Transformer model family&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_summary&quot;},{&quot;title&quot;:&quot;Summary of the tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tokenizer_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tokenizer_summary&quot;},{&quot;title&quot;:&quot;Attention mechanisms&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;attention&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/attention&quot;},{&quot;title&quot;:&quot;Padding and truncation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pad_truncation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pad_truncation&quot;},{&quot;title&quot;:&quot;BERTology&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bertology&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/bertology&quot;},{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perplexity&quot;},{&quot;title&quot;:&quot;Pipelines for webserver inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_webserver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_webserver&quot;},{&quot;title&quot;:&quot;Model training anatomy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_memory_anatomy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_memory_anatomy&quot;}]},{&quot;title&quot;:&quot;API&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main Classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Agents and Tools&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/agent&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/agent&quot;},{&quot;title&quot;:&quot;Auto Classes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/auto&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/auto&quot;},{&quot;title&quot;:&quot;Callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/callback&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/callback&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/configuration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/configuration&quot;},{&quot;title&quot;:&quot;Data Collator&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/data_collator&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/data_collator&quot;},{&quot;title&quot;:&quot;Keras callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/keras_callbacks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/keras_callbacks&quot;},{&quot;title&quot;:&quot;Logging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/logging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/logging&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/model&quot;},{&quot;title&quot;:&quot;Text Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/text_generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/text_generation&quot;},{&quot;title&quot;:&quot;ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/onnx&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/onnx&quot;},{&quot;title&quot;:&quot;Optimization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/optimizer_schedules&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules&quot;},{&quot;title&quot;:&quot;Model outputs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/output&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/output&quot;},{&quot;title&quot;:&quot;Pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/pipelines&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/pipelines&quot;},{&quot;title&quot;:&quot;Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/processors&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/processors&quot;},{&quot;title&quot;:&quot;Quantization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/quantization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/quantization&quot;},{&quot;title&quot;:&quot;Tokenizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/tokenizer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/tokenizer&quot;},{&quot;title&quot;:&quot;Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/trainer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/trainer&quot;},{&quot;title&quot;:&quot;DeepSpeed Integration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/deepspeed&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/deepspeed&quot;},{&quot;title&quot;:&quot;Feature Extractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/feature_extractor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/feature_extractor&quot;},{&quot;title&quot;:&quot;Image Processor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/image_processor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/image_processor&quot;}]},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALBERT&quot;,&quot;id&quot;:&quot;model_doc/albert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/albert&quot;},{&quot;title&quot;:&quot;BART&quot;,&quot;id&quot;:&quot;model_doc/bart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bart&quot;},{&quot;title&quot;:&quot;BARThez&quot;,&quot;id&quot;:&quot;model_doc/barthez&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/barthez&quot;},{&quot;title&quot;:&quot;BARTpho&quot;,&quot;id&quot;:&quot;model_doc/bartpho&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bartpho&quot;},{&quot;title&quot;:&quot;BERT&quot;,&quot;id&quot;:&quot;model_doc/bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert&quot;},{&quot;title&quot;:&quot;BertGeneration&quot;,&quot;id&quot;:&quot;model_doc/bert-generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-generation&quot;},{&quot;title&quot;:&quot;BertJapanese&quot;,&quot;id&quot;:&quot;model_doc/bert-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-japanese&quot;},{&quot;title&quot;:&quot;Bertweet&quot;,&quot;id&quot;:&quot;model_doc/bertweet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bertweet&quot;},{&quot;title&quot;:&quot;BigBird&quot;,&quot;id&quot;:&quot;model_doc/big_bird&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/big_bird&quot;},{&quot;title&quot;:&quot;BigBirdPegasus&quot;,&quot;id&quot;:&quot;model_doc/bigbird_pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bigbird_pegasus&quot;},{&quot;title&quot;:&quot;BioGpt&quot;,&quot;id&quot;:&quot;model_doc/biogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/biogpt&quot;},{&quot;title&quot;:&quot;Blenderbot&quot;,&quot;id&quot;:&quot;model_doc/blenderbot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot&quot;},{&quot;title&quot;:&quot;Blenderbot Small&quot;,&quot;id&quot;:&quot;model_doc/blenderbot-small&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot-small&quot;},{&quot;title&quot;:&quot;BLOOM&quot;,&quot;id&quot;:&quot;model_doc/bloom&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bloom&quot;},{&quot;title&quot;:&quot;BORT&quot;,&quot;id&quot;:&quot;model_doc/bort&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bort&quot;},{&quot;title&quot;:&quot;ByT5&quot;,&quot;id&quot;:&quot;model_doc/byt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/byt5&quot;},{&quot;title&quot;:&quot;CamemBERT&quot;,&quot;id&quot;:&quot;model_doc/camembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/camembert&quot;},{&quot;title&quot;:&quot;CANINE&quot;,&quot;id&quot;:&quot;model_doc/canine&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/canine&quot;},{&quot;title&quot;:&quot;CodeGen&quot;,&quot;id&quot;:&quot;model_doc/codegen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/codegen&quot;},{&quot;title&quot;:&quot;CodeLlama&quot;,&quot;id&quot;:&quot;model_doc/code_llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/code_llama&quot;},{&quot;title&quot;:&quot;ConvBERT&quot;,&quot;id&quot;:&quot;model_doc/convbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convbert&quot;},{&quot;title&quot;:&quot;CPM&quot;,&quot;id&quot;:&quot;model_doc/cpm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpm&quot;},{&quot;title&quot;:&quot;CPMANT&quot;,&quot;id&quot;:&quot;model_doc/cpmant&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpmant&quot;},{&quot;title&quot;:&quot;CTRL&quot;,&quot;id&quot;:&quot;model_doc/ctrl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ctrl&quot;},{&quot;title&quot;:&quot;DeBERTa&quot;,&quot;id&quot;:&quot;model_doc/deberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta&quot;},{&quot;title&quot;:&quot;DeBERTa-v2&quot;,&quot;id&quot;:&quot;model_doc/deberta-v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta-v2&quot;},{&quot;title&quot;:&quot;DialoGPT&quot;,&quot;id&quot;:&quot;model_doc/dialogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dialogpt&quot;},{&quot;title&quot;:&quot;DistilBERT&quot;,&quot;id&quot;:&quot;model_doc/distilbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/distilbert&quot;},{&quot;title&quot;:&quot;DPR&quot;,&quot;id&quot;:&quot;model_doc/dpr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpr&quot;},{&quot;title&quot;:&quot;ELECTRA&quot;,&quot;id&quot;:&quot;model_doc/electra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/electra&quot;},{&quot;title&quot;:&quot;Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encoder-decoder&quot;},{&quot;title&quot;:&quot;ERNIE&quot;,&quot;id&quot;:&quot;model_doc/ernie&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie&quot;},{&quot;title&quot;:&quot;ErnieM&quot;,&quot;id&quot;:&quot;model_doc/ernie_m&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie_m&quot;},{&quot;title&quot;:&quot;ESM&quot;,&quot;id&quot;:&quot;model_doc/esm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/esm&quot;},{&quot;title&quot;:&quot;Falcon&quot;,&quot;id&quot;:&quot;model_doc/falcon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/falcon&quot;},{&quot;title&quot;:&quot;FLAN-T5&quot;,&quot;id&quot;:&quot;model_doc/flan-t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-t5&quot;},{&quot;title&quot;:&quot;FLAN-UL2&quot;,&quot;id&quot;:&quot;model_doc/flan-ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-ul2&quot;},{&quot;title&quot;:&quot;FlauBERT&quot;,&quot;id&quot;:&quot;model_doc/flaubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flaubert&quot;},{&quot;title&quot;:&quot;FNet&quot;,&quot;id&quot;:&quot;model_doc/fnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fnet&quot;},{&quot;title&quot;:&quot;FSMT&quot;,&quot;id&quot;:&quot;model_doc/fsmt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fsmt&quot;},{&quot;title&quot;:&quot;Funnel Transformer&quot;,&quot;id&quot;:&quot;model_doc/funnel&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/funnel&quot;},{&quot;title&quot;:&quot;GPT&quot;,&quot;id&quot;:&quot;model_doc/openai-gpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/openai-gpt&quot;},{&quot;title&quot;:&quot;GPT Neo&quot;,&quot;id&quot;:&quot;model_doc/gpt_neo&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neo&quot;},{&quot;title&quot;:&quot;GPT NeoX&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox&quot;},{&quot;title&quot;:&quot;GPT NeoX Japanese&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox_japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox_japanese&quot;},{&quot;title&quot;:&quot;GPT-J&quot;,&quot;id&quot;:&quot;model_doc/gptj&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptj&quot;},{&quot;title&quot;:&quot;GPT2&quot;,&quot;id&quot;:&quot;model_doc/gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt2&quot;},{&quot;title&quot;:&quot;GPTBigCode&quot;,&quot;id&quot;:&quot;model_doc/gpt_bigcode&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_bigcode&quot;},{&quot;title&quot;:&quot;GPTSAN Japanese&quot;,&quot;id&quot;:&quot;model_doc/gptsan-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptsan-japanese&quot;},{&quot;title&quot;:&quot;GPTSw3&quot;,&quot;id&quot;:&quot;model_doc/gpt-sw3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt-sw3&quot;},{&quot;title&quot;:&quot;HerBERT&quot;,&quot;id&quot;:&quot;model_doc/herbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/herbert&quot;},{&quot;title&quot;:&quot;I-BERT&quot;,&quot;id&quot;:&quot;model_doc/ibert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ibert&quot;},{&quot;title&quot;:&quot;Jukebox&quot;,&quot;id&quot;:&quot;model_doc/jukebox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/jukebox&quot;},{&quot;title&quot;:&quot;LED&quot;,&quot;id&quot;:&quot;model_doc/led&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/led&quot;},{&quot;title&quot;:&quot;LLaMA&quot;,&quot;id&quot;:&quot;model_doc/llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama&quot;},{&quot;title&quot;:&quot;Llama2&quot;,&quot;id&quot;:&quot;model_doc/llama2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama2&quot;},{&quot;title&quot;:&quot;Longformer&quot;,&quot;id&quot;:&quot;model_doc/longformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longformer&quot;},{&quot;title&quot;:&quot;LongT5&quot;,&quot;id&quot;:&quot;model_doc/longt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longt5&quot;},{&quot;title&quot;:&quot;LUKE&quot;,&quot;id&quot;:&quot;model_doc/luke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/luke&quot;},{&quot;title&quot;:&quot;M2M100&quot;,&quot;id&quot;:&quot;model_doc/m2m_100&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/m2m_100&quot;},{&quot;title&quot;:&quot;MarianMT&quot;,&quot;id&quot;:&quot;model_doc/marian&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/marian&quot;},{&quot;title&quot;:&quot;MarkupLM&quot;,&quot;id&quot;:&quot;model_doc/markuplm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/markuplm&quot;},{&quot;title&quot;:&quot;MBart and MBart-50&quot;,&quot;id&quot;:&quot;model_doc/mbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mbart&quot;},{&quot;title&quot;:&quot;MEGA&quot;,&quot;id&quot;:&quot;model_doc/mega&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mega&quot;},{&quot;title&quot;:&quot;MegatronBERT&quot;,&quot;id&quot;:&quot;model_doc/megatron-bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron-bert&quot;},{&quot;title&quot;:&quot;MegatronGPT2&quot;,&quot;id&quot;:&quot;model_doc/megatron_gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron_gpt2&quot;},{&quot;title&quot;:&quot;Mistral&quot;,&quot;id&quot;:&quot;model_doc/mistral&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mistral&quot;},{&quot;title&quot;:&quot;mLUKE&quot;,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MobileBERT&quot;,&quot;id&quot;:&quot;model_doc/mobilebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilebert&quot;},{&quot;title&quot;:&quot;MPNet&quot;,&quot;id&quot;:&quot;model_doc/mpnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpnet&quot;},{&quot;title&quot;:&quot;MPT&quot;,&quot;id&quot;:&quot;model_doc/mpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpt&quot;},{&quot;title&quot;:&quot;MRA&quot;,&quot;id&quot;:&quot;model_doc/mra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mra&quot;},{&quot;title&quot;:&quot;MT5&quot;,&quot;id&quot;:&quot;model_doc/mt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mt5&quot;},{&quot;title&quot;:&quot;MVP&quot;,&quot;id&quot;:&quot;model_doc/mvp&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mvp&quot;},{&quot;title&quot;:&quot;NEZHA&quot;,&quot;id&quot;:&quot;model_doc/nezha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nezha&quot;},{&quot;title&quot;:&quot;NLLB&quot;,&quot;id&quot;:&quot;model_doc/nllb&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb&quot;},{&quot;title&quot;:&quot;NLLB-MoE&quot;,&quot;id&quot;:&quot;model_doc/nllb-moe&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb-moe&quot;},{&quot;title&quot;:&quot;Nyströmformer&quot;,&quot;id&quot;:&quot;model_doc/nystromformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nystromformer&quot;},{&quot;title&quot;:&quot;Open-Llama&quot;,&quot;id&quot;:&quot;model_doc/open-llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/open-llama&quot;},{&quot;title&quot;:&quot;OPT&quot;,&quot;id&quot;:&quot;model_doc/opt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/opt&quot;},{&quot;title&quot;:&quot;Pegasus&quot;,&quot;id&quot;:&quot;model_doc/pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus&quot;},{&quot;title&quot;:&quot;PEGASUS-X&quot;,&quot;id&quot;:&quot;model_doc/pegasus_x&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus_x&quot;},{&quot;title&quot;:&quot;Persimmon&quot;,&quot;id&quot;:&quot;model_doc/persimmon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/persimmon&quot;},{&quot;title&quot;:&quot;PhoBERT&quot;,&quot;id&quot;:&quot;model_doc/phobert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/phobert&quot;},{&quot;title&quot;:&quot;PLBart&quot;,&quot;id&quot;:&quot;model_doc/plbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/plbart&quot;},{&quot;title&quot;:&quot;ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/prophetnet&quot;},{&quot;title&quot;:&quot;QDQBert&quot;,&quot;id&quot;:&quot;model_doc/qdqbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/qdqbert&quot;},{&quot;title&quot;:&quot;RAG&quot;,&quot;id&quot;:&quot;model_doc/rag&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rag&quot;},{&quot;title&quot;:&quot;REALM&quot;,&quot;id&quot;:&quot;model_doc/realm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/realm&quot;},{&quot;title&quot;:&quot;Reformer&quot;,&quot;id&quot;:&quot;model_doc/reformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/reformer&quot;},{&quot;title&quot;:&quot;RemBERT&quot;,&quot;id&quot;:&quot;model_doc/rembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rembert&quot;},{&quot;title&quot;:&quot;RetriBERT&quot;,&quot;id&quot;:&quot;model_doc/retribert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/retribert&quot;},{&quot;title&quot;:&quot;RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta&quot;},{&quot;title&quot;:&quot;RoBERTa-PreLayerNorm&quot;,&quot;id&quot;:&quot;model_doc/roberta-prelayernorm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta-prelayernorm&quot;},{&quot;title&quot;:&quot;RoCBert&quot;,&quot;id&quot;:&quot;model_doc/roc_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roc_bert&quot;},{&quot;title&quot;:&quot;RoFormer&quot;,&quot;id&quot;:&quot;model_doc/roformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roformer&quot;},{&quot;title&quot;:&quot;RWKV&quot;,&quot;id&quot;:&quot;model_doc/rwkv&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rwkv&quot;},{&quot;title&quot;:&quot;Splinter&quot;,&quot;id&quot;:&quot;model_doc/splinter&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/splinter&quot;},{&quot;title&quot;:&quot;SqueezeBERT&quot;,&quot;id&quot;:&quot;model_doc/squeezebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/squeezebert&quot;},{&quot;title&quot;:&quot;SwitchTransformers&quot;,&quot;id&quot;:&quot;model_doc/switch_transformers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/switch_transformers&quot;},{&quot;title&quot;:&quot;T5&quot;,&quot;id&quot;:&quot;model_doc/t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5&quot;},{&quot;title&quot;:&quot;T5v1.1&quot;,&quot;id&quot;:&quot;model_doc/t5v1.1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5v1.1&quot;},{&quot;title&quot;:&quot;TAPEX&quot;,&quot;id&quot;:&quot;model_doc/tapex&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapex&quot;},{&quot;title&quot;:&quot;Transformer XL&quot;,&quot;id&quot;:&quot;model_doc/transfo-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/transfo-xl&quot;},{&quot;title&quot;:&quot;UL2&quot;,&quot;id&quot;:&quot;model_doc/ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ul2&quot;},{&quot;title&quot;:&quot;UMT5&quot;,&quot;id&quot;:&quot;model_doc/umt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/umt5&quot;},{&quot;title&quot;:&quot;X-MOD&quot;,&quot;id&quot;:&quot;model_doc/xmod&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xmod&quot;},{&quot;title&quot;:&quot;XGLM&quot;,&quot;id&quot;:&quot;model_doc/xglm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xglm&quot;},{&quot;title&quot;:&quot;XLM&quot;,&quot;id&quot;:&quot;model_doc/xlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm&quot;},{&quot;title&quot;:&quot;XLM-ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/xlm-prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-prophetnet&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa-XL&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta-xl&quot;},{&quot;title&quot;:&quot;XLM-V&quot;,&quot;id&quot;:&quot;model_doc/xlm-v&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-v&quot;},{&quot;title&quot;:&quot;XLNet&quot;,&quot;id&quot;:&quot;model_doc/xlnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlnet&quot;},{&quot;title&quot;:&quot;YOSO&quot;,&quot;id&quot;:&quot;model_doc/yoso&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yoso&quot;}]},{&quot;title&quot;:&quot;Vision models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;BEiT&quot;,&quot;id&quot;:&quot;model_doc/beit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/beit&quot;},{&quot;title&quot;:&quot;BiT&quot;,&quot;id&quot;:&quot;model_doc/bit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bit&quot;},{&quot;title&quot;:&quot;Conditional DETR&quot;,&quot;id&quot;:&quot;model_doc/conditional_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/conditional_detr&quot;},{&quot;title&quot;:&quot;ConvNeXT&quot;,&quot;id&quot;:&quot;model_doc/convnext&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnext&quot;},{&quot;title&quot;:&quot;ConvNeXTV2&quot;,&quot;id&quot;:&quot;model_doc/convnextv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnextv2&quot;},{&quot;title&quot;:&quot;CvT&quot;,&quot;id&quot;:&quot;model_doc/cvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cvt&quot;},{&quot;title&quot;:&quot;Deformable DETR&quot;,&quot;id&quot;:&quot;model_doc/deformable_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deformable_detr&quot;},{&quot;title&quot;:&quot;DeiT&quot;,&quot;id&quot;:&quot;model_doc/deit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deit&quot;},{&quot;title&quot;:&quot;DETA&quot;,&quot;id&quot;:&quot;model_doc/deta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deta&quot;},{&quot;title&quot;:&quot;DETR&quot;,&quot;id&quot;:&quot;model_doc/detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/detr&quot;},{&quot;title&quot;:&quot;DiNAT&quot;,&quot;id&quot;:&quot;model_doc/dinat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinat&quot;},{&quot;title&quot;:&quot;DINO V2&quot;,&quot;id&quot;:&quot;model_doc/dinov2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinov2&quot;},{&quot;title&quot;:&quot;DiT&quot;,&quot;id&quot;:&quot;model_doc/dit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dit&quot;},{&quot;title&quot;:&quot;DPT&quot;,&quot;id&quot;:&quot;model_doc/dpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpt&quot;},{&quot;title&quot;:&quot;EfficientFormer&quot;,&quot;id&quot;:&quot;model_doc/efficientformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientformer&quot;},{&quot;title&quot;:&quot;EfficientNet&quot;,&quot;id&quot;:&quot;model_doc/efficientnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientnet&quot;},{&quot;title&quot;:&quot;FocalNet&quot;,&quot;id&quot;:&quot;model_doc/focalnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/focalnet&quot;},{&quot;title&quot;:&quot;GLPN&quot;,&quot;id&quot;:&quot;model_doc/glpn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/glpn&quot;},{&quot;title&quot;:&quot;ImageGPT&quot;,&quot;id&quot;:&quot;model_doc/imagegpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/imagegpt&quot;},{&quot;title&quot;:&quot;LeViT&quot;,&quot;id&quot;:&quot;model_doc/levit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/levit&quot;},{&quot;title&quot;:&quot;Mask2Former&quot;,&quot;id&quot;:&quot;model_doc/mask2former&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mask2former&quot;},{&quot;title&quot;:&quot;MaskFormer&quot;,&quot;id&quot;:&quot;model_doc/maskformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/maskformer&quot;},{&quot;title&quot;:&quot;MobileNetV1&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v1&quot;},{&quot;title&quot;:&quot;MobileNetV2&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v2&quot;},{&quot;title&quot;:&quot;MobileViT&quot;,&quot;id&quot;:&quot;model_doc/mobilevit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevit&quot;},{&quot;title&quot;:&quot;MobileViTV2&quot;,&quot;id&quot;:&quot;model_doc/mobilevitv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevitv2&quot;},{&quot;title&quot;:&quot;NAT&quot;,&quot;id&quot;:&quot;model_doc/nat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nat&quot;},{&quot;title&quot;:&quot;PoolFormer&quot;,&quot;id&quot;:&quot;model_doc/poolformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/poolformer&quot;},{&quot;title&quot;:&quot;Pyramid Vision Transformer (PVT)&quot;,&quot;id&quot;:&quot;model_doc/pvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pvt&quot;},{&quot;title&quot;:&quot;RegNet&quot;,&quot;id&quot;:&quot;model_doc/regnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/regnet&quot;},{&quot;title&quot;:&quot;ResNet&quot;,&quot;id&quot;:&quot;model_doc/resnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/resnet&quot;},{&quot;title&quot;:&quot;SegFormer&quot;,&quot;id&quot;:&quot;model_doc/segformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/segformer&quot;},{&quot;title&quot;:&quot;SwiftFormer&quot;,&quot;id&quot;:&quot;model_doc/swiftformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swiftformer&quot;},{&quot;title&quot;:&quot;Swin Transformer&quot;,&quot;id&quot;:&quot;model_doc/swin&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin&quot;},{&quot;title&quot;:&quot;Swin Transformer V2&quot;,&quot;id&quot;:&quot;model_doc/swinv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swinv2&quot;},{&quot;title&quot;:&quot;Swin2SR&quot;,&quot;id&quot;:&quot;model_doc/swin2sr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin2sr&quot;},{&quot;title&quot;:&quot;Table Transformer&quot;,&quot;id&quot;:&quot;model_doc/table-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/table-transformer&quot;},{&quot;title&quot;:&quot;TimeSformer&quot;,&quot;id&quot;:&quot;model_doc/timesformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/timesformer&quot;},{&quot;title&quot;:&quot;UperNet&quot;,&quot;id&quot;:&quot;model_doc/upernet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/upernet&quot;},{&quot;title&quot;:&quot;VAN&quot;,&quot;id&quot;:&quot;model_doc/van&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/van&quot;},{&quot;title&quot;:&quot;VideoMAE&quot;,&quot;id&quot;:&quot;model_doc/videomae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/videomae&quot;},{&quot;title&quot;:&quot;Vision Transformer (ViT)&quot;,&quot;id&quot;:&quot;model_doc/vit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit&quot;},{&quot;title&quot;:&quot;ViT Hybrid&quot;,&quot;id&quot;:&quot;model_doc/vit_hybrid&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_hybrid&quot;},{&quot;title&quot;:&quot;ViTDet&quot;,&quot;id&quot;:&quot;model_doc/vitdet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitdet&quot;},{&quot;title&quot;:&quot;ViTMAE&quot;,&quot;id&quot;:&quot;model_doc/vit_mae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_mae&quot;},{&quot;title&quot;:&quot;ViTMatte&quot;,&quot;id&quot;:&quot;model_doc/vitmatte&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitmatte&quot;},{&quot;title&quot;:&quot;ViTMSN&quot;,&quot;id&quot;:&quot;model_doc/vit_msn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_msn&quot;},{&quot;title&quot;:&quot;ViViT&quot;,&quot;id&quot;:&quot;model_doc/vivit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vivit&quot;},{&quot;title&quot;:&quot;YOLOS&quot;,&quot;id&quot;:&quot;model_doc/yolos&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yolos&quot;}]},{&quot;title&quot;:&quot;Audio models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio Spectrogram Transformer&quot;,&quot;id&quot;:&quot;model_doc/audio-spectrogram-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/audio-spectrogram-transformer&quot;},{&quot;title&quot;:&quot;Bark&quot;,&quot;id&quot;:&quot;model_doc/bark&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bark&quot;},{&quot;title&quot;:&quot;CLAP&quot;,&quot;id&quot;:&quot;model_doc/clap&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clap&quot;},{&quot;title&quot;:&quot;EnCodec&quot;,&quot;id&quot;:&quot;model_doc/encodec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encodec&quot;},{&quot;title&quot;:&quot;Hubert&quot;,&quot;id&quot;:&quot;model_doc/hubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/hubert&quot;},{&quot;title&quot;:&quot;MCTCT&quot;,&quot;id&quot;:&quot;model_doc/mctct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mctct&quot;},{&quot;title&quot;:&quot;MMS&quot;,&quot;id&quot;:&quot;model_doc/mms&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mms&quot;},{&quot;title&quot;:&quot;MusicGen&quot;,&quot;id&quot;:&quot;model_doc/musicgen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/musicgen&quot;},{&quot;title&quot;:&quot;Pop2Piano&quot;,&quot;id&quot;:&quot;model_doc/pop2piano&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pop2piano&quot;},{&quot;title&quot;:&quot;SEW&quot;,&quot;id&quot;:&quot;model_doc/sew&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew&quot;},{&quot;title&quot;:&quot;SEW-D&quot;,&quot;id&quot;:&quot;model_doc/sew-d&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew-d&quot;},{&quot;title&quot;:&quot;Speech2Text&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text&quot;},{&quot;title&quot;:&quot;Speech2Text2&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text_2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text_2&quot;},{&quot;title&quot;:&quot;SpeechT5&quot;,&quot;id&quot;:&quot;model_doc/speecht5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speecht5&quot;},{&quot;title&quot;:&quot;UniSpeech&quot;,&quot;id&quot;:&quot;model_doc/unispeech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech&quot;},{&quot;title&quot;:&quot;UniSpeech-SAT&quot;,&quot;id&quot;:&quot;model_doc/unispeech-sat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech-sat&quot;},{&quot;title&quot;:&quot;VITS&quot;,&quot;id&quot;:&quot;model_doc/vits&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vits&quot;},{&quot;title&quot;:&quot;Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2&quot;},{&quot;title&quot;:&quot;Wav2Vec2-Conformer&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2-conformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2-conformer&quot;},{&quot;title&quot;:&quot;Wav2Vec2Phoneme&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2_phoneme&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2_phoneme&quot;},{&quot;title&quot;:&quot;WavLM&quot;,&quot;id&quot;:&quot;model_doc/wavlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wavlm&quot;},{&quot;title&quot;:&quot;Whisper&quot;,&quot;id&quot;:&quot;model_doc/whisper&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/whisper&quot;},{&quot;title&quot;:&quot;XLS-R&quot;,&quot;id&quot;:&quot;model_doc/xls_r&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xls_r&quot;},{&quot;title&quot;:&quot;XLSR-Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/xlsr_wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlsr_wav2vec2&quot;}]},{&quot;title&quot;:&quot;Multimodal models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALIGN&quot;,&quot;id&quot;:&quot;model_doc/align&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/align&quot;},{&quot;title&quot;:&quot;AltCLIP&quot;,&quot;id&quot;:&quot;model_doc/altclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/altclip&quot;},{&quot;title&quot;:&quot;BLIP&quot;,&quot;id&quot;:&quot;model_doc/blip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip&quot;},{&quot;title&quot;:&quot;BLIP-2&quot;,&quot;id&quot;:&quot;model_doc/blip-2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip-2&quot;},{&quot;title&quot;:&quot;BridgeTower&quot;,&quot;id&quot;:&quot;model_doc/bridgetower&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bridgetower&quot;},{&quot;title&quot;:&quot;BROS&quot;,&quot;id&quot;:&quot;model_doc/bros&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bros&quot;},{&quot;title&quot;:&quot;Chinese-CLIP&quot;,&quot;id&quot;:&quot;model_doc/chinese_clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/chinese_clip&quot;},{&quot;title&quot;:&quot;CLIP&quot;,&quot;id&quot;:&quot;model_doc/clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clip&quot;},{&quot;title&quot;:&quot;CLIPSeg&quot;,&quot;id&quot;:&quot;model_doc/clipseg&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clipseg&quot;},{&quot;title&quot;:&quot;Data2Vec&quot;,&quot;id&quot;:&quot;model_doc/data2vec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/data2vec&quot;},{&quot;title&quot;:&quot;DePlot&quot;,&quot;id&quot;:&quot;model_doc/deplot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deplot&quot;},{&quot;title&quot;:&quot;Donut&quot;,&quot;id&quot;:&quot;model_doc/donut&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/donut&quot;},{&quot;title&quot;:&quot;FLAVA&quot;,&quot;id&quot;:&quot;model_doc/flava&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flava&quot;},{&quot;title&quot;:&quot;GIT&quot;,&quot;id&quot;:&quot;model_doc/git&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/git&quot;},{&quot;title&quot;:&quot;GroupViT&quot;,&quot;id&quot;:&quot;model_doc/groupvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/groupvit&quot;},{&quot;title&quot;:&quot;IDEFICS&quot;,&quot;id&quot;:&quot;model_doc/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/idefics&quot;},{&quot;title&quot;:&quot;InstructBLIP&quot;,&quot;id&quot;:&quot;model_doc/instructblip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/instructblip&quot;},{&quot;title&quot;:&quot;LayoutLM&quot;,&quot;id&quot;:&quot;model_doc/layoutlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlm&quot;},{&quot;title&quot;:&quot;LayoutLMV2&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv2&quot;},{&quot;title&quot;:&quot;LayoutLMV3&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv3&quot;},{&quot;title&quot;:&quot;LayoutXLM&quot;,&quot;id&quot;:&quot;model_doc/layoutxlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutxlm&quot;},{&quot;title&quot;:&quot;LiLT&quot;,&quot;id&quot;:&quot;model_doc/lilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lilt&quot;},{&quot;title&quot;:&quot;LXMERT&quot;,&quot;id&quot;:&quot;model_doc/lxmert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lxmert&quot;},{&quot;title&quot;:&quot;MatCha&quot;,&quot;id&quot;:&quot;model_doc/matcha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/matcha&quot;},{&quot;title&quot;:&quot;MGP-STR&quot;,&quot;id&quot;:&quot;model_doc/mgp-str&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mgp-str&quot;},{&quot;title&quot;:&quot;Nougat&quot;,&quot;id&quot;:&quot;model_doc/nougat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nougat&quot;},{&quot;title&quot;:&quot;OneFormer&quot;,&quot;id&quot;:&quot;model_doc/oneformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/oneformer&quot;},{&quot;title&quot;:&quot;OWL-ViT&quot;,&quot;id&quot;:&quot;model_doc/owlvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/owlvit&quot;},{&quot;title&quot;:&quot;Perceiver&quot;,&quot;id&quot;:&quot;model_doc/perceiver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/perceiver&quot;},{&quot;title&quot;:&quot;Pix2Struct&quot;,&quot;id&quot;:&quot;model_doc/pix2struct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pix2struct&quot;},{&quot;title&quot;:&quot;Segment Anything&quot;,&quot;id&quot;:&quot;model_doc/sam&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sam&quot;},{&quot;title&quot;:&quot;Speech Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/speech-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech-encoder-decoder&quot;},{&quot;title&quot;:&quot;TAPAS&quot;,&quot;id&quot;:&quot;model_doc/tapas&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapas&quot;},{&quot;title&quot;:&quot;TrOCR&quot;,&quot;id&quot;:&quot;model_doc/trocr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trocr&quot;},{&quot;title&quot;:&quot;TVLT&quot;,&quot;id&quot;:&quot;model_doc/tvlt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tvlt&quot;},{&quot;title&quot;:&quot;ViLT&quot;,&quot;id&quot;:&quot;model_doc/vilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vilt&quot;},{&quot;title&quot;:&quot;Vision Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/vision-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-encoder-decoder&quot;},{&quot;title&quot;:&quot;Vision Text Dual Encoder&quot;,&quot;id&quot;:&quot;model_doc/vision-text-dual-encoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-text-dual-encoder&quot;},{&quot;title&quot;:&quot;VisualBERT&quot;,&quot;id&quot;:&quot;model_doc/visual_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/visual_bert&quot;},{&quot;title&quot;:&quot;X-CLIP&quot;,&quot;id&quot;:&quot;model_doc/xclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xclip&quot;}]},{&quot;title&quot;:&quot;Reinforcement learning models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Decision Transformer&quot;,&quot;id&quot;:&quot;model_doc/decision_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/decision_transformer&quot;},{&quot;title&quot;:&quot;Trajectory Transformer&quot;,&quot;id&quot;:&quot;model_doc/trajectory_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trajectory_transformer&quot;}]},{&quot;title&quot;:&quot;Time series models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Autoformer&quot;,&quot;id&quot;:&quot;model_doc/autoformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/autoformer&quot;},{&quot;title&quot;:&quot;Informer&quot;,&quot;id&quot;:&quot;model_doc/informer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/informer&quot;},{&quot;title&quot;:&quot;Time Series Transformer&quot;,&quot;id&quot;:&quot;model_doc/time_series_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/time_series_transformer&quot;}]},{&quot;title&quot;:&quot;Graph models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Graphormer&quot;,&quot;id&quot;:&quot;model_doc/graphormer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/graphormer&quot;}]}]},{&quot;title&quot;:&quot;Internal Helpers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Custom Layers and Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/modeling_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/modeling_utils&quot;},{&quot;title&quot;:&quot;Utilities for pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/pipelines_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/pipelines_utils&quot;},{&quot;title&quot;:&quot;Utilities for Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/tokenization_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/tokenization_utils&quot;},{&quot;title&quot;:&quot;Utilities for Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/trainer_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/trainer_utils&quot;},{&quot;title&quot;:&quot;Utilities for Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/generation_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/generation_utils&quot;},{&quot;title&quot;:&quot;Utilities for Image Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/image_processing_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/image_processing_utils&quot;},{&quot;title&quot;:&quot;Utilities for Audio processing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/audio_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/audio_utils&quot;},{&quot;title&quot;:&quot;General Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/file_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/file_utils&quot;},{&quot;title&quot;:&quot;Utilities for Time Series&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/time_series_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/time_series_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;internal/audio_utils&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;de&quot;,&quot;en&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;ko&quot;,&quot;pt&quot;,&quot;zh&quot;],&quot;library&quot;:&quot;transformers&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v4.34.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v4.34.0&quot;},{&quot;version&quot;:&quot;v4.33.3&quot;},{&quot;version&quot;:&quot;v4.33.2&quot;},{&quot;version&quot;:&quot;v4.33.0&quot;},{&quot;version&quot;:&quot;v4.32.1&quot;},{&quot;version&quot;:&quot;v4.32.0&quot;},{&quot;version&quot;:&quot;v4.31.0&quot;},{&quot;version&quot;:&quot;v4.30.0&quot;},{&quot;version&quot;:&quot;v4.29.1&quot;},{&quot;version&quot;:&quot;v4.29.0&quot;},{&quot;version&quot;:&quot;v4.28.1&quot;},{&quot;version&quot;:&quot;v4.28.0&quot;},{&quot;version&quot;:&quot;v4.27.2&quot;},{&quot;version&quot;:&quot;v4.27.1&quot;},{&quot;version&quot;:&quot;v4.27.0&quot;},{&quot;version&quot;:&quot;v4.26.1&quot;},{&quot;version&quot;:&quot;v4.26.0&quot;},{&quot;version&quot;:&quot;v4.25.1&quot;},{&quot;version&quot;:&quot;v4.24.0&quot;},{&quot;version&quot;:&quot;v4.23.1&quot;},{&quot;version&quot;:&quot;v4.23.0&quot;},{&quot;version&quot;:&quot;v4.22.2&quot;},{&quot;version&quot;:&quot;v4.22.1&quot;},{&quot;version&quot;:&quot;v4.22.0&quot;},{&quot;version&quot;:&quot;v4.21.3&quot;},{&quot;version&quot;:&quot;v4.21.2&quot;},{&quot;version&quot;:&quot;v4.21.1&quot;},{&quot;version&quot;:&quot;v4.21.0&quot;},{&quot;version&quot;:&quot;v4.20.1&quot;},{&quot;version&quot;:&quot;v4.20.0&quot;},{&quot;version&quot;:&quot;v4.19.4&quot;},{&quot;version&quot;:&quot;v4.19.3&quot;},{&quot;version&quot;:&quot;v4.19.2&quot;},{&quot;version&quot;:&quot;v4.19.0&quot;},{&quot;version&quot;:&quot;v4.18.0&quot;},{&quot;version&quot;:&quot;v4.17.0&quot;},{&quot;version&quot;:&quot;v4.16.2&quot;},{&quot;version&quot;:&quot;v4.16.1&quot;},{&quot;version&quot;:&quot;v4.16.0&quot;},{&quot;version&quot;:&quot;v4.15.0&quot;},{&quot;version&quot;:&quot;v4.14.1&quot;},{&quot;version&quot;:&quot;v4.13.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.5&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.4&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.0.0&quot;},{&quot;version&quot;:&quot;doc-builder-html&quot;}],&quot;title&quot;:&quot;Utilities for `FeatureExtractors`&quot;}\" data-target=\"SideMenu\">\\n\\n\\n\\n\\n\\n\\n\\n<div class=\"z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false\"><div class=\"shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden\">\\n\\t\\t<div class=\"flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6\"><p class=\"text-sm text-gray-400 first-letter:capitalize\">Transformers documentation\\n\\t\\t\\t</p>\\n\\t\\t\\t<div class=\"flex items-center\"><p class=\"font-semibold\">Utilities for `FeatureExtractors`</p>\\n\\t\\t\\t\\t<svg class=\"text-xl false\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></div></div>\\n\\t\\t<button class=\"hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2\"><svg class=\"text-gray-500 group-hover:text-gray-700\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg></button></div>\\n\\t<div class=\"hidden h-32 flex-col justify-between border-r border-b bg-white bg-gradient-to-r p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950\"><div class=\"relative \">\\n\\t<button class=\" \" type=\"button\">\\n\\t\\t\\n\\t\\t\\t\\t<h1 class=\"flex items-center text-lg font-bold leading-tight first-letter:capitalize\"><div class=\"mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none\"></div>\\n\\t\\t\\t\\t\\tTransformers\\n\\t\\t\\t\\t\\t<span><svg class=\"opacity-70 \" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></span></h1>\\n\\t\\t\\t\\n\\t\\t</button>\\n\\t\\n\\t\\n\\t\\n\\t</div>\\n\\t\\t<button class=\"shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500\"><svg class=\"flex-none mr-1.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t<div>Search documentation</div>\\n\\t\\t\\t</button>\\n\\t\\t<div class=\"flex items-center\">\\n\\t\\t\\t\\t<select class=\"form-input mr-1 !mt-0 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400\"><option value=\"0\">main</option><option value=\"1\" selected=\"\">v4.34.0</option><option value=\"2\">v4.33.3</option><option value=\"3\">v4.32.1</option><option value=\"4\">v4.31.0</option><option value=\"5\">v4.30.0</option><option value=\"6\">v4.29.1</option><option value=\"7\">v4.28.1</option><option value=\"8\">v4.27.2</option><option value=\"9\">v4.26.1</option><option value=\"10\">v4.25.1</option><option value=\"11\">v4.24.0</option><option value=\"12\">v4.23.1</option><option value=\"13\">v4.22.2</option><option value=\"14\">v4.21.3</option><option value=\"15\">v4.20.1</option><option value=\"16\">v4.19.4</option><option value=\"17\">v4.18.0</option><option value=\"18\">v4.17.0</option><option value=\"19\">v4.16.2</option><option value=\"20\">v4.15.0</option><option value=\"21\">v4.14.1</option><option value=\"22\">v4.13.0</option><option value=\"23\">v4.12.5</option><option value=\"24\">v4.11.3</option><option value=\"25\">v4.10.1</option><option value=\"26\">v4.9.2</option><option value=\"27\">v4.8.2</option><option value=\"28\">v4.7.0</option><option value=\"29\">v4.6.0</option><option value=\"30\">v4.5.1</option><option value=\"31\">v4.4.2</option><option value=\"32\">v4.3.3</option><option value=\"33\">v4.2.2</option><option value=\"34\">v4.1.1</option><option value=\"35\">v4.0.1</option><option value=\"36\">v3.5.1</option><option value=\"37\">v3.4.0</option><option value=\"38\">v3.3.1</option><option value=\"39\">v3.2.0</option><option value=\"40\">v3.1.0</option><option value=\"41\">v3.0.2</option><option value=\"42\">v2.11.0</option><option value=\"43\">v2.10.0</option><option value=\"44\">v2.9.1</option><option value=\"45\">v2.8.0</option><option value=\"46\">v2.7.0</option><option value=\"47\">v2.6.0</option><option value=\"48\">v2.5.1</option><option value=\"49\">v2.4.1</option><option value=\"50\">v2.3.0</option><option value=\"51\">v2.2.2</option><option value=\"52\">v2.1.1</option><option value=\"53\">v2.0.0</option><option value=\"54\">v1.2.0</option><option value=\"55\">v1.1.0</option><option value=\"56\">v1.0.0</option><option value=\"57\">doc-builder-html</option></select>\\n\\t\\t\\t\\n\\t\\t\\t<select class=\"form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border\"><option value=\"de\">DE</option><option value=\"en\" selected=\"\">EN</option><option value=\"es\">ES</option><option value=\"fr\">FR</option><option value=\"it\">IT</option><option value=\"ko\">KO</option><option value=\"pt\">PT</option><option value=\"zh\">ZH</option></select>\\n\\t\\t\\t\\n<div class=\"relative inline-block\">\\n\\t<button class=\"rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 \" type=\"button\">\\n\\t\\t<svg class=\"mr-1.5 text-yellow-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\" fill=\"currentColor\"><path d=\"M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z\"></path></svg>\\n\\t\\t\\t\\n\\t\\t</button>\\n\\t\\n\\t\\n\\t\\n\\t</div>\\n\\t\\t\\t<a href=\"https://github.com/huggingface/transformers\" class=\"group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300\"><svg class=\"inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1.03em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 250\"><path d=\"M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z\" fill=\"currentColor\"></path></svg>\\n\\t\\t\\t\\t</a></div></div>\\n\\n\\t<nav class=\"top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pt-3 pb-16 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]\">\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Get started<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/index\"><!-- HTML_TAG_START -->🤗 Transformers<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/quicktour\"><!-- HTML_TAG_START -->Quick tour<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/installation\"><!-- HTML_TAG_START -->Installation<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Tutorials<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_tutorial\"><!-- HTML_TAG_START -->Run inference with pipelines<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/autoclass_tutorial\"><!-- HTML_TAG_START -->Write portable code with AutoClass<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/preprocessing\"><!-- HTML_TAG_START -->Preprocess data<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/training\"><!-- HTML_TAG_START -->Fine-tune a pretrained model<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/run_scripts\"><!-- HTML_TAG_START -->Train with a script<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/accelerate\"><!-- HTML_TAG_START -->Set up distributed training with 🤗 Accelerate<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/peft\"><!-- HTML_TAG_START -->Load and train adapters with 🤗 PEFT<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_sharing\"><!-- HTML_TAG_START -->Share your model<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/transformers_agents\"><!-- HTML_TAG_START -->Agents<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/llm_tutorial\"><!-- HTML_TAG_START -->Generation with LLMs<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Task Guides<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\">\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Natural Language Processing<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Audio<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Computer Vision<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Multimodal<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Generation<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Prompting<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Developer guides<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/fast_tokenizers\"><!-- HTML_TAG_START -->Use fast tokenizers from 🤗 Tokenizers<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/multilingual\"><!-- HTML_TAG_START -->Run inference with multilingual models<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/create_a_model\"><!-- HTML_TAG_START -->Use model-specific APIs<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_models\"><!-- HTML_TAG_START -->Share a custom model<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/chat_templating\"><!-- HTML_TAG_START -->Templates for chat models<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/sagemaker\"><!-- HTML_TAG_START -->Run training on Amazon SageMaker<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/serialization\"><!-- HTML_TAG_START -->Export to ONNX<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tflite\"><!-- HTML_TAG_START -->Export to TFLite<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/torchscript\"><!-- HTML_TAG_START -->Export to TorchScript<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/benchmarks\"><!-- HTML_TAG_START -->Benchmarks<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/notebooks\"><!-- HTML_TAG_START -->Notebooks with examples<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/community\"><!-- HTML_TAG_START -->Community resources<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_tools\"><!-- HTML_TAG_START -->Custom Tools and Prompts<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/troubleshooting\"><!-- HTML_TAG_START -->Troubleshoot<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Performance and scalability<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/performance\"><!-- HTML_TAG_START -->Overview<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Efficient training techniques<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_one\"><!-- HTML_TAG_START -->Methods and tools for efficient training on a single GPU<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_many\"><!-- HTML_TAG_START -->Multiple GPUs and parallelism<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu\"><!-- HTML_TAG_START -->Efficient training on CPU<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu_many\"><!-- HTML_TAG_START -->Distributed CPU training<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu\"><!-- HTML_TAG_START -->Training on TPUs<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu_tf\"><!-- HTML_TAG_START -->Training on TPU with TensorFlow<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_special\"><!-- HTML_TAG_START -->Training on Specialized Hardware<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_hardware\"><!-- HTML_TAG_START -->Custom hardware for training<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/hpo_train\"><!-- HTML_TAG_START -->Hyperparameter Search using Trainer API<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Optimizing inference<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_cpu\"><!-- HTML_TAG_START -->Inference on CPU<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_one\"><!-- HTML_TAG_START -->Inference on one GPU<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_many\"><!-- HTML_TAG_START -->Inference on many GPUs<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_special\"><!-- HTML_TAG_START -->Inference on Specialized Hardware<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/big_models\"><!-- HTML_TAG_START -->Instantiating a big model<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/debugging\"><!-- HTML_TAG_START -->Troubleshooting<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tf_xla\"><!-- HTML_TAG_START -->XLA Integration for TensorFlow Models<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perf_torch_compile\"><!-- HTML_TAG_START -->Optimize inference using `torch.compile()`<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Contribute<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/contributing\"><!-- HTML_TAG_START -->How to contribute to transformers?<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_model\"><!-- HTML_TAG_START -->How to add a model to 🤗 Transformers?<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_tensorflow_model\"><!-- HTML_TAG_START -->How to convert a 🤗 Transformers model to TensorFlow?<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_pipeline\"><!-- HTML_TAG_START -->How to add a pipeline to 🤗 Transformers?<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/testing\"><!-- HTML_TAG_START -->Testing<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pr_checks\"><!-- HTML_TAG_START -->Checks on a Pull Request<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Conceptual guides<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/philosophy\"><!-- HTML_TAG_START -->Philosophy<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/glossary\"><!-- HTML_TAG_START -->Glossary<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/task_summary\"><!-- HTML_TAG_START -->What 🤗 Transformers can do<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tasks_explained\"><!-- HTML_TAG_START -->How 🤗 Transformers solve tasks<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_summary\"><!-- HTML_TAG_START -->The Transformer model family<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tokenizer_summary\"><!-- HTML_TAG_START -->Summary of the tokenizers<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/attention\"><!-- HTML_TAG_START -->Attention mechanisms<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pad_truncation\"><!-- HTML_TAG_START -->Padding and truncation<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/bertology\"><!-- HTML_TAG_START -->BERTology<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perplexity\"><!-- HTML_TAG_START -->Perplexity of fixed-length models<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_webserver\"><!-- HTML_TAG_START -->Pipelines for webserver inference<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_memory_anatomy\"><!-- HTML_TAG_START -->Model training anatomy<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->API<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\">\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Main Classes<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/agent\"><!-- HTML_TAG_START -->Agents and Tools<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/model_doc/auto\"><!-- HTML_TAG_START -->Auto Classes<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/callback\"><!-- HTML_TAG_START -->Callbacks<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/configuration\"><!-- HTML_TAG_START -->Configuration<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/data_collator\"><!-- HTML_TAG_START -->Data Collator<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/keras_callbacks\"><!-- HTML_TAG_START -->Keras callbacks<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/logging\"><!-- HTML_TAG_START -->Logging<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/model\"><!-- HTML_TAG_START -->Models<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/text_generation\"><!-- HTML_TAG_START -->Text Generation<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/onnx\"><!-- HTML_TAG_START -->ONNX<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules\"><!-- HTML_TAG_START -->Optimization<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/output\"><!-- HTML_TAG_START -->Model outputs<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/pipelines\"><!-- HTML_TAG_START -->Pipelines<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/processors\"><!-- HTML_TAG_START -->Processors<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/quantization\"><!-- HTML_TAG_START -->Quantization<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer\"><!-- HTML_TAG_START -->Tokenizer<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/trainer\"><!-- HTML_TAG_START -->Trainer<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/deepspeed\"><!-- HTML_TAG_START -->DeepSpeed Integration<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/feature_extractor\"><!-- HTML_TAG_START -->Feature Extractor<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/image_processor\"><!-- HTML_TAG_START -->Image Processor<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\">\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Text models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Vision models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Audio models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Multimodal models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Reinforcement learning models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Time series models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Graph models<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t\\n\\t\\t\\t</div>\\n\\t\\t<div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span><!-- HTML_TAG_START -->Internal Helpers<!-- HTML_TAG_END --></span>\\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</span></span>\\n\\t\\t\\t</div></div>\\n\\t\\t<div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/modeling_utils\"><!-- HTML_TAG_START -->Custom Layers and Utilities<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/pipelines_utils\"><!-- HTML_TAG_START -->Utilities for pipelines<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/tokenization_utils\"><!-- HTML_TAG_START -->Utilities for Tokenizers<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/trainer_utils\"><!-- HTML_TAG_START -->Utilities for Trainer<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/generation_utils\"><!-- HTML_TAG_START -->Utilities for Generation<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/image_processing_utils\"><!-- HTML_TAG_START -->Utilities for Image Processors<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pr-2 pl-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/audio_utils\"><!-- HTML_TAG_START -->Utilities for Audio processing<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/file_utils\"><!-- HTML_TAG_START -->General Utilities<!-- HTML_TAG_END -->\\n\\t\\t</a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/time_series_utils\"><!-- HTML_TAG_START -->Utilities for Time Series<!-- HTML_TAG_END -->\\n\\t\\t</a>\\n\\t\\t\\t</div>\\n\\t\\t\\t</div></nav></div></div></div>\\n\\t\\t<div class=\"z-1 min-w-0 flex-1\">\\n\\t\\t\\t<div class=\"px-6 pt-6 md:px-12 md:pt-16 md:pb-16\"><div class=\"max-w-4xl mx-auto mb-10\"><div class=\"relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 py-5 px-4 ring-1 ring-orange-100/70 md:px-6 md:py-8\"><img alt=\"Hugging Face\\'s logo\" class=\"absolute -right-6 -bottom-6 w-28 -rotate-45 md:hidden\" src=\"/front/assets/huggingface_logo-noborder.svg\">\\n\\t\\t<div class=\"mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0\">Join the Hugging Face community</div>\\n\\t\\t<p class=\"mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8\">and get access to the augmented documentation experience\\n\\t\\t</p>\\n\\t\\t<div class=\"mb-8 hidden space-y-4 md:block xl:flex xl:space-y-0 xl:space-x-6\"><div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100\"><svg class=\"text-indigo-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Collaborate on models, datasets and Spaces\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"text-xl text-yellow-400\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M11 15H6l7-14v8h5l-7 14v-8z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Faster examples with accelerated inference\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5\"><svg class=\"text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Switch between documentation themes\\n\\t\\t\\t\\t</div></div></div>\\n\\t\\t<div class=\"flex items-center space-x-2.5\"><a href=\"/join\"><button class=\"rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 py-1.5 px-5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner\">Sign Up</button></a>\\n\\t\\t\\t<p class=\"text-gray-500 dark:text-gray-300\">to get started</p></div></div></div>\\n\\t\\t\\t\\t<div class=\"prose-doc prose relative mx-auto max-w-4xl break-words\"><!-- HTML_TAG_START -->\\t\\t<link href=\"/docs/transformers/v4.34.0/en/_app/immutable/assets/0.e3b0c442.css\" rel=\"modulepreload\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/entry/start.c2db227a.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/scheduler.9bc65507.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/singletons.e3057404.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/index.3b203c72.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/paths.e7de6301.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/entry/app.879d9b87.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/index.78c82d43.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/nodes/0.242aaaff.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/each.e59479a4.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/nodes/24.e1e368ed.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/Docstring.4e7352e2.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/globals.7f7f1b26.js\">\\n\\t\\t<link rel=\"modulepreload\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/chunks/IconCopyLink.bedaa44d.js\"><!-- HEAD_svelte-1phssyn_START --><meta name=\"hf:doc:metadata\" content=\"{&quot;local&quot;:&quot;utilities-for-featureextractors&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;transformers.audio_utils.hertz_to_mel&quot;,&quot;title&quot;:&quot;Audio Transformations&quot;}],&quot;title&quot;:&quot;Utilities for `FeatureExtractors`&quot;}\"><!-- HEAD_svelte-1phssyn_END -->     <p></p>  <h1 class=\"relative group\"><a id=\"utilities-for-featureextractors\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#utilities-for-featureextractors\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-86ckkg\">Utilities for <code>FeatureExtractors</code></span></h1> <p data-svelte-h=\"svelte-sdayy0\">This page lists all the utility functions that can be used by the audio <code>FeatureExtractor</code> in order to compute special features from a raw audio using common algorithms such as <em>Short Time Fourier Transform</em> or <em>log mel spectrogram</em>.</p> <p data-svelte-h=\"svelte-1o3lpho\">Most of those are only useful if you are studying the code of the audio processors in the library.</p> <h2 class=\"relative group\"><a id=\"transformers.audio_utils.hertz_to_mel\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.hertz_to_mel\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1ju3eab\">Audio Transformations</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.hertz_to_mel\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.hertz_to_mel</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.hertz_to_mel\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.hertz_to_mel\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L25\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">freq<span class=\"opacity-60\">: typing.Union[float, numpy.ndarray]</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mel_scale<span class=\"opacity-60\">: str = \\'htk\\'</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><!-- HTML_TAG_START --><span><code>float</code> or <code>np.ndarray</code></span><!-- HTML_TAG_END --></span></p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.hertz_to_mel.freq\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.hertz_to_mel.freq\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>freq</strong> (<code>float</code> or <code>np.ndarray</code>) —\\nThe frequency, or multiple frequencies, in hertz (Hz).<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.hertz_to_mel.mel_scale\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.hertz_to_mel.mel_scale\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>mel_scale</strong> (<code>str</code>, <em>optional</em>, defaults to <code>\"htk\"</code>) —\\nThe mel frequency scale to use, <code>\"htk\"</code>, <code>\"kaldi\"</code> or <code>\"slaney\"</code>.<!-- HTML_TAG_END --> </span></span> </li></ul>  <div id=\"transformers.audio_utils.hertz_to_mel.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> <!-- HTML_TAG_START -->\\n<p><code>float</code> or <code>np.ndarray</code></p>\\n<!-- HTML_TAG_END --> <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\"><!-- HTML_TAG_START -->\\n</p><p>The frequencies on the mel scale.</p>\\n<!-- HTML_TAG_END --><p></p> </div></div> <p data-svelte-h=\"svelte-cxvipk\">Convert frequency from hertz to mels.</p></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.mel_to_hertz\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.mel_to_hertz</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.mel_to_hertz\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.mel_to_hertz\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L61\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mels<span class=\"opacity-60\">: typing.Union[float, numpy.ndarray]</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mel_scale<span class=\"opacity-60\">: str = \\'htk\\'</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><!-- HTML_TAG_START --><span><code>float</code> or <code>np.ndarray</code></span><!-- HTML_TAG_END --></span></p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_to_hertz.mels\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_to_hertz.mels\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>mels</strong> (<code>float</code> or <code>np.ndarray</code>) —\\nThe frequency, or multiple frequencies, in mels.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_to_hertz.mel_scale\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_to_hertz.mel_scale\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>mel_scale</strong> (<code>str</code>, <em>optional</em>, <code>\"htk\"</code>) —\\nThe mel frequency scale to use, <code>\"htk\"</code>, <code>\"kaldi\"</code> or <code>\"slaney\"</code>.<!-- HTML_TAG_END --> </span></span> </li></ul>  <div id=\"transformers.audio_utils.mel_to_hertz.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> <!-- HTML_TAG_START -->\\n<p><code>float</code> or <code>np.ndarray</code></p>\\n<!-- HTML_TAG_END --> <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\"><!-- HTML_TAG_START -->\\n</p><p>The frequencies in hertz.</p>\\n<!-- HTML_TAG_END --><p></p> </div></div> <p data-svelte-h=\"svelte-zjf634\">Convert frequency from mels to hertz.</p></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.mel_filter_bank\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.mel_filter_bank</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.mel_filter_bank\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.mel_filter_bank\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L119\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_frequency_bins<span class=\"opacity-60\">: int</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_mel_filters<span class=\"opacity-60\">: int</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">min_frequency<span class=\"opacity-60\">: float</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">max_frequency<span class=\"opacity-60\">: float</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">sampling_rate<span class=\"opacity-60\">: int</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">norm<span class=\"opacity-60\">: typing.Optional[str] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mel_scale<span class=\"opacity-60\">: str = \\'htk\\'</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">triangularize_in_mel_space<span class=\"opacity-60\">: bool = False</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><!-- HTML_TAG_START --><span><code>np.ndarray</code> of shape (<code>num_frequency_bins</code>, <code>num_mel_filters</code>)</span><!-- HTML_TAG_END --></span></p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.num_frequency_bins\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.num_frequency_bins\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>num_frequency_bins</strong> (<code>int</code>) —\\nNumber of frequencies used to compute the spectrogram (should be the same as in <code>stft</code>).<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.num_mel_filters\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.num_mel_filters\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>num_mel_filters</strong> (<code>int</code>) —\\nNumber of mel filters to generate.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.min_frequency\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.min_frequency\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>min_frequency</strong> (<code>float</code>) —\\nLowest frequency of interest in Hz.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.max_frequency\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.max_frequency\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>max_frequency</strong> (<code>float</code>) —\\nHighest frequency of interest in Hz. This should not exceed <code>sampling_rate / 2</code>.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.sampling_rate\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.sampling_rate\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>sampling_rate</strong> (<code>int</code>) —\\nSample rate of the audio waveform.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.norm\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.norm\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>norm</strong> (<code>str</code>, <em>optional</em>) —\\nIf <code>\"slaney\"</code>, divide the triangular mel weights by the width of the mel band (area normalization).<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.mel_scale\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.mel_scale\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>mel_scale</strong> (<code>str</code>, <em>optional</em>, defaults to <code>\"htk\"</code>) —\\nThe mel frequency scale to use, <code>\"htk\"</code>, <code>\"kaldi\"</code> or <code>\"slaney\"</code>.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.mel_filter_bank.triangularize_in_mel_space\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.mel_filter_bank.triangularize_in_mel_space\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>triangularize_in_mel_space</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) —\\nIf this option is enabled, the triangular filter is applied in mel space rather than frequency space. This\\nshould be set to <code>true</code> in order to get the same results as <code>torchaudio</code> when computing mel filters.<!-- HTML_TAG_END --> </span></span> </li></ul>  <div id=\"transformers.audio_utils.mel_filter_bank.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> <!-- HTML_TAG_START -->\\n<p><code>np.ndarray</code> of shape (<code>num_frequency_bins</code>, <code>num_mel_filters</code>)</p>\\n<!-- HTML_TAG_END --> <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\"><!-- HTML_TAG_START -->\\n</p><p>Triangular filter bank matrix. This is a\\nprojection matrix to go from a spectrogram to a mel spectrogram.</p>\\n<!-- HTML_TAG_END --><p></p> </div></div> <p data-svelte-h=\"svelte-ke4v6b\">Creates a frequency bin conversion matrix used to obtain a mel spectrogram. This is called a <em>mel filter bank</em>, and\\nvarious implementation exist, which differ in the number of filters, the shape of the filters, the way the filters\\nare spaced, the bandwidth of the filters, and the manner in which the spectrum is warped. The goal of these\\nfeatures is to approximate the non-linear human perception of the variation in pitch with respect to the frequency.</p> <p data-svelte-h=\"svelte-1qgwg3t\">Different banks of mel filters were introduced in the literature. The following variations are supported:</p> <ul data-svelte-h=\"svelte-hp9cn6\"><li>MFCC FB-20: introduced in 1980 by Davis and Mermelstein, it assumes a sampling frequency of 10 kHz and a speech\\nbandwidth of <code>[0, 4600]</code> Hz.</li> <li>MFCC FB-24 HTK: from the Cambridge HMM Toolkit (HTK) (1995) uses a filter bank of 24 filters for a speech\\nbandwidth of <code>[0, 8000]</code> Hz. This assumes sampling rate ≥ 16 kHz.</li> <li>MFCC FB-40: from the Auditory Toolbox for MATLAB written by Slaney in 1998, assumes a sampling rate of 16 kHz and\\nspeech bandwidth of <code>[133, 6854]</code> Hz. This version also includes area normalization.</li> <li>HFCC-E FB-29 (Human Factor Cepstral Coefficients) of Skowronski and Harris (2004), assumes a sampling rate of\\n12.5 kHz and speech bandwidth of <code>[0, 6250]</code> Hz.</li></ul> <p data-svelte-h=\"svelte-7p7meu\">This code is adapted from <em>torchaudio</em> and <em>librosa</em>. Note that the default parameters of torchaudio’s\\n<code>melscale_fbanks</code> implement the <code>\"htk\"</code> filters while librosa uses the <code>\"slaney\"</code> implementation.</p></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.optimal_fft_length\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.optimal_fft_length</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.optimal_fft_length\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.optimal_fft_length\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L207\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">window_length<span class=\"opacity-60\">: int</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p>  <div class=\"!mb-10 relative docstring-details \">    </div></div> <p data-svelte-h=\"svelte-7kwh1t\">Finds the best FFT input size for a given <code>window_length</code>. This function takes a given window length and, if not\\nalready a power of two, rounds it up to the next power or two.</p> <p data-svelte-h=\"svelte-iy5srj\">The FFT algorithm works fastest when the length of the input is a power of two, which may be larger than the size\\nof the window or analysis frame. For example, if the window is 400 samples, using an FFT input size of 512 samples\\nis more optimal than an FFT size of 400 samples. Using a larger FFT size does not affect the detected frequencies,\\nit simply gives a higher frequency resolution (i.e. the frequency bins are smaller).</p></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.window_function\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.window_function</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.window_function\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.window_function\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L220\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">window_length<span class=\"opacity-60\">: int</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">name<span class=\"opacity-60\">: str = \\'hann\\'</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">periodic<span class=\"opacity-60\">: bool = True</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">frame_length<span class=\"opacity-60\">: typing.Optional[int] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">center<span class=\"opacity-60\">: bool = True</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.window_function.window_length\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.window_function.window_length\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>window_length</strong> (<code>int</code>) —\\nThe length of the window in samples.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.window_function.name\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.window_function.name\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>name</strong> (<code>str</code>, <em>optional</em>, defaults to <code>\"hann\"</code>) —\\nThe name of the window function.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.window_function.periodic\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.window_function.periodic\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>periodic</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether the window is periodic or symmetric.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.window_function.frame_length\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.window_function.frame_length\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>frame_length</strong> (<code>int</code>, <em>optional</em>) —\\nThe length of the analysis frames in samples. Provide a value for <code>frame_length</code> if the window is smaller\\nthan the frame length, so that it will be zero-padded.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.window_function.center\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.window_function.center\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>center</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether to center the window inside the FFT buffer. Only used when <code>frame_length</code> is provided.<!-- HTML_TAG_END --> </span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-1ws351k\">Returns an array containing the specified window. This window is intended to be used with <code>stft</code>.</p> <p data-svelte-h=\"svelte-tutl6h\">The following window types are supported:</p> <ul data-svelte-h=\"svelte-1wr1sb5\"><li><code>\"boxcar\"</code>: a rectangular window</li> <li><code>\"hamming\"</code>: the Hamming window</li> <li><code>\"hann\"</code>: the Hann window</li> <li><code>\"povey\"</code>: the Povey window</li></ul></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.spectrogram\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.spectrogram</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.spectrogram\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.spectrogram\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L284\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">waveform<span class=\"opacity-60\">: ndarray</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">window<span class=\"opacity-60\">: ndarray</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">frame_length<span class=\"opacity-60\">: int</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">hop_length<span class=\"opacity-60\">: int</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">fft_length<span class=\"opacity-60\">: typing.Optional[int] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">power<span class=\"opacity-60\">: typing.Optional[float] = 1.0</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">center<span class=\"opacity-60\">: bool = True</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">pad_mode<span class=\"opacity-60\">: str = \\'reflect\\'</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">onesided<span class=\"opacity-60\">: bool = True</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">preemphasis<span class=\"opacity-60\">: typing.Optional[float] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mel_filters<span class=\"opacity-60\">: typing.Optional[numpy.ndarray] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">mel_floor<span class=\"opacity-60\">: float = 1e-10</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">log_mel<span class=\"opacity-60\">: typing.Optional[str] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">reference<span class=\"opacity-60\">: float = 1.0</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">min_value<span class=\"opacity-60\">: float = 1e-10</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">db_range<span class=\"opacity-60\">: typing.Optional[float] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">remove_dc_offset<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">dtype<span class=\"opacity-60\">: dtype = &lt;class \\'numpy.float32\\'&gt;</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.waveform\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.waveform\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>waveform</strong> (<code>np.ndarray</code> of shape <code>(length,)</code>) —\\nThe input waveform. This must be a single real-valued, mono waveform.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.window\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.window\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>window</strong> (<code>np.ndarray</code> of shape <code>(frame_length,)</code>) —\\nThe windowing function to apply, including zero-padding if necessary. The actual window length may be\\nshorter than <code>frame_length</code>, but we’re assuming the array has already been zero-padded.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.frame_length\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.frame_length\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>frame_length</strong> (<code>int</code>) —\\nThe length of the analysis frames in samples. With librosa this is always equal to <code>fft_length</code> but we also\\nallow smaller sizes.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.hop_length\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.hop_length\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>hop_length</strong> (<code>int</code>) —\\nThe stride between successive analysis frames in samples.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.fft_length\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.fft_length\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>fft_length</strong> (<code>int</code>, <em>optional</em>) —\\nThe size of the FFT buffer in samples. This determines how many frequency bins the spectrogram will have.\\nFor optimal speed, this should be a power of two. If <code>None</code>, uses <code>frame_length</code>.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.power\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.power\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>power</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) —\\nIf 1.0, returns the amplitude spectrogram. If 2.0, returns the power spectrogram. If <code>None</code>, returns\\ncomplex numbers.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.center\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.center\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>center</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether to pad the waveform so that frame <code>t</code> is centered around time <code>t * hop_length</code>. If <code>False</code>, frame\\n<code>t</code> will start at time <code>t * hop_length</code>.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.pad_mode\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.pad_mode\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>pad_mode</strong> (<code>str</code>, <em>optional</em>, defaults to <code>\"reflect\"</code>) —\\nPadding mode used when <code>center</code> is <code>True</code>. Possible values are: <code>\"constant\"</code> (pad with zeros), <code>\"edge\"</code>\\n(pad with edge values), <code>\"reflect\"</code> (pads with mirrored values).<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.onesided\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.onesided\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>onesided</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nIf True, only computes the positive frequencies and returns a spectrogram containing <code>fft_length // 2 + 1</code>\\nfrequency bins. If False, also computes the negative frequencies and returns <code>fft_length</code> frequency bins.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.preemphasis\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.preemphasis\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>preemphasis</strong> (<code>float</code>, <em>optional</em>) —\\nCoefficient for a low-pass filter that applies pre-emphasis before the DFT.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.mel_filters\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.mel_filters\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>mel_filters</strong> (<code>np.ndarray</code> of shape <code>(num_freq_bins, num_mel_filters)</code>, <em>optional</em>) —\\nThe mel filter bank. If supplied, applies a this filter bank to create a mel spectrogram.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.mel_floor\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.mel_floor\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>mel_floor</strong> (<code>float</code>, <em>optional</em>, defaults to 1e-10) —\\nMinimum value of mel frequency banks.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.log_mel\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.log_mel\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>log_mel</strong> (<code>str</code>, <em>optional</em>) —\\nHow to convert the spectrogram to log scale. Possible options are: <code>None</code> (don’t convert), <code>\"log\"</code> (take\\nthe natural logarithm) <code>\"log10\"</code> (take the base-10 logarithm), <code>\"dB\"</code> (convert to decibels). Can only be\\nused when <code>power</code> is not <code>None</code>.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.reference\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.reference\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>reference</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) —\\nSets the input spectrogram value that corresponds to 0 dB. For example, use <code>np.max(spectrogram)</code> to set\\nthe loudest part to 0 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.min_value\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.min_value\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>min_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>1e-10</code>) —\\nThe spectrogram will be clipped to this minimum value before conversion to decibels, to avoid taking\\n<code>log(0)</code>. For a power spectrogram, the default of <code>1e-10</code> corresponds to a minimum of -100 dB. For an\\namplitude spectrogram, the value <code>1e-5</code> corresponds to -100 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.db_range\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.db_range\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>db_range</strong> (<code>float</code>, <em>optional</em>) —\\nSets the maximum dynamic range in decibels. For example, if <code>db_range = 80</code>, the difference between the\\npeak value and the smallest value will never be more than 80 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.remove_dc_offset\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.remove_dc_offset\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>remove_dc_offset</strong> (<code>bool</code>, <em>optional</em>) —\\nSubtract mean from waveform on each frame, applied before pre-emphasis. This should be set to <code>true</code> in\\norder to get the same results as <code>torchaudio.compliance.kaldi.fbank</code> when computing mel filters.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.spectrogram.dtype\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.spectrogram.dtype\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>dtype</strong> (<code>np.dtype</code>, <em>optional</em>, defaults to <code>np.float32</code>) —\\nData type of the spectrogram tensor. If <code>power</code> is None, this argument is ignored and the dtype will be\\n<code>np.complex64</code>.<!-- HTML_TAG_END --> </span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-10mwufd\">Calculates a spectrogram over one waveform using the Short-Time Fourier Transform.</p> <p data-svelte-h=\"svelte-zfp2ya\">This function can create the following kinds of spectrograms:</p> <ul data-svelte-h=\"svelte-14mziv8\"><li>amplitude spectrogram (<code>power = 1.0</code>)</li> <li>power spectrogram (<code>power = 2.0</code>)</li> <li>complex-valued spectrogram (<code>power = None</code>)</li> <li>log spectrogram (use <code>log_mel</code> argument)</li> <li>mel spectrogram (provide <code>mel_filters</code>)</li> <li>log-mel spectrogram (provide <code>mel_filters</code> and <code>log_mel</code>)</li></ul> <p data-svelte-h=\"svelte-axepee\">How this works:</p> <ol data-svelte-h=\"svelte-op5gf3\"><li>The input waveform is split into frames of size <code>frame_length</code> that are partially overlapping by `frame_length<ul><li>hop_length` samples.</li></ul></li> <li>Each frame is multiplied by the window and placed into a buffer of size <code>fft_length</code>.</li> <li>The DFT is taken of each windowed frame.</li> <li>The results are stacked into a spectrogram.</li></ol> <p data-svelte-h=\"svelte-12asmlu\">We make a distinction between the following “blocks” of sample data, each of which may have a different lengths:</p> <ul data-svelte-h=\"svelte-6jlau3\"><li>The analysis frame. This is the size of the time slices that the input waveform is split into.</li> <li>The window. Each analysis frame is multiplied by the window to avoid spectral leakage.</li> <li>The FFT input buffer. The length of this determines how many frequency bins are in the spectrogram.</li></ul> <p data-svelte-h=\"svelte-ugu4qd\">In this implementation, the window is assumed to be zero-padded to have the same size as the analysis frame. A\\npadded window can be obtained from <code>window_function()</code>. The FFT input buffer may be larger than the analysis frame,\\ntypically the next power of two.</p> <p data-svelte-h=\"svelte-1jpjddx\">Note: This function is not optimized for speed yet. It should be mostly compatible with <code>librosa.stft</code> and\\n<code>torchaudio.functional.transforms.Spectrogram</code>, although it is more flexible due to the different ways spectrograms\\ncan be constructed.</p></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.power_to_db\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.power_to_db</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.power_to_db\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.power_to_db\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L479\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">spectrogram<span class=\"opacity-60\">: ndarray</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">reference<span class=\"opacity-60\">: float = 1.0</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">min_value<span class=\"opacity-60\">: float = 1e-10</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">db_range<span class=\"opacity-60\">: typing.Optional[float] = None</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><!-- HTML_TAG_START --><span><code>np.ndarray</code></span><!-- HTML_TAG_END --></span></p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.power_to_db.spectrogram\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.power_to_db.spectrogram\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>spectrogram</strong> (<code>np.ndarray</code>) —\\nThe input power (mel) spectrogram. Note that a power spectrogram has the amplitudes squared!<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.power_to_db.reference\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.power_to_db.reference\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>reference</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) —\\nSets the input spectrogram value that corresponds to 0 dB. For example, use <code>np.max(spectrogram)</code> to set\\nthe loudest part to 0 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.power_to_db.min_value\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.power_to_db.min_value\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>min_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>1e-10</code>) —\\nThe spectrogram will be clipped to this minimum value before conversion to decibels, to avoid taking\\n<code>log(0)</code>. The default of <code>1e-10</code> corresponds to a minimum of -100 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.power_to_db.db_range\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.power_to_db.db_range\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>db_range</strong> (<code>float</code>, <em>optional</em>) —\\nSets the maximum dynamic range in decibels. For example, if <code>db_range = 80</code>, the difference between the\\npeak value and the smallest value will never be more than 80 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li></ul>  <div id=\"transformers.audio_utils.power_to_db.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> <!-- HTML_TAG_START -->\\n<p><code>np.ndarray</code></p>\\n<!-- HTML_TAG_END --> <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\"><!-- HTML_TAG_START -->\\n</p><p>the spectrogram in decibels</p>\\n<!-- HTML_TAG_END --><p></p> </div></div> <p data-svelte-h=\"svelte-1m05y0g\">Converts a power spectrogram to the decibel scale. This computes <code>10 * log10(spectrogram / reference)</code>, using basic\\nlogarithm properties for numerical stability.</p> <p data-svelte-h=\"svelte-12zo44d\">The motivation behind applying the log function on the (mel) spectrogram is that humans do not hear loudness on a\\nlinear scale. Generally to double the perceived volume of a sound we need to put 8 times as much energy into it.\\nThis means that large variations in energy may not sound all that different if the sound is loud to begin with.\\nThis compression operation makes the (mel) spectrogram features match more closely what humans actually hear.</p> <p data-svelte-h=\"svelte-1bxqqp\">Based on the implementation of <code>librosa.power_to_db</code>.</p></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\">  <div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.audio_utils.amplitude_to_db\"><!-- HTML_TAG_START --><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>transformers.audio_utils.amplitude_to_db</span></h4><!-- HTML_TAG_END --> <a id=\"transformers.audio_utils.amplitude_to_db\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.audio_utils.amplitude_to_db\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/audio_utils.py#L530\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">spectrogram<span class=\"opacity-60\">: ndarray</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">reference<span class=\"opacity-60\">: float = 1.0</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">min_value<span class=\"opacity-60\">: float = 1e-05</span></span> </span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">db_range<span class=\"opacity-60\">: typing.Optional[float] = None</span></span> </span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><!-- HTML_TAG_START --><span><code>np.ndarray</code></span><!-- HTML_TAG_END --></span></p>  <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.amplitude_to_db.spectrogram\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.amplitude_to_db.spectrogram\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>spectrogram</strong> (<code>np.ndarray</code>) —\\nThe input amplitude (mel) spectrogram.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.amplitude_to_db.reference\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.amplitude_to_db.reference\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>reference</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) —\\nSets the input spectrogram value that corresponds to 0 dB. For example, use <code>np.max(spectrogram)</code> to set\\nthe loudest part to 0 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.amplitude_to_db.min_value\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.amplitude_to_db.min_value\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>min_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>1e-5</code>) —\\nThe spectrogram will be clipped to this minimum value before conversion to decibels, to avoid taking\\n<code>log(0)</code>. The default of <code>1e-5</code> corresponds to a minimum of -100 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.audio_utils.amplitude_to_db.db_range\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.audio_utils.amplitude_to_db.db_range\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><!-- HTML_TAG_START --><strong>db_range</strong> (<code>float</code>, <em>optional</em>) —\\nSets the maximum dynamic range in decibels. For example, if <code>db_range = 80</code>, the difference between the\\npeak value and the smallest value will never be more than 80 dB. Must be greater than zero.<!-- HTML_TAG_END --> </span></span> </li></ul>  <div id=\"transformers.audio_utils.amplitude_to_db.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> <!-- HTML_TAG_START -->\\n<p><code>np.ndarray</code></p>\\n<!-- HTML_TAG_END --> <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\"><!-- HTML_TAG_START -->\\n</p><p>the spectrogram in decibels</p>\\n<!-- HTML_TAG_END --><p></p> </div></div> <p data-svelte-h=\"svelte-lpto01\">Converts an amplitude spectrogram to the decibel scale. This computes <code>20 * log10(spectrogram / reference)</code>, using\\nbasic logarithm properties for numerical stability.</p> <p data-svelte-h=\"svelte-12zo44d\">The motivation behind applying the log function on the (mel) spectrogram is that humans do not hear loudness on a\\nlinear scale. Generally to double the perceived volume of a sound we need to put 8 times as much energy into it.\\nThis means that large variations in energy may not sound all that different if the sound is loud to begin with.\\nThis compression operation makes the (mel) spectrogram features match more closely what humans actually hear.</p></div>  <p></p> \\n\\t\\t\\t\\n\\t\\t\\t<script>\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t__sveltekit_1yybmhh = {\\n\\t\\t\\t\\t\\t\\tassets: \"/docs/transformers/v4.34.0/en\",\\n\\t\\t\\t\\t\\t\\tbase: \"/docs/transformers/v4.34.0/en\",\\n\\t\\t\\t\\t\\t\\tenv: {}\\n\\t\\t\\t\\t\\t};\\n\\n\\t\\t\\t\\t\\tconst element = document.currentScript.parentElement;\\n\\n\\t\\t\\t\\t\\tconst data = [null,null];\\n\\n\\t\\t\\t\\t\\tPromise.all([\\n\\t\\t\\t\\t\\t\\timport(\"/docs/transformers/v4.34.0/en/_app/immutable/entry/start.c2db227a.js\"),\\n\\t\\t\\t\\t\\t\\timport(\"/docs/transformers/v4.34.0/en/_app/immutable/entry/app.879d9b87.js\")\\n\\t\\t\\t\\t\\t]).then(([kit, app]) => {\\n\\t\\t\\t\\t\\t\\tkit.start(app, element, {\\n\\t\\t\\t\\t\\t\\t\\tnode_ids: [0, 24],\\n\\t\\t\\t\\t\\t\\t\\tdata,\\n\\t\\t\\t\\t\\t\\t\\tform: null,\\n\\t\\t\\t\\t\\t\\t\\terror: null\\n\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t}\\n\\t\\t\\t</script>\\n\\t\\t\\n<!-- HTML_TAG_END --></div>\\n\\t\\t\\t\\t<div class=\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\"><a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/internal/image_processing_utils\" class=\"mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300\"><span class=\"mr-2 translate-y-px\">←</span>Utilities for Image Processors</a>\\n\\t\\t\\t\\t\\t<a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/internal/file_utils\" class=\"ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300\">General Utilities<span class=\"ml-2 translate-y-px\">→</span></a></div></div></div>\\n\\t\\t<div class=\"sticky top-0 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapter&quot;:{&quot;title&quot;:&quot;Utilities for `FeatureExtractors`&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;utilities-for-featureextractors&quot;,&quot;url&quot;:&quot;#utilities-for-featureextractors&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio Transformations&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.audio_utils.hertz_to_mel&quot;,&quot;url&quot;:&quot;#transformers.audio_utils.hertz_to_mel&quot;}]}}\" data-target=\"SubSideMenu\">\\n\\n<nav class=\"hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pt-24 pl-6 pr-10 pb-16 text-sm lg:flex 2xl:w-[305px]\"><a href=\"#utilities-for-featureextractors\" class=\" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-utilities-for-featureextractors\"><!-- HTML_TAG_START --><wbr>Utilities for `<wbr>Feature<wbr>Extractors`<!-- HTML_TAG_END --></a>\\n\\t<a href=\"#transformers.audio_utils.hertz_to_mel\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.audio_utils.hertz_to_mel\"><!-- HTML_TAG_START --><wbr>Audio <wbr>Transformations<!-- HTML_TAG_END --></a>\\n\\t\\t\\t</nav></div></div></div>\\n\\t<div id=\"doc-footer\"></div></main>\\n\\t</div>\\n\\n\\t\\t<script>\\n\\t\\t\\timport(\"/front/build/kube-b0520c1/index.js\");\\n\\t\\t\\twindow.moonSha = \"kube-b0520c1/\";\\n\\t\\t\\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\"}`);\\n\\t\\t</script>\\n\\n\\t\\t<!-- Stripe -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://js.stripe.com/v3/\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google analytics v4 -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\n\\t\\t\\t\\twindow.dataLayer = window.dataLayer || [];\\n\\t\\t\\t\\tfunction gtag() {\\n\\t\\t\\t\\t\\tif (window.dataLayer !== undefined) {\\n\\t\\t\\t\\t\\t\\twindow.dataLayer.push(arguments);\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tgtag(\"js\", new Date());\\n\\t\\t\\t\\tgtag(\"config\", \"G-8Q63TH4CSL\", { page_path: \"/docs/transformers/v4.34.0/en/internal/audio_utils\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages\\n\\t\\t\\t\\tgtag(\"consent\", \"default\", { ad_storage: \"denied\", analytics_storage: \"denied\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent\\n\\t\\t\\t\\t/// TODO: ask the user for their consent and update this with gtag(\\'consent\\', \\'update\\')\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google Analytics v3 (deprecated) -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\t(function (i, s, o, g, r, a, m) {\\n\\t\\t\\t\\t\\ti[\"GoogleAnalyticsObject\"] = r;\\n\\t\\t\\t\\t\\t(i[r] =\\n\\t\\t\\t\\t\\t\\ti[r] ||\\n\\t\\t\\t\\t\\t\\tfunction () {\\n\\t\\t\\t\\t\\t\\t\\t(i[r].q = i[r].q || []).push(arguments);\\n\\t\\t\\t\\t\\t\\t}),\\n\\t\\t\\t\\t\\t\\t(i[r].l = 1 * new Date());\\n\\t\\t\\t\\t\\t(a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);\\n\\t\\t\\t\\t\\ta.async = 1;\\n\\t\\t\\t\\t\\ta.src = g;\\n\\t\\t\\t\\t\\tm.parentNode.insertBefore(a, m);\\n\\t\\t\\t\\t})(window, document, \"script\", \"https://www.google-analytics.com/analytics.js\", \"ganalytics\");\\n\\t\\t\\t\\tganalytics(\"create\", \"UA-83738774-2\", \"auto\");\\n\\t\\t\\t\\tganalytics(\"send\", \"pageview\", \"/docs/transformers/v4.34.0/en/internal/audio_utils\");\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\t\\n\\n<iframe name=\"__privateStripeMetricsController4530\" frameborder=\"0\" allowtransparency=\"true\" scrolling=\"no\" role=\"presentation\" allow=\"payment *\" src=\"https://js.stripe.com/v3/m-outer-27c67c0d52761104439bb051c7856ab1.html#url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftransformers%2Fv4.34.0%2Fen%2Finternal%2Faudio_utils&amp;title=Utilities%20for%20%60FeatureExtractors%60&amp;referrer=&amp;muid=NA&amp;sid=NA&amp;version=6&amp;preview=false\" aria-hidden=\"true\" tabindex=\"-1\" style=\"border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;\"></iframe></body></html>',\n",
       "  'mime_type': 'text/plain',\n",
       "  'metadata': {}},\n",
       " {'document_id': '3',\n",
       "  'content': '<!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<meta charset=\"utf-8\">\\n\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\">\\n\\t\\t<meta name=\"description\" content=\"We’re on a journey to advance and democratize artificial intelligence through open source and open science.\">\\n\\t\\t<meta property=\"fb:app_id\" content=\"1321688464574422\">\\n\\t\\t<meta name=\"twitter:card\" content=\"summary_large_image\">\\n\\t\\t<meta name=\"twitter:site\" content=\"@huggingface\">\\n\\t\\t<meta property=\"og:title\" content=\"Perplexity of fixed-length models\">\\n\\t\\t<meta property=\"og:type\" content=\"website\">\\n\\t\\t<meta property=\"og:url\" content=\"https://huggingface.co/docs/transformers/v4.34.0/en/perplexity\">\\n\\t\\t<meta property=\"og:image\" content=\"https://huggingface.co/front/thumbnails/docs/transformers.png\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"/front/build/kube-b0520c1/style.css\">\\n\\n\\t\\t<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap\" rel=\"stylesheet\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap\" rel=\"stylesheet\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" as=\"style\" onload=\"this.onload=null;this.rel=\\'stylesheet\\'\">\\n\\t\\t<noscript>\\n\\t\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" />\\n\\t\\t</noscript>\\n\\n\\t\\t  \\n\\n\\t\\t<title>Perplexity of fixed-length models</title>\\n\\n\\t\\t<script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script defer=\"\" data-domain=\"huggingface.co\" src=\"/js/script.js\"></script>\\n\\t<script src=\"https://js.stripe.com/v3/\" async=\"\"></script><script src=\"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\" async=\"\"></script><meta http-equiv=\"origin-trial\" content=\"AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9\"><link rel=\"stylesheet\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/assets/0.e3b0c442.css\"><link rel=\"modulepreload\" as=\"script\" crossorigin=\"\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/nodes/1.38c5c2f6.js\"><meta name=\"hf:doc:metadata\" content=\"{&quot;local&quot;:&quot;perplexity-of-fixedlength-models&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;calculating-ppl-with-fixedlength-models&quot;,&quot;title&quot;:&quot;Calculating PPL with fixed-length models&quot;},{&quot;local&quot;:&quot;example-calculating-perplexity-with-gpt2-in-transformers&quot;,&quot;title&quot;:&quot;Example: Calculating perplexity with GPT-2 in 🤗 Transformers&quot;}],&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;}\"></head>\\n\\t<body class=\"flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage\">\\n\\t\\t<div class=\"flex min-h-screen flex-col\">\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}\" data-target=\"MainHeader\"><header class=\"border-b border-gray-100 \"><div class=\"w-full px-4  flex h-16 items-center\"><div class=\"flex flex-1 items-center\"><a class=\"mr-5 flex flex-none items-center lg:mr-6\" href=\"/\"><img alt=\"Hugging Face\\'s logo\" class=\"w-7 md:mr-2\" src=\"/front/assets/huggingface_logo-noborder.svg\"> <span class=\"hidden whitespace-nowrap text-lg font-bold md:block\">Hugging Face</span></a> <div class=\"relative flex-1 lg:max-w-sm mr-2 sm:mr-4 lg:mr-6\"><input autocomplete=\"off\" class=\"w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl\" name=\"\" placeholder=\"Search models, datasets, users...\" spellcheck=\"false\" type=\"text\"> <svg class=\"absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> </div> <div class=\"flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden\"><button class=\"relative z-40 flex h-6 w-8 items-center justify-center\" type=\"button\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 10 10\" class=\"text-xl\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" preserveAspectRatio=\"xMidYMid meet\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\"></path></svg> </button> </div></div> <nav aria-label=\"Main\" class=\"ml-auto hidden lg:block\"><ul class=\"flex items-center space-x-2\"><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700\" href=\"/models\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg> Models</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700\" href=\"/datasets\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-red-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 25 25\"><ellipse cx=\"12.5\" cy=\"5\" fill=\"currentColor\" fill-opacity=\"0.25\" rx=\"7.5\" ry=\"2\"></ellipse><path d=\"M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z\" fill=\"currentColor\"></path></svg> Datasets</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700\" href=\"/spaces\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-blue-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 25 25\"><path opacity=\".5\" d=\"M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z\" fill=\"currentColor\"></path><path opacity=\".75\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z\" fill=\"currentColor\"></path><path opacity=\".25\" d=\"M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z\" fill=\"currentColor\"></path></svg> Spaces</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/docs\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path opacity=\"0.5\" d=\"M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z\" fill=\"currentColor\"></path><path d=\"M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z\" fill=\"currentColor\" fill-opacity=\"0.75\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z\" fill=\"currentColor\"></path><path opacity=\"0.5\" d=\"M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z\" fill=\"currentColor\"></path></svg> Docs</a></li> <li><div class=\"relative \"><button class=\"px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-green-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-tertiary\" d=\"M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z\" fill=\"currentColor\"></path></svg> Solutions </button> </div></li> <li><a class=\"group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/pricing\">Pricing</a></li> <li><div class=\"relative group\"><button class=\"px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 32 18\" preserveAspectRatio=\"xMidYMid meet\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z\" fill=\"currentColor\"></path></svg>  </button> </div></li> <li><hr class=\"h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800\"></li> <li><a class=\"block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/login\">Log In</a></li> <li><a class=\"rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black\" href=\"/join\">Sign Up</a></li></ul></nav></div></header></div>\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"GoogleAnalyticsTracker\"></div>\\n\\t\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"SSOBanner\"></div>\\n\\n\\t<main class=\"flex flex-1 flex-col\"><div class=\"relative lg:flex\"><div class=\"sticky top-0 z-20 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;🤗 Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/index&quot;},{&quot;title&quot;:&quot;Quick tour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;installation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/installation&quot;}]},{&quot;title&quot;:&quot;Tutorials&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Run inference with pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_tutorial&quot;},{&quot;title&quot;:&quot;Write portable code with AutoClass&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;autoclass_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/autoclass_tutorial&quot;},{&quot;title&quot;:&quot;Preprocess data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocessing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/preprocessing&quot;},{&quot;title&quot;:&quot;Fine-tune a pretrained model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/training&quot;},{&quot;title&quot;:&quot;Train with a script&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;run_scripts&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/run_scripts&quot;},{&quot;title&quot;:&quot;Set up distributed training with 🤗 Accelerate&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/accelerate&quot;},{&quot;title&quot;:&quot;Load and train adapters with 🤗 PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;peft&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/peft&quot;},{&quot;title&quot;:&quot;Share your model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_sharing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_sharing&quot;},{&quot;title&quot;:&quot;Agents&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers_agents&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/transformers_agents&quot;},{&quot;title&quot;:&quot;Generation with LLMs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;llm_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/llm_tutorial&quot;}]},{&quot;title&quot;:&quot;Task Guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Natural Language Processing&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text classification&quot;,&quot;id&quot;:&quot;tasks/sequence_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/sequence_classification&quot;},{&quot;title&quot;:&quot;Token classification&quot;,&quot;id&quot;:&quot;tasks/token_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/token_classification&quot;},{&quot;title&quot;:&quot;Question answering&quot;,&quot;id&quot;:&quot;tasks/question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/question_answering&quot;},{&quot;title&quot;:&quot;Causal language modeling&quot;,&quot;id&quot;:&quot;tasks/language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/language_modeling&quot;},{&quot;title&quot;:&quot;Masked language modeling&quot;,&quot;id&quot;:&quot;tasks/masked_language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/masked_language_modeling&quot;},{&quot;title&quot;:&quot;Translation&quot;,&quot;id&quot;:&quot;tasks/translation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/translation&quot;},{&quot;title&quot;:&quot;Summarization&quot;,&quot;id&quot;:&quot;tasks/summarization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/summarization&quot;},{&quot;title&quot;:&quot;Multiple choice&quot;,&quot;id&quot;:&quot;tasks/multiple_choice&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/multiple_choice&quot;}]},{&quot;title&quot;:&quot;Audio&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio classification&quot;,&quot;id&quot;:&quot;tasks/audio_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/audio_classification&quot;},{&quot;title&quot;:&quot;Automatic speech recognition&quot;,&quot;id&quot;:&quot;tasks/asr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/asr&quot;}]},{&quot;title&quot;:&quot;Computer Vision&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image classification&quot;,&quot;id&quot;:&quot;tasks/image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_classification&quot;},{&quot;title&quot;:&quot;Semantic segmentation&quot;,&quot;id&quot;:&quot;tasks/semantic_segmentation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/semantic_segmentation&quot;},{&quot;title&quot;:&quot;Video classification&quot;,&quot;id&quot;:&quot;tasks/video_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/video_classification&quot;},{&quot;title&quot;:&quot;Object detection&quot;,&quot;id&quot;:&quot;tasks/object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot object detection&quot;,&quot;id&quot;:&quot;tasks/zero_shot_object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot image classification&quot;,&quot;id&quot;:&quot;tasks/zero_shot_image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_image_classification&quot;},{&quot;title&quot;:&quot;Depth estimation&quot;,&quot;id&quot;:&quot;tasks/monocular_depth_estimation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/monocular_depth_estimation&quot;}]},{&quot;title&quot;:&quot;Multimodal&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image captioning&quot;,&quot;id&quot;:&quot;tasks/image_captioning&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_captioning&quot;},{&quot;title&quot;:&quot;Document Question Answering&quot;,&quot;id&quot;:&quot;tasks/document_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/document_question_answering&quot;},{&quot;title&quot;:&quot;Visual Question Answering&quot;,&quot;id&quot;:&quot;tasks/visual_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/visual_question_answering&quot;},{&quot;title&quot;:&quot;Text to speech&quot;,&quot;id&quot;:&quot;tasks/text-to-speech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/text-to-speech&quot;}]},{&quot;title&quot;:&quot;Generation&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Customize the generation strategy&quot;,&quot;id&quot;:&quot;generation_strategies&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/generation_strategies&quot;}]},{&quot;title&quot;:&quot;Prompting&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image tasks with IDEFICS&quot;,&quot;id&quot;:&quot;tasks/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/idefics&quot;}]}]},{&quot;title&quot;:&quot;Developer guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Use fast tokenizers from 🤗 Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/fast_tokenizers&quot;},{&quot;title&quot;:&quot;Run inference with multilingual models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multilingual&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/multilingual&quot;},{&quot;title&quot;:&quot;Use model-specific APIs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;create_a_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/create_a_model&quot;},{&quot;title&quot;:&quot;Share a custom model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_models&quot;},{&quot;title&quot;:&quot;Templates for chat models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;chat_templating&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/chat_templating&quot;},{&quot;title&quot;:&quot;Run training on Amazon SageMaker&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sagemaker&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/sagemaker&quot;},{&quot;title&quot;:&quot;Export to ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;serialization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/serialization&quot;},{&quot;title&quot;:&quot;Export to TFLite&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tflite&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tflite&quot;},{&quot;title&quot;:&quot;Export to TorchScript&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;torchscript&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/torchscript&quot;},{&quot;title&quot;:&quot;Benchmarks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;benchmarks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/benchmarks&quot;},{&quot;title&quot;:&quot;Notebooks with examples&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;notebooks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/notebooks&quot;},{&quot;title&quot;:&quot;Community resources&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;community&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/community&quot;},{&quot;title&quot;:&quot;Custom Tools and Prompts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_tools&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_tools&quot;},{&quot;title&quot;:&quot;Troubleshoot&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;troubleshooting&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/troubleshooting&quot;}]},{&quot;title&quot;:&quot;Performance and scalability&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Overview&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/performance&quot;},{&quot;title&quot;:&quot;Efficient training techniques&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Methods and tools for efficient training on a single GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_one&quot;},{&quot;title&quot;:&quot;Multiple GPUs and parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_many&quot;},{&quot;title&quot;:&quot;Efficient training on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu&quot;},{&quot;title&quot;:&quot;Distributed CPU training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu_many&quot;},{&quot;title&quot;:&quot;Training on TPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu&quot;},{&quot;title&quot;:&quot;Training on TPU with TensorFlow&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu_tf&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu_tf&quot;},{&quot;title&quot;:&quot;Training on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_special&quot;},{&quot;title&quot;:&quot;Custom hardware for training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_hardware&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_hardware&quot;},{&quot;title&quot;:&quot;Hyperparameter Search using Trainer API&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;hpo_train&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/hpo_train&quot;}]},{&quot;title&quot;:&quot;Optimizing inference&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Inference on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_cpu&quot;},{&quot;title&quot;:&quot;Inference on one GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_one&quot;},{&quot;title&quot;:&quot;Inference on many GPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_many&quot;},{&quot;title&quot;:&quot;Inference on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_special&quot;}]},{&quot;title&quot;:&quot;Instantiating a big model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;big_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/big_models&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;debugging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/debugging&quot;},{&quot;title&quot;:&quot;XLA Integration for TensorFlow Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tf_xla&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tf_xla&quot;},{&quot;title&quot;:&quot;Optimize inference using `torch.compile()`&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_torch_compile&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_torch_compile&quot;}]},{&quot;title&quot;:&quot;Contribute&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;How to contribute to transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contributing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/contributing&quot;},{&quot;title&quot;:&quot;How to add a model to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_model&quot;},{&quot;title&quot;:&quot;How to convert a 🤗 Transformers model to TensorFlow?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_tensorflow_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_tensorflow_model&quot;},{&quot;title&quot;:&quot;How to add a pipeline to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_pipeline&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_pipeline&quot;},{&quot;title&quot;:&quot;Testing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;testing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/testing&quot;},{&quot;title&quot;:&quot;Checks on a Pull Request&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pr_checks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pr_checks&quot;}]},{&quot;title&quot;:&quot;Conceptual guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Philosophy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;philosophy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/philosophy&quot;},{&quot;title&quot;:&quot;Glossary&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;glossary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/glossary&quot;},{&quot;title&quot;:&quot;What 🤗 Transformers can do&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/task_summary&quot;},{&quot;title&quot;:&quot;How 🤗 Transformers solve tasks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tasks_explained&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks_explained&quot;},{&quot;title&quot;:&quot;The Transformer model family&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_summary&quot;},{&quot;title&quot;:&quot;Summary of the tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tokenizer_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tokenizer_summary&quot;},{&quot;title&quot;:&quot;Attention mechanisms&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;attention&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/attention&quot;},{&quot;title&quot;:&quot;Padding and truncation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pad_truncation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pad_truncation&quot;},{&quot;title&quot;:&quot;BERTology&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bertology&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/bertology&quot;},{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perplexity&quot;},{&quot;title&quot;:&quot;Pipelines for webserver inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_webserver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_webserver&quot;},{&quot;title&quot;:&quot;Model training anatomy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_memory_anatomy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_memory_anatomy&quot;}]},{&quot;title&quot;:&quot;API&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main Classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Agents and Tools&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/agent&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/agent&quot;},{&quot;title&quot;:&quot;Auto Classes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/auto&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/auto&quot;},{&quot;title&quot;:&quot;Callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/callback&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/callback&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/configuration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/configuration&quot;},{&quot;title&quot;:&quot;Data Collator&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/data_collator&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/data_collator&quot;},{&quot;title&quot;:&quot;Keras callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/keras_callbacks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/keras_callbacks&quot;},{&quot;title&quot;:&quot;Logging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/logging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/logging&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/model&quot;},{&quot;title&quot;:&quot;Text Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/text_generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/text_generation&quot;},{&quot;title&quot;:&quot;ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/onnx&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/onnx&quot;},{&quot;title&quot;:&quot;Optimization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/optimizer_schedules&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules&quot;},{&quot;title&quot;:&quot;Model outputs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/output&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/output&quot;},{&quot;title&quot;:&quot;Pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/pipelines&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/pipelines&quot;},{&quot;title&quot;:&quot;Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/processors&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/processors&quot;},{&quot;title&quot;:&quot;Quantization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/quantization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/quantization&quot;},{&quot;title&quot;:&quot;Tokenizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/tokenizer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/tokenizer&quot;},{&quot;title&quot;:&quot;Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/trainer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/trainer&quot;},{&quot;title&quot;:&quot;DeepSpeed Integration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/deepspeed&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/deepspeed&quot;},{&quot;title&quot;:&quot;Feature Extractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/feature_extractor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/feature_extractor&quot;},{&quot;title&quot;:&quot;Image Processor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/image_processor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/image_processor&quot;}]},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALBERT&quot;,&quot;id&quot;:&quot;model_doc/albert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/albert&quot;},{&quot;title&quot;:&quot;BART&quot;,&quot;id&quot;:&quot;model_doc/bart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bart&quot;},{&quot;title&quot;:&quot;BARThez&quot;,&quot;id&quot;:&quot;model_doc/barthez&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/barthez&quot;},{&quot;title&quot;:&quot;BARTpho&quot;,&quot;id&quot;:&quot;model_doc/bartpho&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bartpho&quot;},{&quot;title&quot;:&quot;BERT&quot;,&quot;id&quot;:&quot;model_doc/bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert&quot;},{&quot;title&quot;:&quot;BertGeneration&quot;,&quot;id&quot;:&quot;model_doc/bert-generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-generation&quot;},{&quot;title&quot;:&quot;BertJapanese&quot;,&quot;id&quot;:&quot;model_doc/bert-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-japanese&quot;},{&quot;title&quot;:&quot;Bertweet&quot;,&quot;id&quot;:&quot;model_doc/bertweet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bertweet&quot;},{&quot;title&quot;:&quot;BigBird&quot;,&quot;id&quot;:&quot;model_doc/big_bird&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/big_bird&quot;},{&quot;title&quot;:&quot;BigBirdPegasus&quot;,&quot;id&quot;:&quot;model_doc/bigbird_pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bigbird_pegasus&quot;},{&quot;title&quot;:&quot;BioGpt&quot;,&quot;id&quot;:&quot;model_doc/biogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/biogpt&quot;},{&quot;title&quot;:&quot;Blenderbot&quot;,&quot;id&quot;:&quot;model_doc/blenderbot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot&quot;},{&quot;title&quot;:&quot;Blenderbot Small&quot;,&quot;id&quot;:&quot;model_doc/blenderbot-small&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot-small&quot;},{&quot;title&quot;:&quot;BLOOM&quot;,&quot;id&quot;:&quot;model_doc/bloom&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bloom&quot;},{&quot;title&quot;:&quot;BORT&quot;,&quot;id&quot;:&quot;model_doc/bort&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bort&quot;},{&quot;title&quot;:&quot;ByT5&quot;,&quot;id&quot;:&quot;model_doc/byt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/byt5&quot;},{&quot;title&quot;:&quot;CamemBERT&quot;,&quot;id&quot;:&quot;model_doc/camembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/camembert&quot;},{&quot;title&quot;:&quot;CANINE&quot;,&quot;id&quot;:&quot;model_doc/canine&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/canine&quot;},{&quot;title&quot;:&quot;CodeGen&quot;,&quot;id&quot;:&quot;model_doc/codegen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/codegen&quot;},{&quot;title&quot;:&quot;CodeLlama&quot;,&quot;id&quot;:&quot;model_doc/code_llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/code_llama&quot;},{&quot;title&quot;:&quot;ConvBERT&quot;,&quot;id&quot;:&quot;model_doc/convbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convbert&quot;},{&quot;title&quot;:&quot;CPM&quot;,&quot;id&quot;:&quot;model_doc/cpm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpm&quot;},{&quot;title&quot;:&quot;CPMANT&quot;,&quot;id&quot;:&quot;model_doc/cpmant&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpmant&quot;},{&quot;title&quot;:&quot;CTRL&quot;,&quot;id&quot;:&quot;model_doc/ctrl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ctrl&quot;},{&quot;title&quot;:&quot;DeBERTa&quot;,&quot;id&quot;:&quot;model_doc/deberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta&quot;},{&quot;title&quot;:&quot;DeBERTa-v2&quot;,&quot;id&quot;:&quot;model_doc/deberta-v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta-v2&quot;},{&quot;title&quot;:&quot;DialoGPT&quot;,&quot;id&quot;:&quot;model_doc/dialogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dialogpt&quot;},{&quot;title&quot;:&quot;DistilBERT&quot;,&quot;id&quot;:&quot;model_doc/distilbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/distilbert&quot;},{&quot;title&quot;:&quot;DPR&quot;,&quot;id&quot;:&quot;model_doc/dpr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpr&quot;},{&quot;title&quot;:&quot;ELECTRA&quot;,&quot;id&quot;:&quot;model_doc/electra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/electra&quot;},{&quot;title&quot;:&quot;Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encoder-decoder&quot;},{&quot;title&quot;:&quot;ERNIE&quot;,&quot;id&quot;:&quot;model_doc/ernie&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie&quot;},{&quot;title&quot;:&quot;ErnieM&quot;,&quot;id&quot;:&quot;model_doc/ernie_m&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie_m&quot;},{&quot;title&quot;:&quot;ESM&quot;,&quot;id&quot;:&quot;model_doc/esm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/esm&quot;},{&quot;title&quot;:&quot;Falcon&quot;,&quot;id&quot;:&quot;model_doc/falcon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/falcon&quot;},{&quot;title&quot;:&quot;FLAN-T5&quot;,&quot;id&quot;:&quot;model_doc/flan-t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-t5&quot;},{&quot;title&quot;:&quot;FLAN-UL2&quot;,&quot;id&quot;:&quot;model_doc/flan-ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-ul2&quot;},{&quot;title&quot;:&quot;FlauBERT&quot;,&quot;id&quot;:&quot;model_doc/flaubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flaubert&quot;},{&quot;title&quot;:&quot;FNet&quot;,&quot;id&quot;:&quot;model_doc/fnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fnet&quot;},{&quot;title&quot;:&quot;FSMT&quot;,&quot;id&quot;:&quot;model_doc/fsmt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fsmt&quot;},{&quot;title&quot;:&quot;Funnel Transformer&quot;,&quot;id&quot;:&quot;model_doc/funnel&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/funnel&quot;},{&quot;title&quot;:&quot;GPT&quot;,&quot;id&quot;:&quot;model_doc/openai-gpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/openai-gpt&quot;},{&quot;title&quot;:&quot;GPT Neo&quot;,&quot;id&quot;:&quot;model_doc/gpt_neo&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neo&quot;},{&quot;title&quot;:&quot;GPT NeoX&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox&quot;},{&quot;title&quot;:&quot;GPT NeoX Japanese&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox_japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox_japanese&quot;},{&quot;title&quot;:&quot;GPT-J&quot;,&quot;id&quot;:&quot;model_doc/gptj&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptj&quot;},{&quot;title&quot;:&quot;GPT2&quot;,&quot;id&quot;:&quot;model_doc/gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt2&quot;},{&quot;title&quot;:&quot;GPTBigCode&quot;,&quot;id&quot;:&quot;model_doc/gpt_bigcode&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_bigcode&quot;},{&quot;title&quot;:&quot;GPTSAN Japanese&quot;,&quot;id&quot;:&quot;model_doc/gptsan-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptsan-japanese&quot;},{&quot;title&quot;:&quot;GPTSw3&quot;,&quot;id&quot;:&quot;model_doc/gpt-sw3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt-sw3&quot;},{&quot;title&quot;:&quot;HerBERT&quot;,&quot;id&quot;:&quot;model_doc/herbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/herbert&quot;},{&quot;title&quot;:&quot;I-BERT&quot;,&quot;id&quot;:&quot;model_doc/ibert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ibert&quot;},{&quot;title&quot;:&quot;Jukebox&quot;,&quot;id&quot;:&quot;model_doc/jukebox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/jukebox&quot;},{&quot;title&quot;:&quot;LED&quot;,&quot;id&quot;:&quot;model_doc/led&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/led&quot;},{&quot;title&quot;:&quot;LLaMA&quot;,&quot;id&quot;:&quot;model_doc/llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama&quot;},{&quot;title&quot;:&quot;Llama2&quot;,&quot;id&quot;:&quot;model_doc/llama2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama2&quot;},{&quot;title&quot;:&quot;Longformer&quot;,&quot;id&quot;:&quot;model_doc/longformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longformer&quot;},{&quot;title&quot;:&quot;LongT5&quot;,&quot;id&quot;:&quot;model_doc/longt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longt5&quot;},{&quot;title&quot;:&quot;LUKE&quot;,&quot;id&quot;:&quot;model_doc/luke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/luke&quot;},{&quot;title&quot;:&quot;M2M100&quot;,&quot;id&quot;:&quot;model_doc/m2m_100&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/m2m_100&quot;},{&quot;title&quot;:&quot;MarianMT&quot;,&quot;id&quot;:&quot;model_doc/marian&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/marian&quot;},{&quot;title&quot;:&quot;MarkupLM&quot;,&quot;id&quot;:&quot;model_doc/markuplm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/markuplm&quot;},{&quot;title&quot;:&quot;MBart and MBart-50&quot;,&quot;id&quot;:&quot;model_doc/mbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mbart&quot;},{&quot;title&quot;:&quot;MEGA&quot;,&quot;id&quot;:&quot;model_doc/mega&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mega&quot;},{&quot;title&quot;:&quot;MegatronBERT&quot;,&quot;id&quot;:&quot;model_doc/megatron-bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron-bert&quot;},{&quot;title&quot;:&quot;MegatronGPT2&quot;,&quot;id&quot;:&quot;model_doc/megatron_gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron_gpt2&quot;},{&quot;title&quot;:&quot;Mistral&quot;,&quot;id&quot;:&quot;model_doc/mistral&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mistral&quot;},{&quot;title&quot;:&quot;mLUKE&quot;,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MobileBERT&quot;,&quot;id&quot;:&quot;model_doc/mobilebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilebert&quot;},{&quot;title&quot;:&quot;MPNet&quot;,&quot;id&quot;:&quot;model_doc/mpnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpnet&quot;},{&quot;title&quot;:&quot;MPT&quot;,&quot;id&quot;:&quot;model_doc/mpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpt&quot;},{&quot;title&quot;:&quot;MRA&quot;,&quot;id&quot;:&quot;model_doc/mra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mra&quot;},{&quot;title&quot;:&quot;MT5&quot;,&quot;id&quot;:&quot;model_doc/mt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mt5&quot;},{&quot;title&quot;:&quot;MVP&quot;,&quot;id&quot;:&quot;model_doc/mvp&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mvp&quot;},{&quot;title&quot;:&quot;NEZHA&quot;,&quot;id&quot;:&quot;model_doc/nezha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nezha&quot;},{&quot;title&quot;:&quot;NLLB&quot;,&quot;id&quot;:&quot;model_doc/nllb&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb&quot;},{&quot;title&quot;:&quot;NLLB-MoE&quot;,&quot;id&quot;:&quot;model_doc/nllb-moe&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb-moe&quot;},{&quot;title&quot;:&quot;Nyströmformer&quot;,&quot;id&quot;:&quot;model_doc/nystromformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nystromformer&quot;},{&quot;title&quot;:&quot;Open-Llama&quot;,&quot;id&quot;:&quot;model_doc/open-llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/open-llama&quot;},{&quot;title&quot;:&quot;OPT&quot;,&quot;id&quot;:&quot;model_doc/opt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/opt&quot;},{&quot;title&quot;:&quot;Pegasus&quot;,&quot;id&quot;:&quot;model_doc/pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus&quot;},{&quot;title&quot;:&quot;PEGASUS-X&quot;,&quot;id&quot;:&quot;model_doc/pegasus_x&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus_x&quot;},{&quot;title&quot;:&quot;Persimmon&quot;,&quot;id&quot;:&quot;model_doc/persimmon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/persimmon&quot;},{&quot;title&quot;:&quot;PhoBERT&quot;,&quot;id&quot;:&quot;model_doc/phobert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/phobert&quot;},{&quot;title&quot;:&quot;PLBart&quot;,&quot;id&quot;:&quot;model_doc/plbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/plbart&quot;},{&quot;title&quot;:&quot;ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/prophetnet&quot;},{&quot;title&quot;:&quot;QDQBert&quot;,&quot;id&quot;:&quot;model_doc/qdqbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/qdqbert&quot;},{&quot;title&quot;:&quot;RAG&quot;,&quot;id&quot;:&quot;model_doc/rag&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rag&quot;},{&quot;title&quot;:&quot;REALM&quot;,&quot;id&quot;:&quot;model_doc/realm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/realm&quot;},{&quot;title&quot;:&quot;Reformer&quot;,&quot;id&quot;:&quot;model_doc/reformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/reformer&quot;},{&quot;title&quot;:&quot;RemBERT&quot;,&quot;id&quot;:&quot;model_doc/rembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rembert&quot;},{&quot;title&quot;:&quot;RetriBERT&quot;,&quot;id&quot;:&quot;model_doc/retribert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/retribert&quot;},{&quot;title&quot;:&quot;RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta&quot;},{&quot;title&quot;:&quot;RoBERTa-PreLayerNorm&quot;,&quot;id&quot;:&quot;model_doc/roberta-prelayernorm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta-prelayernorm&quot;},{&quot;title&quot;:&quot;RoCBert&quot;,&quot;id&quot;:&quot;model_doc/roc_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roc_bert&quot;},{&quot;title&quot;:&quot;RoFormer&quot;,&quot;id&quot;:&quot;model_doc/roformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roformer&quot;},{&quot;title&quot;:&quot;RWKV&quot;,&quot;id&quot;:&quot;model_doc/rwkv&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rwkv&quot;},{&quot;title&quot;:&quot;Splinter&quot;,&quot;id&quot;:&quot;model_doc/splinter&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/splinter&quot;},{&quot;title&quot;:&quot;SqueezeBERT&quot;,&quot;id&quot;:&quot;model_doc/squeezebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/squeezebert&quot;},{&quot;title&quot;:&quot;SwitchTransformers&quot;,&quot;id&quot;:&quot;model_doc/switch_transformers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/switch_transformers&quot;},{&quot;title&quot;:&quot;T5&quot;,&quot;id&quot;:&quot;model_doc/t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5&quot;},{&quot;title&quot;:&quot;T5v1.1&quot;,&quot;id&quot;:&quot;model_doc/t5v1.1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5v1.1&quot;},{&quot;title&quot;:&quot;TAPEX&quot;,&quot;id&quot;:&quot;model_doc/tapex&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapex&quot;},{&quot;title&quot;:&quot;Transformer XL&quot;,&quot;id&quot;:&quot;model_doc/transfo-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/transfo-xl&quot;},{&quot;title&quot;:&quot;UL2&quot;,&quot;id&quot;:&quot;model_doc/ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ul2&quot;},{&quot;title&quot;:&quot;UMT5&quot;,&quot;id&quot;:&quot;model_doc/umt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/umt5&quot;},{&quot;title&quot;:&quot;X-MOD&quot;,&quot;id&quot;:&quot;model_doc/xmod&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xmod&quot;},{&quot;title&quot;:&quot;XGLM&quot;,&quot;id&quot;:&quot;model_doc/xglm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xglm&quot;},{&quot;title&quot;:&quot;XLM&quot;,&quot;id&quot;:&quot;model_doc/xlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm&quot;},{&quot;title&quot;:&quot;XLM-ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/xlm-prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-prophetnet&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa-XL&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta-xl&quot;},{&quot;title&quot;:&quot;XLM-V&quot;,&quot;id&quot;:&quot;model_doc/xlm-v&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-v&quot;},{&quot;title&quot;:&quot;XLNet&quot;,&quot;id&quot;:&quot;model_doc/xlnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlnet&quot;},{&quot;title&quot;:&quot;YOSO&quot;,&quot;id&quot;:&quot;model_doc/yoso&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yoso&quot;}]},{&quot;title&quot;:&quot;Vision models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;BEiT&quot;,&quot;id&quot;:&quot;model_doc/beit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/beit&quot;},{&quot;title&quot;:&quot;BiT&quot;,&quot;id&quot;:&quot;model_doc/bit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bit&quot;},{&quot;title&quot;:&quot;Conditional DETR&quot;,&quot;id&quot;:&quot;model_doc/conditional_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/conditional_detr&quot;},{&quot;title&quot;:&quot;ConvNeXT&quot;,&quot;id&quot;:&quot;model_doc/convnext&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnext&quot;},{&quot;title&quot;:&quot;ConvNeXTV2&quot;,&quot;id&quot;:&quot;model_doc/convnextv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnextv2&quot;},{&quot;title&quot;:&quot;CvT&quot;,&quot;id&quot;:&quot;model_doc/cvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cvt&quot;},{&quot;title&quot;:&quot;Deformable DETR&quot;,&quot;id&quot;:&quot;model_doc/deformable_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deformable_detr&quot;},{&quot;title&quot;:&quot;DeiT&quot;,&quot;id&quot;:&quot;model_doc/deit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deit&quot;},{&quot;title&quot;:&quot;DETA&quot;,&quot;id&quot;:&quot;model_doc/deta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deta&quot;},{&quot;title&quot;:&quot;DETR&quot;,&quot;id&quot;:&quot;model_doc/detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/detr&quot;},{&quot;title&quot;:&quot;DiNAT&quot;,&quot;id&quot;:&quot;model_doc/dinat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinat&quot;},{&quot;title&quot;:&quot;DINO V2&quot;,&quot;id&quot;:&quot;model_doc/dinov2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinov2&quot;},{&quot;title&quot;:&quot;DiT&quot;,&quot;id&quot;:&quot;model_doc/dit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dit&quot;},{&quot;title&quot;:&quot;DPT&quot;,&quot;id&quot;:&quot;model_doc/dpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpt&quot;},{&quot;title&quot;:&quot;EfficientFormer&quot;,&quot;id&quot;:&quot;model_doc/efficientformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientformer&quot;},{&quot;title&quot;:&quot;EfficientNet&quot;,&quot;id&quot;:&quot;model_doc/efficientnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientnet&quot;},{&quot;title&quot;:&quot;FocalNet&quot;,&quot;id&quot;:&quot;model_doc/focalnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/focalnet&quot;},{&quot;title&quot;:&quot;GLPN&quot;,&quot;id&quot;:&quot;model_doc/glpn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/glpn&quot;},{&quot;title&quot;:&quot;ImageGPT&quot;,&quot;id&quot;:&quot;model_doc/imagegpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/imagegpt&quot;},{&quot;title&quot;:&quot;LeViT&quot;,&quot;id&quot;:&quot;model_doc/levit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/levit&quot;},{&quot;title&quot;:&quot;Mask2Former&quot;,&quot;id&quot;:&quot;model_doc/mask2former&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mask2former&quot;},{&quot;title&quot;:&quot;MaskFormer&quot;,&quot;id&quot;:&quot;model_doc/maskformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/maskformer&quot;},{&quot;title&quot;:&quot;MobileNetV1&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v1&quot;},{&quot;title&quot;:&quot;MobileNetV2&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v2&quot;},{&quot;title&quot;:&quot;MobileViT&quot;,&quot;id&quot;:&quot;model_doc/mobilevit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevit&quot;},{&quot;title&quot;:&quot;MobileViTV2&quot;,&quot;id&quot;:&quot;model_doc/mobilevitv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevitv2&quot;},{&quot;title&quot;:&quot;NAT&quot;,&quot;id&quot;:&quot;model_doc/nat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nat&quot;},{&quot;title&quot;:&quot;PoolFormer&quot;,&quot;id&quot;:&quot;model_doc/poolformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/poolformer&quot;},{&quot;title&quot;:&quot;Pyramid Vision Transformer (PVT)&quot;,&quot;id&quot;:&quot;model_doc/pvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pvt&quot;},{&quot;title&quot;:&quot;RegNet&quot;,&quot;id&quot;:&quot;model_doc/regnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/regnet&quot;},{&quot;title&quot;:&quot;ResNet&quot;,&quot;id&quot;:&quot;model_doc/resnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/resnet&quot;},{&quot;title&quot;:&quot;SegFormer&quot;,&quot;id&quot;:&quot;model_doc/segformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/segformer&quot;},{&quot;title&quot;:&quot;SwiftFormer&quot;,&quot;id&quot;:&quot;model_doc/swiftformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swiftformer&quot;},{&quot;title&quot;:&quot;Swin Transformer&quot;,&quot;id&quot;:&quot;model_doc/swin&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin&quot;},{&quot;title&quot;:&quot;Swin Transformer V2&quot;,&quot;id&quot;:&quot;model_doc/swinv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swinv2&quot;},{&quot;title&quot;:&quot;Swin2SR&quot;,&quot;id&quot;:&quot;model_doc/swin2sr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin2sr&quot;},{&quot;title&quot;:&quot;Table Transformer&quot;,&quot;id&quot;:&quot;model_doc/table-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/table-transformer&quot;},{&quot;title&quot;:&quot;TimeSformer&quot;,&quot;id&quot;:&quot;model_doc/timesformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/timesformer&quot;},{&quot;title&quot;:&quot;UperNet&quot;,&quot;id&quot;:&quot;model_doc/upernet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/upernet&quot;},{&quot;title&quot;:&quot;VAN&quot;,&quot;id&quot;:&quot;model_doc/van&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/van&quot;},{&quot;title&quot;:&quot;VideoMAE&quot;,&quot;id&quot;:&quot;model_doc/videomae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/videomae&quot;},{&quot;title&quot;:&quot;Vision Transformer (ViT)&quot;,&quot;id&quot;:&quot;model_doc/vit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit&quot;},{&quot;title&quot;:&quot;ViT Hybrid&quot;,&quot;id&quot;:&quot;model_doc/vit_hybrid&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_hybrid&quot;},{&quot;title&quot;:&quot;ViTDet&quot;,&quot;id&quot;:&quot;model_doc/vitdet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitdet&quot;},{&quot;title&quot;:&quot;ViTMAE&quot;,&quot;id&quot;:&quot;model_doc/vit_mae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_mae&quot;},{&quot;title&quot;:&quot;ViTMatte&quot;,&quot;id&quot;:&quot;model_doc/vitmatte&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitmatte&quot;},{&quot;title&quot;:&quot;ViTMSN&quot;,&quot;id&quot;:&quot;model_doc/vit_msn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_msn&quot;},{&quot;title&quot;:&quot;ViViT&quot;,&quot;id&quot;:&quot;model_doc/vivit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vivit&quot;},{&quot;title&quot;:&quot;YOLOS&quot;,&quot;id&quot;:&quot;model_doc/yolos&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yolos&quot;}]},{&quot;title&quot;:&quot;Audio models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio Spectrogram Transformer&quot;,&quot;id&quot;:&quot;model_doc/audio-spectrogram-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/audio-spectrogram-transformer&quot;},{&quot;title&quot;:&quot;Bark&quot;,&quot;id&quot;:&quot;model_doc/bark&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bark&quot;},{&quot;title&quot;:&quot;CLAP&quot;,&quot;id&quot;:&quot;model_doc/clap&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clap&quot;},{&quot;title&quot;:&quot;EnCodec&quot;,&quot;id&quot;:&quot;model_doc/encodec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encodec&quot;},{&quot;title&quot;:&quot;Hubert&quot;,&quot;id&quot;:&quot;model_doc/hubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/hubert&quot;},{&quot;title&quot;:&quot;MCTCT&quot;,&quot;id&quot;:&quot;model_doc/mctct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mctct&quot;},{&quot;title&quot;:&quot;MMS&quot;,&quot;id&quot;:&quot;model_doc/mms&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mms&quot;},{&quot;title&quot;:&quot;MusicGen&quot;,&quot;id&quot;:&quot;model_doc/musicgen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/musicgen&quot;},{&quot;title&quot;:&quot;Pop2Piano&quot;,&quot;id&quot;:&quot;model_doc/pop2piano&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pop2piano&quot;},{&quot;title&quot;:&quot;SEW&quot;,&quot;id&quot;:&quot;model_doc/sew&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew&quot;},{&quot;title&quot;:&quot;SEW-D&quot;,&quot;id&quot;:&quot;model_doc/sew-d&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew-d&quot;},{&quot;title&quot;:&quot;Speech2Text&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text&quot;},{&quot;title&quot;:&quot;Speech2Text2&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text_2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text_2&quot;},{&quot;title&quot;:&quot;SpeechT5&quot;,&quot;id&quot;:&quot;model_doc/speecht5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speecht5&quot;},{&quot;title&quot;:&quot;UniSpeech&quot;,&quot;id&quot;:&quot;model_doc/unispeech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech&quot;},{&quot;title&quot;:&quot;UniSpeech-SAT&quot;,&quot;id&quot;:&quot;model_doc/unispeech-sat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech-sat&quot;},{&quot;title&quot;:&quot;VITS&quot;,&quot;id&quot;:&quot;model_doc/vits&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vits&quot;},{&quot;title&quot;:&quot;Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2&quot;},{&quot;title&quot;:&quot;Wav2Vec2-Conformer&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2-conformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2-conformer&quot;},{&quot;title&quot;:&quot;Wav2Vec2Phoneme&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2_phoneme&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2_phoneme&quot;},{&quot;title&quot;:&quot;WavLM&quot;,&quot;id&quot;:&quot;model_doc/wavlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wavlm&quot;},{&quot;title&quot;:&quot;Whisper&quot;,&quot;id&quot;:&quot;model_doc/whisper&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/whisper&quot;},{&quot;title&quot;:&quot;XLS-R&quot;,&quot;id&quot;:&quot;model_doc/xls_r&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xls_r&quot;},{&quot;title&quot;:&quot;XLSR-Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/xlsr_wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlsr_wav2vec2&quot;}]},{&quot;title&quot;:&quot;Multimodal models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALIGN&quot;,&quot;id&quot;:&quot;model_doc/align&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/align&quot;},{&quot;title&quot;:&quot;AltCLIP&quot;,&quot;id&quot;:&quot;model_doc/altclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/altclip&quot;},{&quot;title&quot;:&quot;BLIP&quot;,&quot;id&quot;:&quot;model_doc/blip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip&quot;},{&quot;title&quot;:&quot;BLIP-2&quot;,&quot;id&quot;:&quot;model_doc/blip-2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip-2&quot;},{&quot;title&quot;:&quot;BridgeTower&quot;,&quot;id&quot;:&quot;model_doc/bridgetower&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bridgetower&quot;},{&quot;title&quot;:&quot;BROS&quot;,&quot;id&quot;:&quot;model_doc/bros&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bros&quot;},{&quot;title&quot;:&quot;Chinese-CLIP&quot;,&quot;id&quot;:&quot;model_doc/chinese_clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/chinese_clip&quot;},{&quot;title&quot;:&quot;CLIP&quot;,&quot;id&quot;:&quot;model_doc/clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clip&quot;},{&quot;title&quot;:&quot;CLIPSeg&quot;,&quot;id&quot;:&quot;model_doc/clipseg&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clipseg&quot;},{&quot;title&quot;:&quot;Data2Vec&quot;,&quot;id&quot;:&quot;model_doc/data2vec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/data2vec&quot;},{&quot;title&quot;:&quot;DePlot&quot;,&quot;id&quot;:&quot;model_doc/deplot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deplot&quot;},{&quot;title&quot;:&quot;Donut&quot;,&quot;id&quot;:&quot;model_doc/donut&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/donut&quot;},{&quot;title&quot;:&quot;FLAVA&quot;,&quot;id&quot;:&quot;model_doc/flava&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flava&quot;},{&quot;title&quot;:&quot;GIT&quot;,&quot;id&quot;:&quot;model_doc/git&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/git&quot;},{&quot;title&quot;:&quot;GroupViT&quot;,&quot;id&quot;:&quot;model_doc/groupvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/groupvit&quot;},{&quot;title&quot;:&quot;IDEFICS&quot;,&quot;id&quot;:&quot;model_doc/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/idefics&quot;},{&quot;title&quot;:&quot;InstructBLIP&quot;,&quot;id&quot;:&quot;model_doc/instructblip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/instructblip&quot;},{&quot;title&quot;:&quot;LayoutLM&quot;,&quot;id&quot;:&quot;model_doc/layoutlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlm&quot;},{&quot;title&quot;:&quot;LayoutLMV2&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv2&quot;},{&quot;title&quot;:&quot;LayoutLMV3&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv3&quot;},{&quot;title&quot;:&quot;LayoutXLM&quot;,&quot;id&quot;:&quot;model_doc/layoutxlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutxlm&quot;},{&quot;title&quot;:&quot;LiLT&quot;,&quot;id&quot;:&quot;model_doc/lilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lilt&quot;},{&quot;title&quot;:&quot;LXMERT&quot;,&quot;id&quot;:&quot;model_doc/lxmert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lxmert&quot;},{&quot;title&quot;:&quot;MatCha&quot;,&quot;id&quot;:&quot;model_doc/matcha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/matcha&quot;},{&quot;title&quot;:&quot;MGP-STR&quot;,&quot;id&quot;:&quot;model_doc/mgp-str&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mgp-str&quot;},{&quot;title&quot;:&quot;Nougat&quot;,&quot;id&quot;:&quot;model_doc/nougat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nougat&quot;},{&quot;title&quot;:&quot;OneFormer&quot;,&quot;id&quot;:&quot;model_doc/oneformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/oneformer&quot;},{&quot;title&quot;:&quot;OWL-ViT&quot;,&quot;id&quot;:&quot;model_doc/owlvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/owlvit&quot;},{&quot;title&quot;:&quot;Perceiver&quot;,&quot;id&quot;:&quot;model_doc/perceiver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/perceiver&quot;},{&quot;title&quot;:&quot;Pix2Struct&quot;,&quot;id&quot;:&quot;model_doc/pix2struct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pix2struct&quot;},{&quot;title&quot;:&quot;Segment Anything&quot;,&quot;id&quot;:&quot;model_doc/sam&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sam&quot;},{&quot;title&quot;:&quot;Speech Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/speech-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech-encoder-decoder&quot;},{&quot;title&quot;:&quot;TAPAS&quot;,&quot;id&quot;:&quot;model_doc/tapas&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapas&quot;},{&quot;title&quot;:&quot;TrOCR&quot;,&quot;id&quot;:&quot;model_doc/trocr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trocr&quot;},{&quot;title&quot;:&quot;TVLT&quot;,&quot;id&quot;:&quot;model_doc/tvlt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tvlt&quot;},{&quot;title&quot;:&quot;ViLT&quot;,&quot;id&quot;:&quot;model_doc/vilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vilt&quot;},{&quot;title&quot;:&quot;Vision Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/vision-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-encoder-decoder&quot;},{&quot;title&quot;:&quot;Vision Text Dual Encoder&quot;,&quot;id&quot;:&quot;model_doc/vision-text-dual-encoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-text-dual-encoder&quot;},{&quot;title&quot;:&quot;VisualBERT&quot;,&quot;id&quot;:&quot;model_doc/visual_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/visual_bert&quot;},{&quot;title&quot;:&quot;X-CLIP&quot;,&quot;id&quot;:&quot;model_doc/xclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xclip&quot;}]},{&quot;title&quot;:&quot;Reinforcement learning models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Decision Transformer&quot;,&quot;id&quot;:&quot;model_doc/decision_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/decision_transformer&quot;},{&quot;title&quot;:&quot;Trajectory Transformer&quot;,&quot;id&quot;:&quot;model_doc/trajectory_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trajectory_transformer&quot;}]},{&quot;title&quot;:&quot;Time series models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Autoformer&quot;,&quot;id&quot;:&quot;model_doc/autoformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/autoformer&quot;},{&quot;title&quot;:&quot;Informer&quot;,&quot;id&quot;:&quot;model_doc/informer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/informer&quot;},{&quot;title&quot;:&quot;Time Series Transformer&quot;,&quot;id&quot;:&quot;model_doc/time_series_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/time_series_transformer&quot;}]},{&quot;title&quot;:&quot;Graph models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Graphormer&quot;,&quot;id&quot;:&quot;model_doc/graphormer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/graphormer&quot;}]}]},{&quot;title&quot;:&quot;Internal Helpers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Custom Layers and Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/modeling_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/modeling_utils&quot;},{&quot;title&quot;:&quot;Utilities for pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/pipelines_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/pipelines_utils&quot;},{&quot;title&quot;:&quot;Utilities for Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/tokenization_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/tokenization_utils&quot;},{&quot;title&quot;:&quot;Utilities for Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/trainer_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/trainer_utils&quot;},{&quot;title&quot;:&quot;Utilities for Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/generation_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/generation_utils&quot;},{&quot;title&quot;:&quot;Utilities for Image Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/image_processing_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/image_processing_utils&quot;},{&quot;title&quot;:&quot;Utilities for Audio processing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/audio_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/audio_utils&quot;},{&quot;title&quot;:&quot;General Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/file_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/file_utils&quot;},{&quot;title&quot;:&quot;Utilities for Time Series&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/time_series_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/time_series_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;perplexity&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;de&quot;,&quot;en&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;ko&quot;,&quot;pt&quot;,&quot;zh&quot;],&quot;library&quot;:&quot;transformers&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v4.34.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v4.34.0&quot;},{&quot;version&quot;:&quot;v4.33.3&quot;},{&quot;version&quot;:&quot;v4.33.2&quot;},{&quot;version&quot;:&quot;v4.33.0&quot;},{&quot;version&quot;:&quot;v4.32.1&quot;},{&quot;version&quot;:&quot;v4.32.0&quot;},{&quot;version&quot;:&quot;v4.31.0&quot;},{&quot;version&quot;:&quot;v4.30.0&quot;},{&quot;version&quot;:&quot;v4.29.1&quot;},{&quot;version&quot;:&quot;v4.29.0&quot;},{&quot;version&quot;:&quot;v4.28.1&quot;},{&quot;version&quot;:&quot;v4.28.0&quot;},{&quot;version&quot;:&quot;v4.27.2&quot;},{&quot;version&quot;:&quot;v4.27.1&quot;},{&quot;version&quot;:&quot;v4.27.0&quot;},{&quot;version&quot;:&quot;v4.26.1&quot;},{&quot;version&quot;:&quot;v4.26.0&quot;},{&quot;version&quot;:&quot;v4.25.1&quot;},{&quot;version&quot;:&quot;v4.24.0&quot;},{&quot;version&quot;:&quot;v4.23.1&quot;},{&quot;version&quot;:&quot;v4.23.0&quot;},{&quot;version&quot;:&quot;v4.22.2&quot;},{&quot;version&quot;:&quot;v4.22.1&quot;},{&quot;version&quot;:&quot;v4.22.0&quot;},{&quot;version&quot;:&quot;v4.21.3&quot;},{&quot;version&quot;:&quot;v4.21.2&quot;},{&quot;version&quot;:&quot;v4.21.1&quot;},{&quot;version&quot;:&quot;v4.21.0&quot;},{&quot;version&quot;:&quot;v4.20.1&quot;},{&quot;version&quot;:&quot;v4.20.0&quot;},{&quot;version&quot;:&quot;v4.19.4&quot;},{&quot;version&quot;:&quot;v4.19.3&quot;},{&quot;version&quot;:&quot;v4.19.2&quot;},{&quot;version&quot;:&quot;v4.19.0&quot;},{&quot;version&quot;:&quot;v4.18.0&quot;},{&quot;version&quot;:&quot;v4.17.0&quot;},{&quot;version&quot;:&quot;v4.16.2&quot;},{&quot;version&quot;:&quot;v4.16.1&quot;},{&quot;version&quot;:&quot;v4.16.0&quot;},{&quot;version&quot;:&quot;v4.15.0&quot;},{&quot;version&quot;:&quot;v4.14.1&quot;},{&quot;version&quot;:&quot;v4.13.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.5&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.4&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.0.0&quot;},{&quot;version&quot;:&quot;doc-builder-html&quot;}],&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;}\" data-target=\"SideMenu\"> <div class=\"z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false\"><div class=\"shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden\"><div class=\"flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6\"><p class=\"text-sm text-gray-400 first-letter:capitalize\">Transformers documentation</p> <div class=\"flex items-center\"><p class=\"font-semibold\">Perplexity of fixed-length models</p> <svg class=\"text-xl false\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></div></div> <button class=\"hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2\"><svg class=\"text-gray-500 group-hover:text-gray-700\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg></button></div> <div class=\"hidden h-32 flex-col justify-between border-r border-b bg-white bg-gradient-to-r p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950\"><div class=\"relative \"><button class=\" \" type=\"button\"><h1 class=\"flex items-center text-lg font-bold leading-tight first-letter:capitalize\"><div class=\"mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none\"></div> Transformers <span><svg class=\"opacity-70 \" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></span></h1> </button> </div> <button class=\"shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500\"><svg class=\"flex-none mr-1.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> <div>Search documentation</div> <span class=\"ml-auto rounded border border-gray-200 bg-gray-100 px-0.5 text-xs dark:border-gray-800 dark:bg-gray-800\"><kbd class=\"font-sans\">⌘K</kbd></span></button> <div class=\"flex items-center\"><select class=\"form-input mr-1 !mt-0 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400\"><option value=\"0\">main</option><option value=\"1\">v4.34.0</option><option value=\"2\">v4.33.3</option><option value=\"3\">v4.32.1</option><option value=\"4\">v4.31.0</option><option value=\"5\">v4.30.0</option><option value=\"6\">v4.29.1</option><option value=\"7\">v4.28.1</option><option value=\"8\">v4.27.2</option><option value=\"9\">v4.26.1</option><option value=\"10\">v4.25.1</option><option value=\"11\">v4.24.0</option><option value=\"12\">v4.23.1</option><option value=\"13\">v4.22.2</option><option value=\"14\">v4.21.3</option><option value=\"15\">v4.20.1</option><option value=\"16\">v4.19.4</option><option value=\"17\">v4.18.0</option><option value=\"18\">v4.17.0</option><option value=\"19\">v4.16.2</option><option value=\"20\">v4.15.0</option><option value=\"21\">v4.14.1</option><option value=\"22\">v4.13.0</option><option value=\"23\">v4.12.5</option><option value=\"24\">v4.11.3</option><option value=\"25\">v4.10.1</option><option value=\"26\">v4.9.2</option><option value=\"27\">v4.8.2</option><option value=\"28\">v4.7.0</option><option value=\"29\">v4.6.0</option><option value=\"30\">v4.5.1</option><option value=\"31\">v4.4.2</option><option value=\"32\">v4.3.3</option><option value=\"33\">v4.2.2</option><option value=\"34\">v4.1.1</option><option value=\"35\">v4.0.1</option><option value=\"36\">v3.5.1</option><option value=\"37\">v3.4.0</option><option value=\"38\">v3.3.1</option><option value=\"39\">v3.2.0</option><option value=\"40\">v3.1.0</option><option value=\"41\">v3.0.2</option><option value=\"42\">v2.11.0</option><option value=\"43\">v2.10.0</option><option value=\"44\">v2.9.1</option><option value=\"45\">v2.8.0</option><option value=\"46\">v2.7.0</option><option value=\"47\">v2.6.0</option><option value=\"48\">v2.5.1</option><option value=\"49\">v2.4.1</option><option value=\"50\">v2.3.0</option><option value=\"51\">v2.2.2</option><option value=\"52\">v2.1.1</option><option value=\"53\">v2.0.0</option><option value=\"54\">v1.2.0</option><option value=\"55\">v1.1.0</option><option value=\"56\">v1.0.0</option><option value=\"57\">doc-builder-html</option></select> <select class=\"form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border\"><option value=\"de\">DE</option><option value=\"en\">EN</option><option value=\"es\">ES</option><option value=\"fr\">FR</option><option value=\"it\">IT</option><option value=\"ko\">KO</option><option value=\"pt\">PT</option><option value=\"zh\">ZH</option></select> <div class=\"relative inline-block\"><button class=\"rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 \" type=\"button\"><svg class=\"mr-1.5 text-yellow-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\" fill=\"currentColor\"><path d=\"M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z\"></path></svg>  </button> </div> <a href=\"https://github.com/huggingface/transformers\" class=\"group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300\"><svg class=\"inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1.03em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 250\"><path d=\"M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z\" fill=\"currentColor\"></path></svg> 112,792</a></div></div> <nav class=\"top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pt-3 pb-16 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]\"> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Get started</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/index\">🤗 Transformers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/quicktour\">Quick tour </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/installation\">Installation </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Tutorials</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_tutorial\">Run inference with pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/autoclass_tutorial\">Write portable code with AutoClass </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/preprocessing\">Preprocess data </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/training\">Fine-tune a pretrained model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/run_scripts\">Train with a script </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/accelerate\">Set up distributed training with 🤗 Accelerate </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/peft\">Load and train adapters with 🤗 PEFT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_sharing\">Share your model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/transformers_agents\">Agents </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/llm_tutorial\">Generation with LLMs </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Task Guides</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Natural Language Processing</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Computer Vision</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Generation</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Prompting</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Developer guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/fast_tokenizers\">Use fast tokenizers from 🤗 Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/multilingual\">Run inference with multilingual models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/create_a_model\">Use model-specific APIs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_models\">Share a custom model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/chat_templating\">Templates for chat models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/sagemaker\">Run training on Amazon SageMaker </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/serialization\">Export to ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tflite\">Export to TFLite </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/torchscript\">Export to TorchScript </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/benchmarks\">Benchmarks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/notebooks\">Notebooks with examples </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/community\">Community resources </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_tools\">Custom Tools and Prompts </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/troubleshooting\">Troubleshoot </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Performance and scalability</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/performance\">Overview </a><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Efficient training techniques</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_one\">Methods and tools for efficient training on a single GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_many\">Multiple GPUs and parallelism </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu\">Efficient training on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu_many\">Distributed CPU training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu\">Training on TPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu_tf\">Training on TPU with TensorFlow </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_special\">Training on Specialized Hardware </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_hardware\">Custom hardware for training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/hpo_train\">Hyperparameter Search using Trainer API </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Optimizing inference</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_cpu\">Inference on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_one\">Inference on one GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_many\">Inference on many GPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_special\">Inference on Specialized Hardware </a> </div><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/big_models\">Instantiating a big model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/debugging\">Troubleshooting </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tf_xla\">XLA Integration for TensorFlow Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perf_torch_compile\">Optimize inference using `torch.compile()` </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Contribute</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/contributing\">How to contribute to transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_model\">How to add a model to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_tensorflow_model\">How to convert a 🤗 Transformers model to TensorFlow? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_pipeline\">How to add a pipeline to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/testing\">Testing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pr_checks\">Checks on a Pull Request </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Conceptual guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/philosophy\">Philosophy </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/glossary\">Glossary </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/task_summary\">What 🤗 Transformers can do </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tasks_explained\">How 🤗 Transformers solve tasks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_summary\">The Transformer model family </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tokenizer_summary\">Summary of the tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/attention\">Attention mechanisms </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pad_truncation\">Padding and truncation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/bertology\">BERTology </a><a data-sveltekit-reload=\"\" class=\"rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pr-2 pl-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-2\" href=\"/docs/transformers/v4.34.0/en/perplexity\">Perplexity of fixed-length models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_webserver\">Pipelines for webserver inference </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_memory_anatomy\">Model training anatomy </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>API</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Main Classes</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/agent\">Agents and Tools </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/model_doc/auto\">Auto Classes </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/callback\">Callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/configuration\">Configuration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/data_collator\">Data Collator </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/keras_callbacks\">Keras callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/logging\">Logging </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/model\">Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/text_generation\">Text Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/onnx\">ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules\">Optimization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/output\">Model outputs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/pipelines\">Pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/processors\">Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/quantization\">Quantization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer\">Tokenizer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/trainer\">Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/deepspeed\">DeepSpeed Integration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/feature_extractor\">Feature Extractor </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/image_processor\">Image Processor </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Models</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Text models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Vision models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Reinforcement learning models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Time series models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Graph models</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Internal Helpers</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/modeling_utils\">Custom Layers and Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/pipelines_utils\">Utilities for pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/tokenization_utils\">Utilities for Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/trainer_utils\">Utilities for Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/generation_utils\">Utilities for Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/image_processing_utils\">Utilities for Image Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/audio_utils\">Utilities for Audio processing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/file_utils\">General Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/time_series_utils\">Utilities for Time Series </a> </div> </div></nav></div></div></div>\\n\\t\\t<div class=\"z-1 min-w-0 flex-1\">\\n\\t\\t\\t<div class=\"px-6 pt-6 md:px-12 md:pt-16 md:pb-16\"><div class=\"max-w-4xl mx-auto mb-10\"><div class=\"relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 py-5 px-4 ring-1 ring-orange-100/70 md:px-6 md:py-8\"><img alt=\"Hugging Face\\'s logo\" class=\"absolute -right-6 -bottom-6 w-28 -rotate-45 md:hidden\" src=\"/front/assets/huggingface_logo-noborder.svg\">\\n\\t\\t<div class=\"mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0\">Join the Hugging Face community</div>\\n\\t\\t<p class=\"mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8\">and get access to the augmented documentation experience\\n\\t\\t</p>\\n\\t\\t<div class=\"mb-8 hidden space-y-4 md:block xl:flex xl:space-y-0 xl:space-x-6\"><div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100\"><svg class=\"text-indigo-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Collaborate on models, datasets and Spaces\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"text-xl text-yellow-400\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M11 15H6l7-14v8h5l-7 14v-8z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Faster examples with accelerated inference\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5\"><svg class=\"text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Switch between documentation themes\\n\\t\\t\\t\\t</div></div></div>\\n\\t\\t<div class=\"flex items-center space-x-2.5\"><a href=\"/join\"><button class=\"rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 py-1.5 px-5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner\">Sign Up</button></a>\\n\\t\\t\\t<p class=\"text-gray-500 dark:text-gray-300\">to get started</p></div></div></div>\\n\\t\\t\\t\\t<div class=\"prose-doc prose relative mx-auto max-w-4xl break-words\"> <p></p> <h1 class=\"relative group\"><a id=\"perplexity-of-fixedlength-models\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#perplexity-of-fixedlength-models\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-11mcch1\">Perplexity of fixed-length models</span></h1> <div class=\"flex space-x-1 absolute z-10 right-0 top-0\"> <div class=\"relative colab-dropdown \"><button class=\"  \" type=\"button\"><img alt=\"Open In Colab\" class=\"!m-0\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></button> </div> <div class=\"relative colab-dropdown \"><button class=\"  \" type=\"button\"><img alt=\"Open In Studio Lab\" class=\"!m-0\" src=\"https://studiolab.sagemaker.aws/studiolab.svg\"></button> </div></div> <p data-svelte-h=\"svelte-syn4xn\">Perplexity (PPL) is one of the most common metrics for evaluating language models. Before diving in, we should note\\nthat the metric applies specifically to classical language models (sometimes called autoregressive or causal language\\nmodels) and is not well defined for masked language models like BERT (see <a href=\"model_summary\">summary of the models</a>).</p> <p>Perplexity is defined as the exponentiated average negative log-likelihood of a sequence. If we have a tokenized\\nsequence <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>…</mo><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">X = (x_0, x_1, \\\\dots, x_t)</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>, then the perplexity of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> is,</p> <p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>PPL</mtext><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>exp</mi><mo>\\u2061</mo><mrow><mo fence=\"true\">{</mo><mrow><mo>−</mo><mfrac><mn>1</mn><mi>t</mi></mfrac><munderover><mo>∑</mo><mi>i</mi><mi>t</mi></munderover><mi>log</mi><mo>\\u2061</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo fence=\"true\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\\\text{PPL}(X) = \\\\exp \\\\left\\\\{ {-\\\\frac{1}{t}\\\\sum_i^t \\\\log p_\\\\theta (x_i|x_{&lt;i}) } \\\\right\\\\}</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">PPL</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0582em;vertical-align:-1.2777em;\"></span><span class=\"mop\">exp</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">{</span></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.7806em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2777em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">&lt;</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1774em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">}</span></span></span></span></span></span></span></p> <p>where <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>log</mi><mo>\\u2061</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\\\log p_\\\\theta (x_i|x_{&lt;i})</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">&lt;</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1774em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> is the log-likelihood of the ith token conditioned on the preceding tokens <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">x_{&lt;i}</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6079em;vertical-align:-0.1774em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">&lt;</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1774em;\"><span></span></span></span></span></span></span></span></span></span> according to our model. Intuitively, it can be thought of as an evaluation of the model’s ability to predict uniformly among the set of specified tokens in a corpus. Importantly, this means that the tokenization procedure has a direct impact on a model’s perplexity which should always be taken into consideration when comparing different models.</p> <p data-svelte-h=\"svelte-10yo7ds\">This is also equivalent to the exponentiation of the cross-entropy between the data and model predictions. For more\\nintuition about perplexity and its relationship to Bits Per Character (BPC) and data compression, check out this\\n<a href=\"https://thegradient.pub/understanding-evaluation-metrics-for-language-models/\" rel=\"nofollow\">fantastic blog post on The Gradient</a>.</p> <h2 class=\"relative group\"><a id=\"calculating-ppl-with-fixedlength-models\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#calculating-ppl-with-fixedlength-models\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1a3jub9\">Calculating PPL with fixed-length models</span></h2> <p data-svelte-h=\"svelte-nt0thp\">If we weren’t limited by a model’s context size, we would evaluate the model’s perplexity by autoregressively\\nfactorizing a sequence and conditioning on the entire preceding subsequence at each step, as shown below.</p> <img width=\"600\" alt=\"Full decomposition of a sequence with unlimited context length\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif\"> <p>When working with approximate models, however, we typically have a constraint on the number of tokens the model can\\nprocess. The largest version of <a href=\"model_doc/gpt2\" data-svelte-h=\"svelte-1kdeo4m\">GPT-2</a>, for example, has a fixed length of 1024 tokens, so we\\ncannot calculate <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">p_\\\\theta(x_t|x_{&lt;t})</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">&lt;</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1774em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> directly when <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> is greater than 1024.</p> <p>Instead, the sequence is typically broken into subsequences equal to the model’s maximum input size. If a model’s max\\ninput size is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>, we then approximate the likelihood of a token <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">\\u200b</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> by conditioning only on the\\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">k-1</annotation></semantics></math></span><span class=\"katex-html hidden\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span> tokens that precede it rather than the entire context. When evaluating the model’s perplexity of a\\nsequence, a tempting but suboptimal approach is to break the sequence into disjoint chunks and add up the decomposed\\nlog-likelihoods of each segment independently.</p> <img width=\"600\" alt=\"Suboptimal PPL not taking advantage of full available context\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif\"> <p data-svelte-h=\"svelte-19oj8tf\">This is quick to compute since the perplexity of each segment can be computed in one forward pass, but serves as a poor\\napproximation of the fully-factorized perplexity and will typically yield a higher (worse) PPL because the model will\\nhave less context at most of the prediction steps.</p> <p data-svelte-h=\"svelte-w5z9wi\">Instead, the PPL of fixed-length models should be evaluated with a sliding-window strategy. This involves repeatedly\\nsliding the context window so that the model has more context when making each prediction.</p> <img width=\"600\" alt=\"Sliding window PPL taking advantage of all available context\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_sliding.gif\"> <p data-svelte-h=\"svelte-zqbk5w\">This is a closer approximation to the true decomposition of the sequence probability and will typically yield a more\\nfavorable score. The downside is that it requires a separate forward pass for each token in the corpus. A good\\npractical compromise is to employ a strided sliding window, moving the context by larger strides rather than sliding by\\n1 token a time. This allows computation to proceed much faster while still giving the model a large context to make\\npredictions at each step.</p> <h2 class=\"relative group\"><a id=\"example-calculating-perplexity-with-gpt2-in-transformers\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#example-calculating-perplexity-with-gpt2-in-transformers\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-13x259g\">Example: Calculating perplexity with GPT-2 in 🤗 Transformers</span></h2> <p data-svelte-h=\"svelte-atwk84\">Let’s demonstrate this process with GPT-2.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> GPT2LMHeadModel, GPT2TokenizerFast\\n\\ndevice = <span class=\"hljs-string\">\"cuda\"</span>\\nmodel_id = <span class=\"hljs-string\">\"gpt2-large\"</span>\\nmodel = GPT2LMHeadModel.from_pretrained(model_id).to(device)\\ntokenizer = GPT2TokenizerFast.from_pretrained(model_id)</pre></div> <p data-svelte-h=\"svelte-1jth08f\">We’ll load in the WikiText-2 dataset and evaluate the perplexity using a few different sliding-window strategies. Since\\nthis dataset is small and we’re just doing one forward pass over the set, we can just load and encode the entire\\ndataset in memory.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\\n\\ntest = load_dataset(<span class=\"hljs-string\">\"wikitext\"</span>, <span class=\"hljs-string\">\"wikitext-2-raw-v1\"</span>, split=<span class=\"hljs-string\">\"test\"</span>)\\nencodings = tokenizer(<span class=\"hljs-string\">\"\\\\n\\\\n\"</span>.join(test[<span class=\"hljs-string\">\"text\"</span>]), return_tensors=<span class=\"hljs-string\">\"pt\"</span>)</pre></div> <p data-svelte-h=\"svelte-1jepp38\">With 🤗 Transformers, we can simply pass the <code>input_ids</code> as the <code>labels</code> to our model, and the average negative\\nlog-likelihood for each token is returned as the loss. With our sliding window approach, however, there is overlap in\\nthe tokens we pass to the model at each iteration. We don’t want the log-likelihood for the tokens we’re just treating\\nas context to be included in our loss, so we can set these targets to <code>-100</code> so that they are ignored. The following\\nis an example of how we could do this with a stride of <code>512</code>. This means that the model will have at least 512 tokens\\nfor context when calculating the conditional likelihood of any one token (provided there are 512 preceding tokens\\navailable to condition on).</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-keyword\">import</span> torch\\n<span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm\\n\\nmax_length = model.config.n_positions\\nstride = <span class=\"hljs-number\">512</span>\\nseq_len = encodings.input_ids.size(<span class=\"hljs-number\">1</span>)\\n\\nnlls = []\\nprev_end_loc = <span class=\"hljs-number\">0</span>\\n<span class=\"hljs-keyword\">for</span> begin_loc <span class=\"hljs-keyword\">in</span> tqdm(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, seq_len, stride)):\\n    end_loc = <span class=\"hljs-built_in\">min</span>(begin_loc + max_length, seq_len)\\n    trg_len = end_loc - prev_end_loc  <span class=\"hljs-comment\"># may be different from stride on last loop</span>\\n    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\\n    target_ids = input_ids.clone()\\n    target_ids[:, :-trg_len] = -<span class=\"hljs-number\">100</span>\\n\\n    <span class=\"hljs-keyword\">with</span> torch.no_grad():\\n        outputs = model(input_ids, labels=target_ids)\\n\\n        <span class=\"hljs-comment\"># loss is calculated using CrossEntropyLoss which averages over valid labels</span>\\n        <span class=\"hljs-comment\"># N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels</span>\\n        <span class=\"hljs-comment\"># to the left by 1.</span>\\n        neg_log_likelihood = outputs.loss\\n\\n    nlls.append(neg_log_likelihood)\\n\\n    prev_end_loc = end_loc\\n    <span class=\"hljs-keyword\">if</span> end_loc == seq_len:\\n        <span class=\"hljs-keyword\">break</span>\\n\\nppl = torch.exp(torch.stack(nlls).mean())</pre></div> <p data-svelte-h=\"svelte-6e6tqv\">Running this with the stride length equal to the max input length is equivalent to the suboptimal, non-sliding-window\\nstrategy we discussed above. The smaller the stride, the more context the model will have in making each prediction,\\nand the better the reported perplexity will typically be.</p> <p data-svelte-h=\"svelte-1um3qvs\">When we run the above with <code>stride = 1024</code>, i.e. no overlap, the resulting PPL is <code>19.44</code>, which is about the same\\nas the <code>19.93</code> reported in the GPT-2 paper. By using <code>stride = 512</code> and thereby employing our striding window\\nstrategy, this jumps down to <code>16.45</code>. This is not only a more favorable score, but is calculated in a way that is\\ncloser to the true autoregressive decomposition of a sequence likelihood.</p> <p></p> <div id=\"svelte-announcer\" aria-live=\"assertive\" aria-atomic=\"true\" style=\"position: absolute; left: 0px; top: 0px; clip: rect(0px, 0px, 0px, 0px); clip-path: inset(50%); overflow: hidden; white-space: nowrap; width: 1px; height: 1px;\"></div></div>\\n\\t\\t\\t\\t<div class=\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\"><a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/bertology\" class=\"mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300\"><span class=\"mr-2 translate-y-px\">←</span>BERTology</a>\\n\\t\\t\\t\\t\\t<a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/pipeline_webserver\" class=\"ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300\">Pipelines for webserver inference<span class=\"ml-2 translate-y-px\">→</span></a></div></div></div>\\n\\t\\t<div class=\"sticky top-0 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapter&quot;:{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity-of-fixedlength-models&quot;,&quot;url&quot;:&quot;#perplexity-of-fixedlength-models&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Calculating PPL with fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;calculating-ppl-with-fixedlength-models&quot;,&quot;url&quot;:&quot;#calculating-ppl-with-fixedlength-models&quot;},{&quot;title&quot;:&quot;Example: Calculating perplexity with GPT-2 in 🤗 Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;example-calculating-perplexity-with-gpt2-in-transformers&quot;,&quot;url&quot;:&quot;#example-calculating-perplexity-with-gpt2-in-transformers&quot;}]}}\" data-target=\"SubSideMenu\"><nav class=\"hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pt-24 pl-6 pr-10 pb-16 text-sm lg:flex 2xl:w-[305px]\"><a href=\"#perplexity-of-fixedlength-models\" class=\" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-perplexity-of-fixedlength-models\"><wbr>Perplexity of fixed-length models</a> <a href=\"#calculating-ppl-with-fixedlength-models\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-calculating-ppl-with-fixedlength-models\"><wbr>Calculating PP<wbr>L with fixed-length models</a> <a href=\"#example-calculating-perplexity-with-gpt2-in-transformers\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-example-calculating-perplexity-with-gpt2-in-transformers\"><wbr>Example: <wbr>Calculating perplexity with GP<wbr>T-2 in 🤗 <wbr>Transformers</a> </nav></div></div></div>\\n\\t<div id=\"doc-footer\"></div></main>\\n\\t</div>\\n\\n\\t\\t<script>\\n\\t\\t\\timport(\"/front/build/kube-b0520c1/index.js\");\\n\\t\\t\\twindow.moonSha = \"kube-b0520c1/\";\\n\\t\\t\\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\"}`);\\n\\t\\t</script>\\n\\n\\t\\t<!-- Stripe -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://js.stripe.com/v3/\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google analytics v4 -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\n\\t\\t\\t\\twindow.dataLayer = window.dataLayer || [];\\n\\t\\t\\t\\tfunction gtag() {\\n\\t\\t\\t\\t\\tif (window.dataLayer !== undefined) {\\n\\t\\t\\t\\t\\t\\twindow.dataLayer.push(arguments);\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tgtag(\"js\", new Date());\\n\\t\\t\\t\\tgtag(\"config\", \"G-8Q63TH4CSL\", { page_path: \"/docs/transformers/v4.34.0/en/perplexity\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages\\n\\t\\t\\t\\tgtag(\"consent\", \"default\", { ad_storage: \"denied\", analytics_storage: \"denied\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent\\n\\t\\t\\t\\t/// TODO: ask the user for their consent and update this with gtag(\\'consent\\', \\'update\\')\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google Analytics v3 (deprecated) -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\t(function (i, s, o, g, r, a, m) {\\n\\t\\t\\t\\t\\ti[\"GoogleAnalyticsObject\"] = r;\\n\\t\\t\\t\\t\\t(i[r] =\\n\\t\\t\\t\\t\\t\\ti[r] ||\\n\\t\\t\\t\\t\\t\\tfunction () {\\n\\t\\t\\t\\t\\t\\t\\t(i[r].q = i[r].q || []).push(arguments);\\n\\t\\t\\t\\t\\t\\t}),\\n\\t\\t\\t\\t\\t\\t(i[r].l = 1 * new Date());\\n\\t\\t\\t\\t\\t(a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);\\n\\t\\t\\t\\t\\ta.async = 1;\\n\\t\\t\\t\\t\\ta.src = g;\\n\\t\\t\\t\\t\\tm.parentNode.insertBefore(a, m);\\n\\t\\t\\t\\t})(window, document, \"script\", \"https://www.google-analytics.com/analytics.js\", \"ganalytics\");\\n\\t\\t\\t\\tganalytics(\"create\", \"UA-83738774-2\", \"auto\");\\n\\t\\t\\t\\tganalytics(\"send\", \"pageview\", \"/docs/transformers/v4.34.0/en/perplexity\");\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\t\\n\\n<iframe name=\"__privateStripeMetricsController5410\" frameborder=\"0\" allowtransparency=\"true\" scrolling=\"no\" role=\"presentation\" allow=\"payment *\" src=\"https://js.stripe.com/v3/m-outer-27c67c0d52761104439bb051c7856ab1.html#url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftransformers%2Fv4.34.0%2Fen%2Fperplexity&amp;title=Perplexity%20of%20fixed-length%20models&amp;referrer=&amp;muid=NA&amp;sid=NA&amp;version=6&amp;preview=false\" aria-hidden=\"true\" tabindex=\"-1\" style=\"border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;\"></iframe></body></html>',\n",
       "  'mime_type': 'text/plain',\n",
       "  'metadata': {}},\n",
       " {'document_id': '4',\n",
       "  'content': '<!DOCTYPE html><html class=\"\"><head>\\n\\t\\t<meta charset=\"utf-8\">\\n\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\">\\n\\t\\t<meta name=\"description\" content=\"We’re on a journey to advance and democratize artificial intelligence through open source and open science.\">\\n\\t\\t<meta property=\"fb:app_id\" content=\"1321688464574422\">\\n\\t\\t<meta name=\"twitter:card\" content=\"summary_large_image\">\\n\\t\\t<meta name=\"twitter:site\" content=\"@huggingface\">\\n\\t\\t<meta property=\"og:title\" content=\"Sample usage\">\\n\\t\\t<meta property=\"og:type\" content=\"website\">\\n\\t\\t<meta property=\"og:url\" content=\"https://huggingface.co/docs/transformers/v4.34.0/en/model_doc/umt5\">\\n\\t\\t<meta property=\"og:image\" content=\"https://huggingface.co/front/thumbnails/docs/transformers.png\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"/front/build/kube-b0520c1/style.css\">\\n\\n\\t\\t<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap\" rel=\"stylesheet\">\\n\\t\\t<link href=\"https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap\" rel=\"stylesheet\">\\n\\n\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" as=\"style\" onload=\"this.onload=null;this.rel=\\'stylesheet\\'\">\\n\\t\\t<noscript>\\n\\t\\t\\t<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" />\\n\\t\\t</noscript>\\n\\n\\t\\t  \\n\\n\\t\\t<title>Sample usage</title>\\n\\n\\t\\t<script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script defer=\"\" data-domain=\"huggingface.co\" src=\"/js/script.js\"></script>\\n\\t<script src=\"https://js.stripe.com/v3/\" async=\"\"></script><script src=\"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\" async=\"\"></script><link rel=\"stylesheet\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/assets/0.e3b0c442.css\"><link rel=\"modulepreload\" as=\"script\" crossorigin=\"\" href=\"/docs/transformers/v4.34.0/en/_app/immutable/nodes/1.38c5c2f6.js\"><meta http-equiv=\"origin-trial\" content=\"AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9\"><meta name=\"hf:doc:metadata\" content=\"{&quot;local&quot;:&quot;sample-usage&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;transformers.UMT5Config&quot;,&quot;title&quot;:&quot;UMT5Config&quot;},{&quot;local&quot;:&quot;transformers.UMT5Model&quot;,&quot;title&quot;:&quot;UMT5Model&quot;},{&quot;local&quot;:&quot;transformers.UMT5ForConditionalGeneration&quot;,&quot;title&quot;:&quot;UMT5ForConditionalGeneration&quot;},{&quot;local&quot;:&quot;transformers.UMT5EncoderModel&quot;,&quot;title&quot;:&quot;UMT5EncoderModel&quot;},{&quot;local&quot;:&quot;transformers.UMT5ForSequenceClassification&quot;,&quot;title&quot;:&quot;UMT5ForSequenceClassification&quot;},{&quot;local&quot;:&quot;transformers.UMT5ForQuestionAnswering&quot;,&quot;title&quot;:&quot;UMT5ForQuestionAnswering&quot;}],&quot;title&quot;:&quot;Sample usage&quot;}\"></head>\\n\\t<body class=\"flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage\">\\n\\t\\t<div class=\"flex min-h-screen flex-col\">\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}\" data-target=\"MainHeader\"><header class=\"border-b border-gray-100 \"><div class=\"w-full px-4  flex h-16 items-center\"><div class=\"flex flex-1 items-center\"><a class=\"mr-5 flex flex-none items-center lg:mr-6\" href=\"/\"><img alt=\"Hugging Face\\'s logo\" class=\"w-7 md:mr-2\" src=\"/front/assets/huggingface_logo-noborder.svg\"> <span class=\"hidden whitespace-nowrap text-lg font-bold md:block\">Hugging Face</span></a> <div class=\"relative flex-1 lg:max-w-sm mr-2 sm:mr-4 lg:mr-6\"><input autocomplete=\"off\" class=\"w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl\" name=\"\" placeholder=\"Search models, datasets, users...\" spellcheck=\"false\" type=\"text\"> <svg class=\"absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> </div> <div class=\"flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden\"><button class=\"relative z-40 flex h-6 w-8 items-center justify-center\" type=\"button\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 10 10\" class=\"text-xl\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" preserveAspectRatio=\"xMidYMid meet\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\"></path></svg> </button> </div></div> <nav aria-label=\"Main\" class=\"ml-auto hidden lg:block\"><ul class=\"flex items-center space-x-2\"><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700\" href=\"/models\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg> Models</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700\" href=\"/datasets\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-red-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 25 25\"><ellipse cx=\"12.5\" cy=\"5\" fill=\"currentColor\" fill-opacity=\"0.25\" rx=\"7.5\" ry=\"2\"></ellipse><path d=\"M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z\" fill=\"currentColor\"></path></svg> Datasets</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700\" href=\"/spaces\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-blue-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 25 25\"><path opacity=\".5\" d=\"M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z\" fill=\"currentColor\"></path><path opacity=\".75\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z\" fill=\"currentColor\"></path><path opacity=\".25\" d=\"M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z\" fill=\"currentColor\"></path></svg> Spaces</a></li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/docs\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path opacity=\"0.5\" d=\"M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z\" fill=\"currentColor\"></path><path d=\"M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z\" fill=\"currentColor\" fill-opacity=\"0.75\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z\" fill=\"currentColor\"></path><path opacity=\"0.5\" d=\"M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z\" fill=\"currentColor\"></path></svg> Docs</a></li> <li><div class=\"relative \"><button class=\"px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-400 group-hover:text-green-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-tertiary\" d=\"M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z\" fill=\"currentColor\"></path></svg> Solutions </button> </div></li> <li><a class=\"group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/pricing\">Pricing</a></li> <li><div class=\"relative group\"><button class=\"px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center \" type=\"button\"><svg class=\"mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" viewBox=\"0 0 32 18\" preserveAspectRatio=\"xMidYMid meet\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z\" fill=\"currentColor\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z\" fill=\"currentColor\"></path></svg>  </button> </div></li> <li><hr class=\"h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800\"></li> <li><a class=\"block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/login\">Log In</a></li> <li><a class=\"rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black\" href=\"/join\">Sign Up</a></li></ul></nav></div></header></div>\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"GoogleAnalyticsTracker\"></div>\\n\\t\\n\\t\\n\\t<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"SSOBanner\"></div>\\n\\n\\t<main class=\"flex flex-1 flex-col\"><div class=\"relative lg:flex\"><div class=\"sticky top-0 z-20 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;🤗 Transformers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/index&quot;},{&quot;title&quot;:&quot;Quick tour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;installation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/installation&quot;}]},{&quot;title&quot;:&quot;Tutorials&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Run inference with pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_tutorial&quot;},{&quot;title&quot;:&quot;Write portable code with AutoClass&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;autoclass_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/autoclass_tutorial&quot;},{&quot;title&quot;:&quot;Preprocess data&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;preprocessing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/preprocessing&quot;},{&quot;title&quot;:&quot;Fine-tune a pretrained model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;training&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/training&quot;},{&quot;title&quot;:&quot;Train with a script&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;run_scripts&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/run_scripts&quot;},{&quot;title&quot;:&quot;Set up distributed training with 🤗 Accelerate&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/accelerate&quot;},{&quot;title&quot;:&quot;Load and train adapters with 🤗 PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;peft&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/peft&quot;},{&quot;title&quot;:&quot;Share your model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_sharing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_sharing&quot;},{&quot;title&quot;:&quot;Agents&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers_agents&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/transformers_agents&quot;},{&quot;title&quot;:&quot;Generation with LLMs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;llm_tutorial&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/llm_tutorial&quot;}]},{&quot;title&quot;:&quot;Task Guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Natural Language Processing&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text classification&quot;,&quot;id&quot;:&quot;tasks/sequence_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/sequence_classification&quot;},{&quot;title&quot;:&quot;Token classification&quot;,&quot;id&quot;:&quot;tasks/token_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/token_classification&quot;},{&quot;title&quot;:&quot;Question answering&quot;,&quot;id&quot;:&quot;tasks/question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/question_answering&quot;},{&quot;title&quot;:&quot;Causal language modeling&quot;,&quot;id&quot;:&quot;tasks/language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/language_modeling&quot;},{&quot;title&quot;:&quot;Masked language modeling&quot;,&quot;id&quot;:&quot;tasks/masked_language_modeling&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/masked_language_modeling&quot;},{&quot;title&quot;:&quot;Translation&quot;,&quot;id&quot;:&quot;tasks/translation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/translation&quot;},{&quot;title&quot;:&quot;Summarization&quot;,&quot;id&quot;:&quot;tasks/summarization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/summarization&quot;},{&quot;title&quot;:&quot;Multiple choice&quot;,&quot;id&quot;:&quot;tasks/multiple_choice&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/multiple_choice&quot;}]},{&quot;title&quot;:&quot;Audio&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio classification&quot;,&quot;id&quot;:&quot;tasks/audio_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/audio_classification&quot;},{&quot;title&quot;:&quot;Automatic speech recognition&quot;,&quot;id&quot;:&quot;tasks/asr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/asr&quot;}]},{&quot;title&quot;:&quot;Computer Vision&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image classification&quot;,&quot;id&quot;:&quot;tasks/image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_classification&quot;},{&quot;title&quot;:&quot;Semantic segmentation&quot;,&quot;id&quot;:&quot;tasks/semantic_segmentation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/semantic_segmentation&quot;},{&quot;title&quot;:&quot;Video classification&quot;,&quot;id&quot;:&quot;tasks/video_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/video_classification&quot;},{&quot;title&quot;:&quot;Object detection&quot;,&quot;id&quot;:&quot;tasks/object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot object detection&quot;,&quot;id&quot;:&quot;tasks/zero_shot_object_detection&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_object_detection&quot;},{&quot;title&quot;:&quot;Zero-shot image classification&quot;,&quot;id&quot;:&quot;tasks/zero_shot_image_classification&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/zero_shot_image_classification&quot;},{&quot;title&quot;:&quot;Depth estimation&quot;,&quot;id&quot;:&quot;tasks/monocular_depth_estimation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/monocular_depth_estimation&quot;}]},{&quot;title&quot;:&quot;Multimodal&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image captioning&quot;,&quot;id&quot;:&quot;tasks/image_captioning&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/image_captioning&quot;},{&quot;title&quot;:&quot;Document Question Answering&quot;,&quot;id&quot;:&quot;tasks/document_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/document_question_answering&quot;},{&quot;title&quot;:&quot;Visual Question Answering&quot;,&quot;id&quot;:&quot;tasks/visual_question_answering&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/visual_question_answering&quot;},{&quot;title&quot;:&quot;Text to speech&quot;,&quot;id&quot;:&quot;tasks/text-to-speech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/text-to-speech&quot;}]},{&quot;title&quot;:&quot;Generation&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Customize the generation strategy&quot;,&quot;id&quot;:&quot;generation_strategies&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/generation_strategies&quot;}]},{&quot;title&quot;:&quot;Prompting&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Image tasks with IDEFICS&quot;,&quot;id&quot;:&quot;tasks/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks/idefics&quot;}]}]},{&quot;title&quot;:&quot;Developer guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Use fast tokenizers from 🤗 Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;fast_tokenizers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/fast_tokenizers&quot;},{&quot;title&quot;:&quot;Run inference with multilingual models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;multilingual&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/multilingual&quot;},{&quot;title&quot;:&quot;Use model-specific APIs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;create_a_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/create_a_model&quot;},{&quot;title&quot;:&quot;Share a custom model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_models&quot;},{&quot;title&quot;:&quot;Templates for chat models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;chat_templating&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/chat_templating&quot;},{&quot;title&quot;:&quot;Run training on Amazon SageMaker&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sagemaker&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/sagemaker&quot;},{&quot;title&quot;:&quot;Export to ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;serialization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/serialization&quot;},{&quot;title&quot;:&quot;Export to TFLite&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tflite&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tflite&quot;},{&quot;title&quot;:&quot;Export to TorchScript&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;torchscript&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/torchscript&quot;},{&quot;title&quot;:&quot;Benchmarks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;benchmarks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/benchmarks&quot;},{&quot;title&quot;:&quot;Notebooks with examples&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;notebooks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/notebooks&quot;},{&quot;title&quot;:&quot;Community resources&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;community&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/community&quot;},{&quot;title&quot;:&quot;Custom Tools and Prompts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;custom_tools&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/custom_tools&quot;},{&quot;title&quot;:&quot;Troubleshoot&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;troubleshooting&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/troubleshooting&quot;}]},{&quot;title&quot;:&quot;Performance and scalability&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Overview&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;performance&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/performance&quot;},{&quot;title&quot;:&quot;Efficient training techniques&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Methods and tools for efficient training on a single GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_one&quot;},{&quot;title&quot;:&quot;Multiple GPUs and parallelism&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_gpu_many&quot;},{&quot;title&quot;:&quot;Efficient training on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu&quot;},{&quot;title&quot;:&quot;Distributed CPU training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_cpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_cpu_many&quot;},{&quot;title&quot;:&quot;Training on TPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu&quot;},{&quot;title&quot;:&quot;Training on TPU with TensorFlow&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_tpu_tf&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_tpu_tf&quot;},{&quot;title&quot;:&quot;Training on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_train_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_train_special&quot;},{&quot;title&quot;:&quot;Custom hardware for training&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_hardware&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_hardware&quot;},{&quot;title&quot;:&quot;Hyperparameter Search using Trainer API&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;hpo_train&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/hpo_train&quot;}]},{&quot;title&quot;:&quot;Optimizing inference&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Inference on CPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_cpu&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_cpu&quot;},{&quot;title&quot;:&quot;Inference on one GPU&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_one&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_one&quot;},{&quot;title&quot;:&quot;Inference on many GPUs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_gpu_many&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_gpu_many&quot;},{&quot;title&quot;:&quot;Inference on Specialized Hardware&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_infer_special&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_infer_special&quot;}]},{&quot;title&quot;:&quot;Instantiating a big model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;big_models&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/big_models&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;debugging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/debugging&quot;},{&quot;title&quot;:&quot;XLA Integration for TensorFlow Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tf_xla&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tf_xla&quot;},{&quot;title&quot;:&quot;Optimize inference using `torch.compile()`&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perf_torch_compile&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perf_torch_compile&quot;}]},{&quot;title&quot;:&quot;Contribute&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;How to contribute to transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;contributing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/contributing&quot;},{&quot;title&quot;:&quot;How to add a model to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_model&quot;},{&quot;title&quot;:&quot;How to convert a 🤗 Transformers model to TensorFlow?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_tensorflow_model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_tensorflow_model&quot;},{&quot;title&quot;:&quot;How to add a pipeline to 🤗 Transformers?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;add_new_pipeline&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/add_new_pipeline&quot;},{&quot;title&quot;:&quot;Testing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;testing&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/testing&quot;},{&quot;title&quot;:&quot;Checks on a Pull Request&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pr_checks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pr_checks&quot;}]},{&quot;title&quot;:&quot;Conceptual guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Philosophy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;philosophy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/philosophy&quot;},{&quot;title&quot;:&quot;Glossary&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;glossary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/glossary&quot;},{&quot;title&quot;:&quot;What 🤗 Transformers can do&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/task_summary&quot;},{&quot;title&quot;:&quot;How 🤗 Transformers solve tasks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tasks_explained&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tasks_explained&quot;},{&quot;title&quot;:&quot;The Transformer model family&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_summary&quot;},{&quot;title&quot;:&quot;Summary of the tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tokenizer_summary&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/tokenizer_summary&quot;},{&quot;title&quot;:&quot;Attention mechanisms&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;attention&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/attention&quot;},{&quot;title&quot;:&quot;Padding and truncation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pad_truncation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pad_truncation&quot;},{&quot;title&quot;:&quot;BERTology&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;bertology&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/bertology&quot;},{&quot;title&quot;:&quot;Perplexity of fixed-length models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;perplexity&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/perplexity&quot;},{&quot;title&quot;:&quot;Pipelines for webserver inference&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;pipeline_webserver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/pipeline_webserver&quot;},{&quot;title&quot;:&quot;Model training anatomy&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_memory_anatomy&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_memory_anatomy&quot;}]},{&quot;title&quot;:&quot;API&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main Classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Agents and Tools&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/agent&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/agent&quot;},{&quot;title&quot;:&quot;Auto Classes&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/auto&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/auto&quot;},{&quot;title&quot;:&quot;Callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/callback&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/callback&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/configuration&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/configuration&quot;},{&quot;title&quot;:&quot;Data Collator&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/data_collator&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/data_collator&quot;},{&quot;title&quot;:&quot;Keras callbacks&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/keras_callbacks&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/keras_callbacks&quot;},{&quot;title&quot;:&quot;Logging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/logging&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/logging&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/model&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/model&quot;},{&quot;title&quot;:&quot;Text Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/text_generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/text_generation&quot;},{&quot;title&quot;:&quot;ONNX&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/onnx&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/onnx&quot;},{&quot;title&quot;:&quot;Optimization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/optimizer_schedules&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules&quot;},{&quot;title&quot;:&quot;Model outputs&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/output&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/output&quot;},{&quot;title&quot;:&quot;Pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/pipelines&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/pipelines&quot;},{&quot;title&quot;:&quot;Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/processors&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/processors&quot;},{&quot;title&quot;:&quot;Quantization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/quantization&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/quantization&quot;},{&quot;title&quot;:&quot;Tokenizer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/tokenizer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/tokenizer&quot;},{&quot;title&quot;:&quot;Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/trainer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/trainer&quot;},{&quot;title&quot;:&quot;DeepSpeed Integration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/deepspeed&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/deepspeed&quot;},{&quot;title&quot;:&quot;Feature Extractor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/feature_extractor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/feature_extractor&quot;},{&quot;title&quot;:&quot;Image Processor&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;main_classes/image_processor&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/main_classes/image_processor&quot;}]},{&quot;title&quot;:&quot;Models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Text models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALBERT&quot;,&quot;id&quot;:&quot;model_doc/albert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/albert&quot;},{&quot;title&quot;:&quot;BART&quot;,&quot;id&quot;:&quot;model_doc/bart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bart&quot;},{&quot;title&quot;:&quot;BARThez&quot;,&quot;id&quot;:&quot;model_doc/barthez&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/barthez&quot;},{&quot;title&quot;:&quot;BARTpho&quot;,&quot;id&quot;:&quot;model_doc/bartpho&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bartpho&quot;},{&quot;title&quot;:&quot;BERT&quot;,&quot;id&quot;:&quot;model_doc/bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert&quot;},{&quot;title&quot;:&quot;BertGeneration&quot;,&quot;id&quot;:&quot;model_doc/bert-generation&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-generation&quot;},{&quot;title&quot;:&quot;BertJapanese&quot;,&quot;id&quot;:&quot;model_doc/bert-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bert-japanese&quot;},{&quot;title&quot;:&quot;Bertweet&quot;,&quot;id&quot;:&quot;model_doc/bertweet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bertweet&quot;},{&quot;title&quot;:&quot;BigBird&quot;,&quot;id&quot;:&quot;model_doc/big_bird&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/big_bird&quot;},{&quot;title&quot;:&quot;BigBirdPegasus&quot;,&quot;id&quot;:&quot;model_doc/bigbird_pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bigbird_pegasus&quot;},{&quot;title&quot;:&quot;BioGpt&quot;,&quot;id&quot;:&quot;model_doc/biogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/biogpt&quot;},{&quot;title&quot;:&quot;Blenderbot&quot;,&quot;id&quot;:&quot;model_doc/blenderbot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot&quot;},{&quot;title&quot;:&quot;Blenderbot Small&quot;,&quot;id&quot;:&quot;model_doc/blenderbot-small&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blenderbot-small&quot;},{&quot;title&quot;:&quot;BLOOM&quot;,&quot;id&quot;:&quot;model_doc/bloom&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bloom&quot;},{&quot;title&quot;:&quot;BORT&quot;,&quot;id&quot;:&quot;model_doc/bort&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bort&quot;},{&quot;title&quot;:&quot;ByT5&quot;,&quot;id&quot;:&quot;model_doc/byt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/byt5&quot;},{&quot;title&quot;:&quot;CamemBERT&quot;,&quot;id&quot;:&quot;model_doc/camembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/camembert&quot;},{&quot;title&quot;:&quot;CANINE&quot;,&quot;id&quot;:&quot;model_doc/canine&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/canine&quot;},{&quot;title&quot;:&quot;CodeGen&quot;,&quot;id&quot;:&quot;model_doc/codegen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/codegen&quot;},{&quot;title&quot;:&quot;CodeLlama&quot;,&quot;id&quot;:&quot;model_doc/code_llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/code_llama&quot;},{&quot;title&quot;:&quot;ConvBERT&quot;,&quot;id&quot;:&quot;model_doc/convbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convbert&quot;},{&quot;title&quot;:&quot;CPM&quot;,&quot;id&quot;:&quot;model_doc/cpm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpm&quot;},{&quot;title&quot;:&quot;CPMANT&quot;,&quot;id&quot;:&quot;model_doc/cpmant&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cpmant&quot;},{&quot;title&quot;:&quot;CTRL&quot;,&quot;id&quot;:&quot;model_doc/ctrl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ctrl&quot;},{&quot;title&quot;:&quot;DeBERTa&quot;,&quot;id&quot;:&quot;model_doc/deberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta&quot;},{&quot;title&quot;:&quot;DeBERTa-v2&quot;,&quot;id&quot;:&quot;model_doc/deberta-v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deberta-v2&quot;},{&quot;title&quot;:&quot;DialoGPT&quot;,&quot;id&quot;:&quot;model_doc/dialogpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dialogpt&quot;},{&quot;title&quot;:&quot;DistilBERT&quot;,&quot;id&quot;:&quot;model_doc/distilbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/distilbert&quot;},{&quot;title&quot;:&quot;DPR&quot;,&quot;id&quot;:&quot;model_doc/dpr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpr&quot;},{&quot;title&quot;:&quot;ELECTRA&quot;,&quot;id&quot;:&quot;model_doc/electra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/electra&quot;},{&quot;title&quot;:&quot;Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encoder-decoder&quot;},{&quot;title&quot;:&quot;ERNIE&quot;,&quot;id&quot;:&quot;model_doc/ernie&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie&quot;},{&quot;title&quot;:&quot;ErnieM&quot;,&quot;id&quot;:&quot;model_doc/ernie_m&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ernie_m&quot;},{&quot;title&quot;:&quot;ESM&quot;,&quot;id&quot;:&quot;model_doc/esm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/esm&quot;},{&quot;title&quot;:&quot;Falcon&quot;,&quot;id&quot;:&quot;model_doc/falcon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/falcon&quot;},{&quot;title&quot;:&quot;FLAN-T5&quot;,&quot;id&quot;:&quot;model_doc/flan-t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-t5&quot;},{&quot;title&quot;:&quot;FLAN-UL2&quot;,&quot;id&quot;:&quot;model_doc/flan-ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flan-ul2&quot;},{&quot;title&quot;:&quot;FlauBERT&quot;,&quot;id&quot;:&quot;model_doc/flaubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flaubert&quot;},{&quot;title&quot;:&quot;FNet&quot;,&quot;id&quot;:&quot;model_doc/fnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fnet&quot;},{&quot;title&quot;:&quot;FSMT&quot;,&quot;id&quot;:&quot;model_doc/fsmt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/fsmt&quot;},{&quot;title&quot;:&quot;Funnel Transformer&quot;,&quot;id&quot;:&quot;model_doc/funnel&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/funnel&quot;},{&quot;title&quot;:&quot;GPT&quot;,&quot;id&quot;:&quot;model_doc/openai-gpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/openai-gpt&quot;},{&quot;title&quot;:&quot;GPT Neo&quot;,&quot;id&quot;:&quot;model_doc/gpt_neo&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neo&quot;},{&quot;title&quot;:&quot;GPT NeoX&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox&quot;},{&quot;title&quot;:&quot;GPT NeoX Japanese&quot;,&quot;id&quot;:&quot;model_doc/gpt_neox_japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_neox_japanese&quot;},{&quot;title&quot;:&quot;GPT-J&quot;,&quot;id&quot;:&quot;model_doc/gptj&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptj&quot;},{&quot;title&quot;:&quot;GPT2&quot;,&quot;id&quot;:&quot;model_doc/gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt2&quot;},{&quot;title&quot;:&quot;GPTBigCode&quot;,&quot;id&quot;:&quot;model_doc/gpt_bigcode&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt_bigcode&quot;},{&quot;title&quot;:&quot;GPTSAN Japanese&quot;,&quot;id&quot;:&quot;model_doc/gptsan-japanese&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gptsan-japanese&quot;},{&quot;title&quot;:&quot;GPTSw3&quot;,&quot;id&quot;:&quot;model_doc/gpt-sw3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/gpt-sw3&quot;},{&quot;title&quot;:&quot;HerBERT&quot;,&quot;id&quot;:&quot;model_doc/herbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/herbert&quot;},{&quot;title&quot;:&quot;I-BERT&quot;,&quot;id&quot;:&quot;model_doc/ibert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ibert&quot;},{&quot;title&quot;:&quot;Jukebox&quot;,&quot;id&quot;:&quot;model_doc/jukebox&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/jukebox&quot;},{&quot;title&quot;:&quot;LED&quot;,&quot;id&quot;:&quot;model_doc/led&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/led&quot;},{&quot;title&quot;:&quot;LLaMA&quot;,&quot;id&quot;:&quot;model_doc/llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama&quot;},{&quot;title&quot;:&quot;Llama2&quot;,&quot;id&quot;:&quot;model_doc/llama2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/llama2&quot;},{&quot;title&quot;:&quot;Longformer&quot;,&quot;id&quot;:&quot;model_doc/longformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longformer&quot;},{&quot;title&quot;:&quot;LongT5&quot;,&quot;id&quot;:&quot;model_doc/longt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/longt5&quot;},{&quot;title&quot;:&quot;LUKE&quot;,&quot;id&quot;:&quot;model_doc/luke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/luke&quot;},{&quot;title&quot;:&quot;M2M100&quot;,&quot;id&quot;:&quot;model_doc/m2m_100&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/m2m_100&quot;},{&quot;title&quot;:&quot;MarianMT&quot;,&quot;id&quot;:&quot;model_doc/marian&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/marian&quot;},{&quot;title&quot;:&quot;MarkupLM&quot;,&quot;id&quot;:&quot;model_doc/markuplm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/markuplm&quot;},{&quot;title&quot;:&quot;MBart and MBart-50&quot;,&quot;id&quot;:&quot;model_doc/mbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mbart&quot;},{&quot;title&quot;:&quot;MEGA&quot;,&quot;id&quot;:&quot;model_doc/mega&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mega&quot;},{&quot;title&quot;:&quot;MegatronBERT&quot;,&quot;id&quot;:&quot;model_doc/megatron-bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron-bert&quot;},{&quot;title&quot;:&quot;MegatronGPT2&quot;,&quot;id&quot;:&quot;model_doc/megatron_gpt2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/megatron_gpt2&quot;},{&quot;title&quot;:&quot;Mistral&quot;,&quot;id&quot;:&quot;model_doc/mistral&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mistral&quot;},{&quot;title&quot;:&quot;mLUKE&quot;,&quot;id&quot;:&quot;model_doc/mluke&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mluke&quot;},{&quot;title&quot;:&quot;MobileBERT&quot;,&quot;id&quot;:&quot;model_doc/mobilebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilebert&quot;},{&quot;title&quot;:&quot;MPNet&quot;,&quot;id&quot;:&quot;model_doc/mpnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpnet&quot;},{&quot;title&quot;:&quot;MPT&quot;,&quot;id&quot;:&quot;model_doc/mpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mpt&quot;},{&quot;title&quot;:&quot;MRA&quot;,&quot;id&quot;:&quot;model_doc/mra&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mra&quot;},{&quot;title&quot;:&quot;MT5&quot;,&quot;id&quot;:&quot;model_doc/mt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mt5&quot;},{&quot;title&quot;:&quot;MVP&quot;,&quot;id&quot;:&quot;model_doc/mvp&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mvp&quot;},{&quot;title&quot;:&quot;NEZHA&quot;,&quot;id&quot;:&quot;model_doc/nezha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nezha&quot;},{&quot;title&quot;:&quot;NLLB&quot;,&quot;id&quot;:&quot;model_doc/nllb&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb&quot;},{&quot;title&quot;:&quot;NLLB-MoE&quot;,&quot;id&quot;:&quot;model_doc/nllb-moe&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nllb-moe&quot;},{&quot;title&quot;:&quot;Nyströmformer&quot;,&quot;id&quot;:&quot;model_doc/nystromformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nystromformer&quot;},{&quot;title&quot;:&quot;Open-Llama&quot;,&quot;id&quot;:&quot;model_doc/open-llama&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/open-llama&quot;},{&quot;title&quot;:&quot;OPT&quot;,&quot;id&quot;:&quot;model_doc/opt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/opt&quot;},{&quot;title&quot;:&quot;Pegasus&quot;,&quot;id&quot;:&quot;model_doc/pegasus&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus&quot;},{&quot;title&quot;:&quot;PEGASUS-X&quot;,&quot;id&quot;:&quot;model_doc/pegasus_x&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pegasus_x&quot;},{&quot;title&quot;:&quot;Persimmon&quot;,&quot;id&quot;:&quot;model_doc/persimmon&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/persimmon&quot;},{&quot;title&quot;:&quot;PhoBERT&quot;,&quot;id&quot;:&quot;model_doc/phobert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/phobert&quot;},{&quot;title&quot;:&quot;PLBart&quot;,&quot;id&quot;:&quot;model_doc/plbart&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/plbart&quot;},{&quot;title&quot;:&quot;ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/prophetnet&quot;},{&quot;title&quot;:&quot;QDQBert&quot;,&quot;id&quot;:&quot;model_doc/qdqbert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/qdqbert&quot;},{&quot;title&quot;:&quot;RAG&quot;,&quot;id&quot;:&quot;model_doc/rag&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rag&quot;},{&quot;title&quot;:&quot;REALM&quot;,&quot;id&quot;:&quot;model_doc/realm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/realm&quot;},{&quot;title&quot;:&quot;Reformer&quot;,&quot;id&quot;:&quot;model_doc/reformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/reformer&quot;},{&quot;title&quot;:&quot;RemBERT&quot;,&quot;id&quot;:&quot;model_doc/rembert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rembert&quot;},{&quot;title&quot;:&quot;RetriBERT&quot;,&quot;id&quot;:&quot;model_doc/retribert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/retribert&quot;},{&quot;title&quot;:&quot;RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta&quot;},{&quot;title&quot;:&quot;RoBERTa-PreLayerNorm&quot;,&quot;id&quot;:&quot;model_doc/roberta-prelayernorm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roberta-prelayernorm&quot;},{&quot;title&quot;:&quot;RoCBert&quot;,&quot;id&quot;:&quot;model_doc/roc_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roc_bert&quot;},{&quot;title&quot;:&quot;RoFormer&quot;,&quot;id&quot;:&quot;model_doc/roformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/roformer&quot;},{&quot;title&quot;:&quot;RWKV&quot;,&quot;id&quot;:&quot;model_doc/rwkv&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/rwkv&quot;},{&quot;title&quot;:&quot;Splinter&quot;,&quot;id&quot;:&quot;model_doc/splinter&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/splinter&quot;},{&quot;title&quot;:&quot;SqueezeBERT&quot;,&quot;id&quot;:&quot;model_doc/squeezebert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/squeezebert&quot;},{&quot;title&quot;:&quot;SwitchTransformers&quot;,&quot;id&quot;:&quot;model_doc/switch_transformers&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/switch_transformers&quot;},{&quot;title&quot;:&quot;T5&quot;,&quot;id&quot;:&quot;model_doc/t5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5&quot;},{&quot;title&quot;:&quot;T5v1.1&quot;,&quot;id&quot;:&quot;model_doc/t5v1.1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/t5v1.1&quot;},{&quot;title&quot;:&quot;TAPEX&quot;,&quot;id&quot;:&quot;model_doc/tapex&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapex&quot;},{&quot;title&quot;:&quot;Transformer XL&quot;,&quot;id&quot;:&quot;model_doc/transfo-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/transfo-xl&quot;},{&quot;title&quot;:&quot;UL2&quot;,&quot;id&quot;:&quot;model_doc/ul2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/ul2&quot;},{&quot;title&quot;:&quot;UMT5&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;model_doc/umt5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/umt5&quot;},{&quot;title&quot;:&quot;X-MOD&quot;,&quot;id&quot;:&quot;model_doc/xmod&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xmod&quot;},{&quot;title&quot;:&quot;XGLM&quot;,&quot;id&quot;:&quot;model_doc/xglm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xglm&quot;},{&quot;title&quot;:&quot;XLM&quot;,&quot;id&quot;:&quot;model_doc/xlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm&quot;},{&quot;title&quot;:&quot;XLM-ProphetNet&quot;,&quot;id&quot;:&quot;model_doc/xlm-prophetnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-prophetnet&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta&quot;},{&quot;title&quot;:&quot;XLM-RoBERTa-XL&quot;,&quot;id&quot;:&quot;model_doc/xlm-roberta-xl&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-roberta-xl&quot;},{&quot;title&quot;:&quot;XLM-V&quot;,&quot;id&quot;:&quot;model_doc/xlm-v&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlm-v&quot;},{&quot;title&quot;:&quot;XLNet&quot;,&quot;id&quot;:&quot;model_doc/xlnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlnet&quot;},{&quot;title&quot;:&quot;YOSO&quot;,&quot;id&quot;:&quot;model_doc/yoso&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yoso&quot;}]},{&quot;title&quot;:&quot;Vision models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;BEiT&quot;,&quot;id&quot;:&quot;model_doc/beit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/beit&quot;},{&quot;title&quot;:&quot;BiT&quot;,&quot;id&quot;:&quot;model_doc/bit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bit&quot;},{&quot;title&quot;:&quot;Conditional DETR&quot;,&quot;id&quot;:&quot;model_doc/conditional_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/conditional_detr&quot;},{&quot;title&quot;:&quot;ConvNeXT&quot;,&quot;id&quot;:&quot;model_doc/convnext&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnext&quot;},{&quot;title&quot;:&quot;ConvNeXTV2&quot;,&quot;id&quot;:&quot;model_doc/convnextv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/convnextv2&quot;},{&quot;title&quot;:&quot;CvT&quot;,&quot;id&quot;:&quot;model_doc/cvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/cvt&quot;},{&quot;title&quot;:&quot;Deformable DETR&quot;,&quot;id&quot;:&quot;model_doc/deformable_detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deformable_detr&quot;},{&quot;title&quot;:&quot;DeiT&quot;,&quot;id&quot;:&quot;model_doc/deit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deit&quot;},{&quot;title&quot;:&quot;DETA&quot;,&quot;id&quot;:&quot;model_doc/deta&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deta&quot;},{&quot;title&quot;:&quot;DETR&quot;,&quot;id&quot;:&quot;model_doc/detr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/detr&quot;},{&quot;title&quot;:&quot;DiNAT&quot;,&quot;id&quot;:&quot;model_doc/dinat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinat&quot;},{&quot;title&quot;:&quot;DINO V2&quot;,&quot;id&quot;:&quot;model_doc/dinov2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dinov2&quot;},{&quot;title&quot;:&quot;DiT&quot;,&quot;id&quot;:&quot;model_doc/dit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dit&quot;},{&quot;title&quot;:&quot;DPT&quot;,&quot;id&quot;:&quot;model_doc/dpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/dpt&quot;},{&quot;title&quot;:&quot;EfficientFormer&quot;,&quot;id&quot;:&quot;model_doc/efficientformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientformer&quot;},{&quot;title&quot;:&quot;EfficientNet&quot;,&quot;id&quot;:&quot;model_doc/efficientnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/efficientnet&quot;},{&quot;title&quot;:&quot;FocalNet&quot;,&quot;id&quot;:&quot;model_doc/focalnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/focalnet&quot;},{&quot;title&quot;:&quot;GLPN&quot;,&quot;id&quot;:&quot;model_doc/glpn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/glpn&quot;},{&quot;title&quot;:&quot;ImageGPT&quot;,&quot;id&quot;:&quot;model_doc/imagegpt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/imagegpt&quot;},{&quot;title&quot;:&quot;LeViT&quot;,&quot;id&quot;:&quot;model_doc/levit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/levit&quot;},{&quot;title&quot;:&quot;Mask2Former&quot;,&quot;id&quot;:&quot;model_doc/mask2former&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mask2former&quot;},{&quot;title&quot;:&quot;MaskFormer&quot;,&quot;id&quot;:&quot;model_doc/maskformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/maskformer&quot;},{&quot;title&quot;:&quot;MobileNetV1&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v1&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v1&quot;},{&quot;title&quot;:&quot;MobileNetV2&quot;,&quot;id&quot;:&quot;model_doc/mobilenet_v2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilenet_v2&quot;},{&quot;title&quot;:&quot;MobileViT&quot;,&quot;id&quot;:&quot;model_doc/mobilevit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevit&quot;},{&quot;title&quot;:&quot;MobileViTV2&quot;,&quot;id&quot;:&quot;model_doc/mobilevitv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mobilevitv2&quot;},{&quot;title&quot;:&quot;NAT&quot;,&quot;id&quot;:&quot;model_doc/nat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nat&quot;},{&quot;title&quot;:&quot;PoolFormer&quot;,&quot;id&quot;:&quot;model_doc/poolformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/poolformer&quot;},{&quot;title&quot;:&quot;Pyramid Vision Transformer (PVT)&quot;,&quot;id&quot;:&quot;model_doc/pvt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pvt&quot;},{&quot;title&quot;:&quot;RegNet&quot;,&quot;id&quot;:&quot;model_doc/regnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/regnet&quot;},{&quot;title&quot;:&quot;ResNet&quot;,&quot;id&quot;:&quot;model_doc/resnet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/resnet&quot;},{&quot;title&quot;:&quot;SegFormer&quot;,&quot;id&quot;:&quot;model_doc/segformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/segformer&quot;},{&quot;title&quot;:&quot;SwiftFormer&quot;,&quot;id&quot;:&quot;model_doc/swiftformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swiftformer&quot;},{&quot;title&quot;:&quot;Swin Transformer&quot;,&quot;id&quot;:&quot;model_doc/swin&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin&quot;},{&quot;title&quot;:&quot;Swin Transformer V2&quot;,&quot;id&quot;:&quot;model_doc/swinv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swinv2&quot;},{&quot;title&quot;:&quot;Swin2SR&quot;,&quot;id&quot;:&quot;model_doc/swin2sr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/swin2sr&quot;},{&quot;title&quot;:&quot;Table Transformer&quot;,&quot;id&quot;:&quot;model_doc/table-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/table-transformer&quot;},{&quot;title&quot;:&quot;TimeSformer&quot;,&quot;id&quot;:&quot;model_doc/timesformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/timesformer&quot;},{&quot;title&quot;:&quot;UperNet&quot;,&quot;id&quot;:&quot;model_doc/upernet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/upernet&quot;},{&quot;title&quot;:&quot;VAN&quot;,&quot;id&quot;:&quot;model_doc/van&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/van&quot;},{&quot;title&quot;:&quot;VideoMAE&quot;,&quot;id&quot;:&quot;model_doc/videomae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/videomae&quot;},{&quot;title&quot;:&quot;Vision Transformer (ViT)&quot;,&quot;id&quot;:&quot;model_doc/vit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit&quot;},{&quot;title&quot;:&quot;ViT Hybrid&quot;,&quot;id&quot;:&quot;model_doc/vit_hybrid&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_hybrid&quot;},{&quot;title&quot;:&quot;ViTDet&quot;,&quot;id&quot;:&quot;model_doc/vitdet&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitdet&quot;},{&quot;title&quot;:&quot;ViTMAE&quot;,&quot;id&quot;:&quot;model_doc/vit_mae&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_mae&quot;},{&quot;title&quot;:&quot;ViTMatte&quot;,&quot;id&quot;:&quot;model_doc/vitmatte&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vitmatte&quot;},{&quot;title&quot;:&quot;ViTMSN&quot;,&quot;id&quot;:&quot;model_doc/vit_msn&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vit_msn&quot;},{&quot;title&quot;:&quot;ViViT&quot;,&quot;id&quot;:&quot;model_doc/vivit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vivit&quot;},{&quot;title&quot;:&quot;YOLOS&quot;,&quot;id&quot;:&quot;model_doc/yolos&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/yolos&quot;}]},{&quot;title&quot;:&quot;Audio models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Audio Spectrogram Transformer&quot;,&quot;id&quot;:&quot;model_doc/audio-spectrogram-transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/audio-spectrogram-transformer&quot;},{&quot;title&quot;:&quot;Bark&quot;,&quot;id&quot;:&quot;model_doc/bark&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bark&quot;},{&quot;title&quot;:&quot;CLAP&quot;,&quot;id&quot;:&quot;model_doc/clap&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clap&quot;},{&quot;title&quot;:&quot;EnCodec&quot;,&quot;id&quot;:&quot;model_doc/encodec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/encodec&quot;},{&quot;title&quot;:&quot;Hubert&quot;,&quot;id&quot;:&quot;model_doc/hubert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/hubert&quot;},{&quot;title&quot;:&quot;MCTCT&quot;,&quot;id&quot;:&quot;model_doc/mctct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mctct&quot;},{&quot;title&quot;:&quot;MMS&quot;,&quot;id&quot;:&quot;model_doc/mms&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mms&quot;},{&quot;title&quot;:&quot;MusicGen&quot;,&quot;id&quot;:&quot;model_doc/musicgen&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/musicgen&quot;},{&quot;title&quot;:&quot;Pop2Piano&quot;,&quot;id&quot;:&quot;model_doc/pop2piano&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pop2piano&quot;},{&quot;title&quot;:&quot;SEW&quot;,&quot;id&quot;:&quot;model_doc/sew&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew&quot;},{&quot;title&quot;:&quot;SEW-D&quot;,&quot;id&quot;:&quot;model_doc/sew-d&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sew-d&quot;},{&quot;title&quot;:&quot;Speech2Text&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text&quot;},{&quot;title&quot;:&quot;Speech2Text2&quot;,&quot;id&quot;:&quot;model_doc/speech_to_text_2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech_to_text_2&quot;},{&quot;title&quot;:&quot;SpeechT5&quot;,&quot;id&quot;:&quot;model_doc/speecht5&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speecht5&quot;},{&quot;title&quot;:&quot;UniSpeech&quot;,&quot;id&quot;:&quot;model_doc/unispeech&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech&quot;},{&quot;title&quot;:&quot;UniSpeech-SAT&quot;,&quot;id&quot;:&quot;model_doc/unispeech-sat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/unispeech-sat&quot;},{&quot;title&quot;:&quot;VITS&quot;,&quot;id&quot;:&quot;model_doc/vits&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vits&quot;},{&quot;title&quot;:&quot;Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2&quot;},{&quot;title&quot;:&quot;Wav2Vec2-Conformer&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2-conformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2-conformer&quot;},{&quot;title&quot;:&quot;Wav2Vec2Phoneme&quot;,&quot;id&quot;:&quot;model_doc/wav2vec2_phoneme&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wav2vec2_phoneme&quot;},{&quot;title&quot;:&quot;WavLM&quot;,&quot;id&quot;:&quot;model_doc/wavlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/wavlm&quot;},{&quot;title&quot;:&quot;Whisper&quot;,&quot;id&quot;:&quot;model_doc/whisper&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/whisper&quot;},{&quot;title&quot;:&quot;XLS-R&quot;,&quot;id&quot;:&quot;model_doc/xls_r&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xls_r&quot;},{&quot;title&quot;:&quot;XLSR-Wav2Vec2&quot;,&quot;id&quot;:&quot;model_doc/xlsr_wav2vec2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xlsr_wav2vec2&quot;}]},{&quot;title&quot;:&quot;Multimodal models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;ALIGN&quot;,&quot;id&quot;:&quot;model_doc/align&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/align&quot;},{&quot;title&quot;:&quot;AltCLIP&quot;,&quot;id&quot;:&quot;model_doc/altclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/altclip&quot;},{&quot;title&quot;:&quot;BLIP&quot;,&quot;id&quot;:&quot;model_doc/blip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip&quot;},{&quot;title&quot;:&quot;BLIP-2&quot;,&quot;id&quot;:&quot;model_doc/blip-2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/blip-2&quot;},{&quot;title&quot;:&quot;BridgeTower&quot;,&quot;id&quot;:&quot;model_doc/bridgetower&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bridgetower&quot;},{&quot;title&quot;:&quot;BROS&quot;,&quot;id&quot;:&quot;model_doc/bros&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/bros&quot;},{&quot;title&quot;:&quot;Chinese-CLIP&quot;,&quot;id&quot;:&quot;model_doc/chinese_clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/chinese_clip&quot;},{&quot;title&quot;:&quot;CLIP&quot;,&quot;id&quot;:&quot;model_doc/clip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clip&quot;},{&quot;title&quot;:&quot;CLIPSeg&quot;,&quot;id&quot;:&quot;model_doc/clipseg&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/clipseg&quot;},{&quot;title&quot;:&quot;Data2Vec&quot;,&quot;id&quot;:&quot;model_doc/data2vec&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/data2vec&quot;},{&quot;title&quot;:&quot;DePlot&quot;,&quot;id&quot;:&quot;model_doc/deplot&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/deplot&quot;},{&quot;title&quot;:&quot;Donut&quot;,&quot;id&quot;:&quot;model_doc/donut&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/donut&quot;},{&quot;title&quot;:&quot;FLAVA&quot;,&quot;id&quot;:&quot;model_doc/flava&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/flava&quot;},{&quot;title&quot;:&quot;GIT&quot;,&quot;id&quot;:&quot;model_doc/git&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/git&quot;},{&quot;title&quot;:&quot;GroupViT&quot;,&quot;id&quot;:&quot;model_doc/groupvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/groupvit&quot;},{&quot;title&quot;:&quot;IDEFICS&quot;,&quot;id&quot;:&quot;model_doc/idefics&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/idefics&quot;},{&quot;title&quot;:&quot;InstructBLIP&quot;,&quot;id&quot;:&quot;model_doc/instructblip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/instructblip&quot;},{&quot;title&quot;:&quot;LayoutLM&quot;,&quot;id&quot;:&quot;model_doc/layoutlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlm&quot;},{&quot;title&quot;:&quot;LayoutLMV2&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv2&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv2&quot;},{&quot;title&quot;:&quot;LayoutLMV3&quot;,&quot;id&quot;:&quot;model_doc/layoutlmv3&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutlmv3&quot;},{&quot;title&quot;:&quot;LayoutXLM&quot;,&quot;id&quot;:&quot;model_doc/layoutxlm&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/layoutxlm&quot;},{&quot;title&quot;:&quot;LiLT&quot;,&quot;id&quot;:&quot;model_doc/lilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lilt&quot;},{&quot;title&quot;:&quot;LXMERT&quot;,&quot;id&quot;:&quot;model_doc/lxmert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/lxmert&quot;},{&quot;title&quot;:&quot;MatCha&quot;,&quot;id&quot;:&quot;model_doc/matcha&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/matcha&quot;},{&quot;title&quot;:&quot;MGP-STR&quot;,&quot;id&quot;:&quot;model_doc/mgp-str&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/mgp-str&quot;},{&quot;title&quot;:&quot;Nougat&quot;,&quot;id&quot;:&quot;model_doc/nougat&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/nougat&quot;},{&quot;title&quot;:&quot;OneFormer&quot;,&quot;id&quot;:&quot;model_doc/oneformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/oneformer&quot;},{&quot;title&quot;:&quot;OWL-ViT&quot;,&quot;id&quot;:&quot;model_doc/owlvit&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/owlvit&quot;},{&quot;title&quot;:&quot;Perceiver&quot;,&quot;id&quot;:&quot;model_doc/perceiver&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/perceiver&quot;},{&quot;title&quot;:&quot;Pix2Struct&quot;,&quot;id&quot;:&quot;model_doc/pix2struct&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/pix2struct&quot;},{&quot;title&quot;:&quot;Segment Anything&quot;,&quot;id&quot;:&quot;model_doc/sam&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/sam&quot;},{&quot;title&quot;:&quot;Speech Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/speech-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/speech-encoder-decoder&quot;},{&quot;title&quot;:&quot;TAPAS&quot;,&quot;id&quot;:&quot;model_doc/tapas&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tapas&quot;},{&quot;title&quot;:&quot;TrOCR&quot;,&quot;id&quot;:&quot;model_doc/trocr&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trocr&quot;},{&quot;title&quot;:&quot;TVLT&quot;,&quot;id&quot;:&quot;model_doc/tvlt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/tvlt&quot;},{&quot;title&quot;:&quot;ViLT&quot;,&quot;id&quot;:&quot;model_doc/vilt&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vilt&quot;},{&quot;title&quot;:&quot;Vision Encoder Decoder Models&quot;,&quot;id&quot;:&quot;model_doc/vision-encoder-decoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-encoder-decoder&quot;},{&quot;title&quot;:&quot;Vision Text Dual Encoder&quot;,&quot;id&quot;:&quot;model_doc/vision-text-dual-encoder&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/vision-text-dual-encoder&quot;},{&quot;title&quot;:&quot;VisualBERT&quot;,&quot;id&quot;:&quot;model_doc/visual_bert&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/visual_bert&quot;},{&quot;title&quot;:&quot;X-CLIP&quot;,&quot;id&quot;:&quot;model_doc/xclip&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/xclip&quot;}]},{&quot;title&quot;:&quot;Reinforcement learning models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Decision Transformer&quot;,&quot;id&quot;:&quot;model_doc/decision_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/decision_transformer&quot;},{&quot;title&quot;:&quot;Trajectory Transformer&quot;,&quot;id&quot;:&quot;model_doc/trajectory_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/trajectory_transformer&quot;}]},{&quot;title&quot;:&quot;Time series models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Autoformer&quot;,&quot;id&quot;:&quot;model_doc/autoformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/autoformer&quot;},{&quot;title&quot;:&quot;Informer&quot;,&quot;id&quot;:&quot;model_doc/informer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/informer&quot;},{&quot;title&quot;:&quot;Time Series Transformer&quot;,&quot;id&quot;:&quot;model_doc/time_series_transformer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/time_series_transformer&quot;}]},{&quot;title&quot;:&quot;Graph models&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Graphormer&quot;,&quot;id&quot;:&quot;model_doc/graphormer&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/model_doc/graphormer&quot;}]}]},{&quot;title&quot;:&quot;Internal Helpers&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Custom Layers and Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/modeling_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/modeling_utils&quot;},{&quot;title&quot;:&quot;Utilities for pipelines&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/pipelines_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/pipelines_utils&quot;},{&quot;title&quot;:&quot;Utilities for Tokenizers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/tokenization_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/tokenization_utils&quot;},{&quot;title&quot;:&quot;Utilities for Trainer&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/trainer_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/trainer_utils&quot;},{&quot;title&quot;:&quot;Utilities for Generation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/generation_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/generation_utils&quot;},{&quot;title&quot;:&quot;Utilities for Image Processors&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/image_processing_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/image_processing_utils&quot;},{&quot;title&quot;:&quot;Utilities for Audio processing&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/audio_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/audio_utils&quot;},{&quot;title&quot;:&quot;General Utilities&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/file_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/file_utils&quot;},{&quot;title&quot;:&quot;Utilities for Time Series&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;internal/time_series_utils&quot;,&quot;url&quot;:&quot;/docs/transformers/v4.34.0/en/internal/time_series_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;model_doc/umt5&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;de&quot;,&quot;en&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;ko&quot;,&quot;pt&quot;,&quot;zh&quot;],&quot;library&quot;:&quot;transformers&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v4.34.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v4.34.0&quot;},{&quot;version&quot;:&quot;v4.33.3&quot;},{&quot;version&quot;:&quot;v4.33.2&quot;},{&quot;version&quot;:&quot;v4.33.0&quot;},{&quot;version&quot;:&quot;v4.32.1&quot;},{&quot;version&quot;:&quot;v4.32.0&quot;},{&quot;version&quot;:&quot;v4.31.0&quot;},{&quot;version&quot;:&quot;v4.30.0&quot;},{&quot;version&quot;:&quot;v4.29.1&quot;},{&quot;version&quot;:&quot;v4.29.0&quot;},{&quot;version&quot;:&quot;v4.28.1&quot;},{&quot;version&quot;:&quot;v4.28.0&quot;},{&quot;version&quot;:&quot;v4.27.2&quot;},{&quot;version&quot;:&quot;v4.27.1&quot;},{&quot;version&quot;:&quot;v4.27.0&quot;},{&quot;version&quot;:&quot;v4.26.1&quot;},{&quot;version&quot;:&quot;v4.26.0&quot;},{&quot;version&quot;:&quot;v4.25.1&quot;},{&quot;version&quot;:&quot;v4.24.0&quot;},{&quot;version&quot;:&quot;v4.23.1&quot;},{&quot;version&quot;:&quot;v4.23.0&quot;},{&quot;version&quot;:&quot;v4.22.2&quot;},{&quot;version&quot;:&quot;v4.22.1&quot;},{&quot;version&quot;:&quot;v4.22.0&quot;},{&quot;version&quot;:&quot;v4.21.3&quot;},{&quot;version&quot;:&quot;v4.21.2&quot;},{&quot;version&quot;:&quot;v4.21.1&quot;},{&quot;version&quot;:&quot;v4.21.0&quot;},{&quot;version&quot;:&quot;v4.20.1&quot;},{&quot;version&quot;:&quot;v4.20.0&quot;},{&quot;version&quot;:&quot;v4.19.4&quot;},{&quot;version&quot;:&quot;v4.19.3&quot;},{&quot;version&quot;:&quot;v4.19.2&quot;},{&quot;version&quot;:&quot;v4.19.0&quot;},{&quot;version&quot;:&quot;v4.18.0&quot;},{&quot;version&quot;:&quot;v4.17.0&quot;},{&quot;version&quot;:&quot;v4.16.2&quot;},{&quot;version&quot;:&quot;v4.16.1&quot;},{&quot;version&quot;:&quot;v4.16.0&quot;},{&quot;version&quot;:&quot;v4.15.0&quot;},{&quot;version&quot;:&quot;v4.14.1&quot;},{&quot;version&quot;:&quot;v4.13.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.5&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.4&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.12.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.3&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v4.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v3.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.11.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.10.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.9.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.8.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.7.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.6.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.5.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.4.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.3.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.2&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.1.1&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v2.0.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.2.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.1.0&quot;},{&quot;sphinx&quot;:true,&quot;version&quot;:&quot;v1.0.0&quot;},{&quot;version&quot;:&quot;doc-builder-html&quot;}],&quot;title&quot;:&quot;Sample usage&quot;}\" data-target=\"SideMenu\"> <div class=\"z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false\"><div class=\"shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden\"><div class=\"flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6\"><p class=\"text-sm text-gray-400 first-letter:capitalize\">Transformers documentation</p> <div class=\"flex items-center\"><p class=\"font-semibold\">Sample usage</p> <svg class=\"text-xl false\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></div></div> <button class=\"hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2\"><svg class=\"text-gray-500 group-hover:text-gray-700\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg></button></div> <div class=\"hidden h-32 flex-col justify-between border-r border-b bg-white bg-gradient-to-r p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950\"><div class=\"relative \"><button class=\" \" type=\"button\"><h1 class=\"flex items-center text-lg font-bold leading-tight first-letter:capitalize\"><div class=\"mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none\"></div> Transformers <span><svg class=\"opacity-70 \" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></span></h1> </button> </div> <button class=\"shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500\"><svg class=\"flex-none mr-1.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg> <div>Search documentation</div> <span class=\"ml-auto rounded border border-gray-200 bg-gray-100 px-0.5 text-xs dark:border-gray-800 dark:bg-gray-800\"><kbd class=\"font-sans\">⌘K</kbd></span></button> <div class=\"flex items-center\"><select class=\"form-input mr-1 !mt-0 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400\"><option value=\"0\">main</option><option value=\"1\">v4.34.0</option><option value=\"2\">v4.33.3</option><option value=\"3\">v4.32.1</option><option value=\"4\">v4.31.0</option><option value=\"5\">v4.30.0</option><option value=\"6\">v4.29.1</option><option value=\"7\">v4.28.1</option><option value=\"8\">v4.27.2</option><option value=\"9\">v4.26.1</option><option value=\"10\">v4.25.1</option><option value=\"11\">v4.24.0</option><option value=\"12\">v4.23.1</option><option value=\"13\">v4.22.2</option><option value=\"14\">v4.21.3</option><option value=\"15\">v4.20.1</option><option value=\"16\">v4.19.4</option><option value=\"17\">v4.18.0</option><option value=\"18\">v4.17.0</option><option value=\"19\">v4.16.2</option><option value=\"20\">v4.15.0</option><option value=\"21\">v4.14.1</option><option value=\"22\">v4.13.0</option><option value=\"23\">v4.12.5</option><option value=\"24\">v4.11.3</option><option value=\"25\">v4.10.1</option><option value=\"26\">v4.9.2</option><option value=\"27\">v4.8.2</option><option value=\"28\">v4.7.0</option><option value=\"29\">v4.6.0</option><option value=\"30\">v4.5.1</option><option value=\"31\">v4.4.2</option><option value=\"32\">v4.3.3</option><option value=\"33\">v4.2.2</option><option value=\"34\">v4.1.1</option><option value=\"35\">v4.0.1</option><option value=\"36\">v3.5.1</option><option value=\"37\">v3.4.0</option><option value=\"38\">v3.3.1</option><option value=\"39\">v3.2.0</option><option value=\"40\">v3.1.0</option><option value=\"41\">v3.0.2</option><option value=\"42\">v2.11.0</option><option value=\"43\">v2.10.0</option><option value=\"44\">v2.9.1</option><option value=\"45\">v2.8.0</option><option value=\"46\">v2.7.0</option><option value=\"47\">v2.6.0</option><option value=\"48\">v2.5.1</option><option value=\"49\">v2.4.1</option><option value=\"50\">v2.3.0</option><option value=\"51\">v2.2.2</option><option value=\"52\">v2.1.1</option><option value=\"53\">v2.0.0</option><option value=\"54\">v1.2.0</option><option value=\"55\">v1.1.0</option><option value=\"56\">v1.0.0</option><option value=\"57\">doc-builder-html</option></select> <select class=\"form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border\"><option value=\"de\">DE</option><option value=\"en\">EN</option><option value=\"es\">ES</option><option value=\"fr\">FR</option><option value=\"it\">IT</option><option value=\"ko\">KO</option><option value=\"pt\">PT</option><option value=\"zh\">ZH</option></select> <div class=\"relative inline-block\"><button class=\"rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 \" type=\"button\"><svg class=\"mr-1.5 text-yellow-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\" fill=\"currentColor\"><path d=\"M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z\"></path></svg>  </button> </div> <a href=\"https://github.com/huggingface/transformers\" class=\"group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300\"><svg class=\"inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1.03em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 250\"><path d=\"M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z\" fill=\"currentColor\"></path></svg> 112,792</a></div></div> <nav class=\"top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pt-3 pb-16 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]\"> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Get started</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/index\">🤗 Transformers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/quicktour\">Quick tour </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/installation\">Installation </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Tutorials</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_tutorial\">Run inference with pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/autoclass_tutorial\">Write portable code with AutoClass </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/preprocessing\">Preprocess data </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/training\">Fine-tune a pretrained model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/run_scripts\">Train with a script </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/accelerate\">Set up distributed training with 🤗 Accelerate </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/peft\">Load and train adapters with 🤗 PEFT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_sharing\">Share your model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/transformers_agents\">Agents </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/llm_tutorial\">Generation with LLMs </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Task Guides</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Natural Language Processing</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Computer Vision</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Generation</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Prompting</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Developer guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/fast_tokenizers\">Use fast tokenizers from 🤗 Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/multilingual\">Run inference with multilingual models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/create_a_model\">Use model-specific APIs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_models\">Share a custom model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/chat_templating\">Templates for chat models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/sagemaker\">Run training on Amazon SageMaker </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/serialization\">Export to ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tflite\">Export to TFLite </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/torchscript\">Export to TorchScript </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/benchmarks\">Benchmarks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/notebooks\">Notebooks with examples </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/community\">Community resources </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/custom_tools\">Custom Tools and Prompts </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/troubleshooting\">Troubleshoot </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Performance and scalability</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/performance\">Overview </a><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Efficient training techniques</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_one\">Methods and tools for efficient training on a single GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_gpu_many\">Multiple GPUs and parallelism </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu\">Efficient training on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_cpu_many\">Distributed CPU training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu\">Training on TPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_tpu_tf\">Training on TPU with TensorFlow </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_train_special\">Training on Specialized Hardware </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_hardware\">Custom hardware for training </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/hpo_train\">Hyperparameter Search using Trainer API </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Optimizing inference</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_cpu\">Inference on CPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_one\">Inference on one GPU </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_gpu_many\">Inference on many GPUs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/perf_infer_special\">Inference on Specialized Hardware </a> </div><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/big_models\">Instantiating a big model </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/debugging\">Troubleshooting </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tf_xla\">XLA Integration for TensorFlow Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perf_torch_compile\">Optimize inference using `torch.compile()` </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Contribute</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/contributing\">How to contribute to transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_model\">How to add a model to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_tensorflow_model\">How to convert a 🤗 Transformers model to TensorFlow? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/add_new_pipeline\">How to add a pipeline to 🤗 Transformers? </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/testing\">Testing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pr_checks\">Checks on a Pull Request </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Conceptual guides</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/philosophy\">Philosophy </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/glossary\">Glossary </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/task_summary\">What 🤗 Transformers can do </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tasks_explained\">How 🤗 Transformers solve tasks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_summary\">The Transformer model family </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/tokenizer_summary\">Summary of the tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/attention\">Attention mechanisms </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pad_truncation\">Padding and truncation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/bertology\">BERTology </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/perplexity\">Perplexity of fixed-length models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/pipeline_webserver\">Pipelines for webserver inference </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2\" href=\"/docs/transformers/v4.34.0/en/model_memory_anatomy\">Model training anatomy </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>API</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Main Classes</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/agent\">Agents and Tools </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/model_doc/auto\">Auto Classes </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/callback\">Callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/configuration\">Configuration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/data_collator\">Data Collator </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/keras_callbacks\">Keras callbacks </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/logging\">Logging </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/model\">Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/text_generation\">Text Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/onnx\">ONNX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/optimizer_schedules\">Optimization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/output\">Model outputs </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/pipelines\">Pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/processors\">Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/quantization\">Quantization </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer\">Tokenizer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/trainer\">Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/deepspeed\">DeepSpeed Integration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/feature_extractor\">Feature Extractor </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/main_classes/image_processor\">Image Processor </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Models</span> </span></span></div></div> <div class=\"flex flex-col\"><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Text models</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/albert\">ALBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bart\">BART </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/barthez\">BARThez </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bartpho\">BARTpho </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bert\">BERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bert-generation\">BertGeneration </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bert-japanese\">BertJapanese </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bertweet\">Bertweet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/big_bird\">BigBird </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bigbird_pegasus\">BigBirdPegasus </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/biogpt\">BioGpt </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/blenderbot\">Blenderbot </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/blenderbot-small\">Blenderbot Small </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bloom\">BLOOM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/bort\">BORT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/byt5\">ByT5 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/camembert\">CamemBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/canine\">CANINE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/codegen\">CodeGen </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/code_llama\">CodeLlama </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/convbert\">ConvBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/cpm\">CPM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/cpmant\">CPMANT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/ctrl\">CTRL </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/deberta\">DeBERTa </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/deberta-v2\">DeBERTa-v2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/dialogpt\">DialoGPT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/distilbert\">DistilBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/dpr\">DPR </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/electra\">ELECTRA </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/encoder-decoder\">Encoder Decoder Models </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/ernie\">ERNIE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/ernie_m\">ErnieM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/esm\">ESM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/falcon\">Falcon </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/flan-t5\">FLAN-T5 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/flan-ul2\">FLAN-UL2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/flaubert\">FlauBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/fnet\">FNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/fsmt\">FSMT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/funnel\">Funnel Transformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/openai-gpt\">GPT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gpt_neo\">GPT Neo </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gpt_neox\">GPT NeoX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gpt_neox_japanese\">GPT NeoX Japanese </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gptj\">GPT-J </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gpt2\">GPT2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gpt_bigcode\">GPTBigCode </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gptsan-japanese\">GPTSAN Japanese </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/gpt-sw3\">GPTSw3 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/herbert\">HerBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/ibert\">I-BERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/jukebox\">Jukebox </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/led\">LED </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/llama\">LLaMA </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/llama2\">Llama2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/longformer\">Longformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/longt5\">LongT5 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/luke\">LUKE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/m2m_100\">M2M100 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/marian\">MarianMT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/markuplm\">MarkupLM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mbart\">MBart and MBart-50 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mega\">MEGA </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/megatron-bert\">MegatronBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/megatron_gpt2\">MegatronGPT2 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mistral\">Mistral </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mluke\">mLUKE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mobilebert\">MobileBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mpnet\">MPNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mpt\">MPT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mra\">MRA </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mt5\">MT5 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/mvp\">MVP </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/nezha\">NEZHA </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/nllb\">NLLB </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/nllb-moe\">NLLB-MoE </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/nystromformer\">Nyströmformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/open-llama\">Open-Llama </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/opt\">OPT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/pegasus\">Pegasus </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/pegasus_x\">PEGASUS-X </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/persimmon\">Persimmon </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/phobert\">PhoBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/plbart\">PLBart </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/prophetnet\">ProphetNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/qdqbert\">QDQBert </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/rag\">RAG </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/realm\">REALM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/reformer\">Reformer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/rembert\">RemBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/retribert\">RetriBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/roberta\">RoBERTa </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/roberta-prelayernorm\">RoBERTa-PreLayerNorm </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/roc_bert\">RoCBert </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/roformer\">RoFormer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/rwkv\">RWKV </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/splinter\">Splinter </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/squeezebert\">SqueezeBERT </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/switch_transformers\">SwitchTransformers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/t5\">T5 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/t5v1.1\">T5v1.1 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/tapex\">TAPEX </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/transfo-xl\">Transformer XL </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/ul2\">UL2 </a><a data-sveltekit-reload=\"\" class=\"rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pr-2 pl-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/umt5\">UMT5 </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xmod\">X-MOD </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xglm\">XGLM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xlm\">XLM </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xlm-prophetnet\">XLM-ProphetNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xlm-roberta\">XLM-RoBERTa </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xlm-roberta-xl\">XLM-RoBERTa-XL </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xlm-v\">XLM-V </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/xlnet\">XLNet </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-6\" href=\"/docs/transformers/v4.34.0/en/model_doc/yoso\">YOSO </a> </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Vision models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Audio models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Multimodal models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Reinforcement learning models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Time series models</span> </span></span></div></div> <div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-4\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] false\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Graph models</span> </span></span></div></div>  </div><div class=\"group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2\"><div class=\"flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-[\\'▶\\'] after:rotate-90 after:transform\"><span><span class=\"inline-block space-x-1 leading-5\"><span>Internal Helpers</span> </span></span></div></div> <div class=\"flex flex-col\"><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/modeling_utils\">Custom Layers and Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/pipelines_utils\">Utilities for pipelines </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/tokenization_utils\">Utilities for Tokenizers </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/trainer_utils\">Utilities for Trainer </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/generation_utils\">Utilities for Generation </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/image_processing_utils\">Utilities for Image Processors </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/audio_utils\">Utilities for Audio processing </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/file_utils\">General Utilities </a><a data-sveltekit-reload=\"\" class=\"transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4\" href=\"/docs/transformers/v4.34.0/en/internal/time_series_utils\">Utilities for Time Series </a> </div> </div></nav></div></div></div>\\n\\t\\t<div class=\"z-1 min-w-0 flex-1\">\\n\\t\\t\\t<div class=\"px-6 pt-6 md:px-12 md:pt-16 md:pb-16\"><div class=\"max-w-4xl mx-auto mb-10\"><div class=\"relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 py-5 px-4 ring-1 ring-orange-100/70 md:px-6 md:py-8\"><img alt=\"Hugging Face\\'s logo\" class=\"absolute -right-6 -bottom-6 w-28 -rotate-45 md:hidden\" src=\"/front/assets/huggingface_logo-noborder.svg\">\\n\\t\\t<div class=\"mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0\">Join the Hugging Face community</div>\\n\\t\\t<p class=\"mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8\">and get access to the augmented documentation experience\\n\\t\\t</p>\\n\\t\\t<div class=\"mb-8 hidden space-y-4 md:block xl:flex xl:space-y-0 xl:space-x-6\"><div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100\"><svg class=\"text-indigo-400 group-hover:text-indigo-500\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Collaborate on models, datasets and Spaces\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" class=\"text-xl text-yellow-400\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path d=\"M11 15H6l7-14v8h5l-7 14v-8z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Faster examples with accelerated inference\\n\\t\\t\\t\\t</div></div>\\n\\t\\t\\t<div class=\"flex items-center\"><div class=\"mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5\"><svg class=\"text-gray-400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z\" fill=\"currentColor\"></path></svg></div>\\n\\t\\t\\t\\t<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Switch between documentation themes\\n\\t\\t\\t\\t</div></div></div>\\n\\t\\t<div class=\"flex items-center space-x-2.5\"><a href=\"/join\"><button class=\"rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 py-1.5 px-5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner\">Sign Up</button></a>\\n\\t\\t\\t<p class=\"text-gray-500 dark:text-gray-300\">to get started</p></div></div></div>\\n\\t\\t\\t\\t<div class=\"prose-doc prose relative mx-auto max-w-4xl break-words\"> <p></p> <h1 class=\"relative group\"><a id=\"umt5\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#umt5\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-7jy6x2\">UMT5</span></h1> <div class=\"flex flex-wrap space-x-1\" data-svelte-h=\"svelte-aa8zp4\"><a href=\"https://huggingface.co/models?filter=umt5\"><img alt=\"Models\" src=\"https://img.shields.io/badge/All_model_pages-mt5-blueviolet\"></a> <a href=\"https://huggingface.co/spaces/docs-demos/mt5-small-finetuned-arxiv-cs-finetuned-arxiv-cs-full\"><img alt=\"Spaces\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue\"></a></div> <h2 class=\"relative group\"><a id=\"overview\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#overview\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1jsw1pg\">Overview</span></h2> <p data-svelte-h=\"svelte-1r3qk5i\">The UMT5 model was proposed in <a href=\"https://openreview.net/forum?id=kXwdL1cWOAi\" rel=\"nofollow\">UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining</a> by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.</p> <p data-svelte-h=\"svelte-vfdo9a\">The abstract from the paper is the following:</p> <p data-svelte-h=\"svelte-10kmzrd\"><em>Pretrained multilingual large language models have typically used heuristic temperature-based sampling to balance between different languages. However previous work has not systematically evaluated the efficacy of different pretraining language distributions across model scales. In this paper, we propose a new sampling method, UniMax, that delivers more uniform coverage of head languages while mitigating overfitting on tail languages by explicitly capping the number of repeats over each language’s corpus. We perform an extensive series of ablations testing a range of sampling strategies on a suite of multilingual benchmarks, while varying model scale. We find that UniMax outperforms standard temperature-based sampling, and the benefits persist as scale increases. As part of our contribution, we release: (i) an improved and refreshed mC4 multilingual corpus consisting of 29 trillion characters across 107 languages, and (ii) a suite of pretrained umT5 model checkpoints trained with UniMax sampling.</em></p> <p data-svelte-h=\"svelte-1vzt0i4\">Tips:</p> <ul data-svelte-h=\"svelte-r5zwla\"><li>UMT5 was only pre-trained on <a href=\"https://huggingface.co/datasets/mc4\" rel=\"nofollow\">mC4</a> excluding any supervised training.\\nTherefore, this model has to be fine-tuned before it is usable on a downstream task, unlike the original T5 model.</li> <li>Since umT5 was pre-trained in an unsupervise manner, there’s no real advantage to using a task prefix during single-task\\nfine-tuning. If you are doing multi-task fine-tuning, you should use a prefix.</li></ul> <p data-svelte-h=\"svelte-1p0jqca\">Google has released the following variants:</p> <ul data-svelte-h=\"svelte-coj30a\"><li><a href=\"https://huggingface.co/google/umt5-small\" rel=\"nofollow\">google/umt5-small</a></li> <li><a href=\"https://huggingface.co/google/umt5-base\" rel=\"nofollow\">google/umt5-base</a></li> <li><a href=\"https://huggingface.co/google/umt5-xl\" rel=\"nofollow\">google/umt5-xl</a></li> <li><a href=\"https://huggingface.co/google/umt5-xxl\" rel=\"nofollow\">google/umt5-xxl</a>.</li></ul> <p data-svelte-h=\"svelte-1orfdft\">This model was contributed by <a href=\"https://huggingface.co/agemagician\" rel=\"nofollow\">agemagician</a> and <a href=\"https://huggingface.co/stefan-it\" rel=\"nofollow\">stefan-it</a>. The original code can be\\nfound <a href=\"https://github.com/google-research/t5x\" rel=\"nofollow\">here</a>.</p> <p data-svelte-h=\"svelte-fx9nqk\">One can refer to <a href=\"t5\">T5’s documentation page</a> for more tips, code examples and notebooks.</p> <h2 class=\"relative group\"><a id=\"differences-with-mt5\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#differences-with-mt5\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1og30hi\">Differences with mT5?</span></h2>\\n\\n\\n`UmT5` is based on mT5, with a non-shared relative positional bias that is computed for each layer. This means that the model set `has_relative_bias` for each layer.\\nThe conversion script is also different because the model was saved in t5x\\'s latest checkpointing format.\\n<h1 class=\"relative group\"><a id=\"sample-usage\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#sample-usage\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-12m0tcq\">Sample usage</span></h1> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForSeq2SeqLM, AutoTokenizer\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>inputs = tokenizer(\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-string\">\"A &lt;extra_id_0&gt; walks into a bar and orders a &lt;extra_id_1&gt; with &lt;extra_id_2&gt; pinch of &lt;extra_id_3&gt;.\"</span>,\\n<span class=\"hljs-meta\">... </span>    return_tensors=<span class=\"hljs-string\">\"pt\"</span>,\\n<span class=\"hljs-meta\">... </span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model.generate(**inputs)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-built_in\">print</span>(tokenizer.batch_decode(outputs))\\n[<span class=\"hljs-string\">\\'&lt;pad&gt;&lt;extra_id_0&gt;nyone who&lt;extra_id_1&gt; drink&lt;extra_id_2&gt; a&lt;extra_id_3&gt; alcohol&lt;extra_id_4&gt; A&lt;extra_id_5&gt; A. This&lt;extra_id_6&gt; I&lt;extra_id_7&gt;&lt;extra_id_52&gt;&lt;extra_id_53&gt;&lt;/s&gt;\\'</span>]</pre></div> <h2 class=\"relative group\"><a id=\"transformers.UMT5Config\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1gxkw7g\">UMT5Config</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5Config\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">UMT5Config</span></span></h3> <a id=\"transformers.UMT5Config\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5Config\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/configuration_umt5.py#L31\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">vocab_size<span class=\"opacity-60\"> = 250112</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">d_model<span class=\"opacity-60\"> = 512</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">d_kv<span class=\"opacity-60\"> = 64</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">d_ff<span class=\"opacity-60\"> = 1024</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_layers<span class=\"opacity-60\"> = 8</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_decoder_layers<span class=\"opacity-60\"> = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">num_heads<span class=\"opacity-60\"> = 6</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">relative_attention_num_buckets<span class=\"opacity-60\"> = 32</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">relative_attention_max_distance<span class=\"opacity-60\"> = 128</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">dropout_rate<span class=\"opacity-60\"> = 0.1</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">layer_norm_epsilon<span class=\"opacity-60\"> = 1e-06</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">initializer_factor<span class=\"opacity-60\"> = 1.0</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">feed_forward_proj<span class=\"opacity-60\"> = \\'gated-gelu\\'</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">is_encoder_decoder<span class=\"opacity-60\"> = True</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">use_cache<span class=\"opacity-60\"> = True</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">tokenizer_class<span class=\"opacity-60\"> = \\'T5Tokenizer\\'</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">tie_word_embeddings<span class=\"opacity-60\"> = True</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">pad_token_id<span class=\"opacity-60\"> = 0</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">eos_token_id<span class=\"opacity-60\"> = 1</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_start_token_id<span class=\"opacity-60\"> = 0</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">classifier_dropout<span class=\"opacity-60\"> = 0.0</span></span></span><span class=\"comma cursor-default\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">**kwargs<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 15 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.vocab_size\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.vocab_size\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 250112) —\\nVocabulary size of the UMT5 model. Defines the number of different tokens that can be represented by the\\n<code>inputs_ids</code> passed when calling <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Model\">UMT5Model</a> or <code>TFUMT5Model</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.d_model\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.d_model\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>d_model</strong> (<code>int</code>, <em>optional</em>, defaults to 512) —\\nSize of the encoder layers and the pooler layer.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.d_kv\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.d_kv\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>d_kv</strong> (<code>int</code>, <em>optional</em>, defaults to 64) —\\nSize of the key, query, value projections per attention head. <code>d_kv</code> has to be equal to <code>d_model // num_heads</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.d_ff\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.d_ff\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>d_ff</strong> (<code>int</code>, <em>optional</em>, defaults to 1024) —\\nSize of the intermediate feed forward layer in each <code>UMT5Block</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.num_layers\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.num_layers\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>num_layers</strong> (<code>int</code>, <em>optional</em>, defaults to 8) —\\nNumber of hidden layers in the Transformer encoder.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.num_decoder_layers\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.num_decoder_layers\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>num_decoder_layers</strong> (<code>int</code>, <em>optional</em>) —\\nNumber of hidden layers in the Transformer decoder. Will use the same value as <code>num_layers</code> if not set.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.num_heads\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.num_heads\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>num_heads</strong> (<code>int</code>, <em>optional</em>, defaults to 6) —\\nNumber of attention heads for each attention layer in the Transformer encoder.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.relative_attention_num_buckets\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.relative_attention_num_buckets\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>relative_attention_num_buckets</strong> (<code>int</code>, <em>optional</em>, defaults to 32) —\\nThe number of buckets to use for each attention layer.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.relative_attention_max_distance\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.relative_attention_max_distance\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>relative_attention_max_distance</strong> (<code>int</code>, <em>optional</em>, defaults to 128) —\\nThe maximum distance of the longer sequences for the bucket separation.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.dropout_rate\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.dropout_rate\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>dropout_rate</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) —\\nThe ratio for all dropout layers.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.classifier_dropout\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.classifier_dropout\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>classifier_dropout</strong> (<code>float</code>, <em>optional</em>, defaults to 0.0) —\\nThe dropout ratio for classifier.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.layer_norm_eps\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.layer_norm_eps\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>layer_norm_eps</strong> (<code>float</code>, <em>optional</em>, defaults to 1e-6) —\\nThe epsilon used by the layer normalization layers.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.initializer_factor\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.initializer_factor\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>initializer_factor</strong> (<code>float</code>, <em>optional</em>, defaults to 1) —\\nA factor for initializing all weight matrices (should be kept to 1, used internally for initialization\\ntesting).</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.feed_forward_proj\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.feed_forward_proj\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>feed_forward_proj</strong> (<code>string</code>, <em>optional</em>, defaults to <code>\"gated-gelu\"</code>) —\\nType of feed forward layer to be used. Should be one of <code>\"relu\"</code> or <code>\"gated-gelu\"</code>.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Config.use_cache\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Config.use_cache\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>use_cache</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) —\\nWhether or not the model should return the last key/values attentions (not used by all models).</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-mevz9i\">This is the configuration class to store the configuration of a <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Model\">UMT5Model</a>. It is used to instantiate a UMT5\\nmodel according to the specified arguments, defining the model architecture. Instantiating a configuration with the\\ndefaults will yield a similar configuration to that of the UMT5\\n<a href=\"https://huggingface.co/google/umt5-small\" rel=\"nofollow\">google/umt5-small</a> architecture.</p> <p data-svelte-h=\"svelte-10kqkkl\">Configuration objects inherit from <a href=\"/docs/transformers/v4.34.0/en/main_classes/configuration#transformers.PretrainedConfig\">PretrainedConfig</a> and can be used to control the model outputs. Read the\\ndocumentation from <a href=\"/docs/transformers/v4.34.0/en/main_classes/configuration#transformers.PretrainedConfig\">PretrainedConfig</a> for more information.</p></div> <h2 class=\"relative group\"><a id=\"transformers.UMT5Model\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-1hzcetd\">UMT5Model</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5Model\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">UMT5Model</span></span></h3> <a id=\"transformers.UMT5Model\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5Model\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L936\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-j7l1ea\">The bare UMT5 Model transformer outputting raw hidden-states without any specific head on top.</p> <p data-svelte-h=\"svelte-4ex3z6\">The UMT5 model was proposed in <a href=\"https://arxiv.org/abs/1910.10683\" rel=\"nofollow\">Exploring the Limits of Transfer Learning with a Unified Text-to-Text\\nTransformer</a> by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\\nNarang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. It’s an encoder decoder transformer pre-trained in a\\ntext-to-text denoising generative setting.</p> <p data-svelte-h=\"svelte-hmtw9k\">This model inherits from <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel\">PreTrainedModel</a>. Check the superclass documentation for the generic methods the\\nlibrary implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\\netc.)</p> <p data-svelte-h=\"svelte-hswkmf\">This model is also a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> subclass.\\nUse it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\\nand behavior.</p> <div class=\"relative group rounded-md\"><a id=\"transformers.UMT5Model.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-kvfsh7\">Examples:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> UMT5Model, AutoTokenizer\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = UMT5Model.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>noisy_text = <span class=\"hljs-string\">\"UN Offizier sagt, dass weiter &lt;extra_id_0&gt; werden muss in Syrien.\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>label = <span class=\"hljs-string\">\"&lt;extra_id_0&gt; verhandelt\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>inputs = tokenizer(inputs, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>labels = tokenizer(label=label, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model(input_ids=inputs[<span class=\"hljs-string\">\"input_ids\"</span>], decoder_input_ids=labels[<span class=\"hljs-string\">\"input_ids\"</span>])\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>hidden_states = outputs.last_hidden_state</pre></div></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5Model.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.UMT5Model.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5Model.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1003\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">attention_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_attention_mask<span class=\"opacity-60\">: typing.Optional[torch.BoolTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">cross_attn_head_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">encoder_outputs<span class=\"opacity-60\">: typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">past_key_values<span class=\"opacity-60\">: typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">use_cache<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_attentions<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput\">transformers.modeling_outputs.Seq2SeqModelOutput</a> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 15 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) —\\nIndices of input sequence tokens in the vocabulary. UMT5 is a model with relative position embeddings so\\nyou should be able to pad the inputs on both the right and the left.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for detail.</p>\\n<p><a href=\"../glossary#input-ids\">What are input IDs?</a></p>\\n<p>To know more on how to prepare <code>input_ids</code> for pretraining take a look a <a href=\"./umt5#training\">UMT5 Training</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) —\\nMask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 for tokens that are <strong>not masked</strong>,</li>\\n<li>0 for tokens that are <strong>masked</strong>.</li>\\n</ul>\\n<p><a href=\"../glossary#attention-mask\">What are attention masks?</a></p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.decoder_input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.decoder_input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nIndices of decoder input sequence tokens in the vocabulary.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>\\n<p><a href=\"../glossary#decoder-input-ids\">What are decoder input IDs?</a></p>\\n<p>UMT5 uses the <code>pad_token_id</code> as the starting token for <code>decoder_input_ids</code> generation. If <code>past_key_values</code>\\nis used, optionally only the last <code>decoder_input_ids</code> have to be input (see <code>past_key_values</code>).</p>\\n<p>To know more on how to prepare <code>decoder_input_ids</code> for pretraining take a look at <a href=\"./umt5#training\">UMT5\\nTraining</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.decoder_attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.decoder_attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_attention_mask</strong> (<code>torch.BoolTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nDefault behavior: generate a tensor that ignores pad tokens in <code>decoder_input_ids</code>. Causal mask will also\\nbe used by default.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the encoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.decoder_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.decoder_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the decoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.cross_attn_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.cross_attn_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>cross_attn_head_mask</strong> (<code>torch.Tensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in\\n<code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.encoder_outputs\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.encoder_outputs\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>encoder_outputs</strong> (<code>tuple(tuple(torch.FloatTensor)</code>, <em>optional</em>) —\\nTuple consists of (<code>last_hidden_state</code>, <code>optional</code>: <em>hidden_states</em>, <code>optional</code>: <em>attentions</em>)\\n<code>last_hidden_state</code> of shape <code>(batch_size, sequence_length, hidden_size)</code> is a sequence of hidden states at\\nthe output of the last layer of the encoder. Used in the cross-attention of the decoder.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.past_key_values\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.past_key_values\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code> of length <code>config.n_layers</code> with each tuple having 4 tensors of shape <code>(batch_size, num_heads, sequence_length - 1, embed_size_per_head)</code>) —\\nContains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.<p></p>\\n<p>If <code>past_key_values</code> are used, the user can optionally input only the last <code>decoder_input_ids</code> (those that\\ndon’t have their past key value states given to this model) of shape <code>(batch_size, 1)</code> instead of all\\n<code>decoder_input_ids</code> of shape <code>(batch_size, sequence_length)</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This\\nis useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the\\nmodel’s internal embedding lookup matrix.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.decoder_inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.decoder_inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, target_sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>decoder_input_ids</code> you can choose to directly pass an embedded\\nrepresentation. If <code>past_key_values</code> is used, optionally only the last <code>decoder_inputs_embeds</code> have to be\\ninput (see <code>past_key_values</code>). This is useful if you want more control over how to convert\\n<code>decoder_input_ids</code> indices into associated vectors than the model’s internal embedding lookup matrix.<p></p>\\n<p>If <code>decoder_input_ids</code> and <code>decoder_inputs_embeds</code> are both unset, <code>decoder_inputs_embeds</code> takes the value\\nof <code>inputs_embeds</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.use_cache\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.use_cache\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>use_cache</strong> (<code>bool</code>, <em>optional</em>) —\\nIf set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding (see\\n<code>past_key_values</code>).</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.output_attentions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.output_attentions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned\\ntensors for more detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.output_hidden_states\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.output_hidden_states\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for\\nmore detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5Model.forward.return_dict\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.return_dict\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return a <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.utils.ModelOutput\">ModelOutput</a> instead of a plain tuple.</span></span> </li></ul>  <div id=\"transformers.UMT5Model.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput\">transformers.modeling_outputs.Seq2SeqModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqModelOutput\">transformers.modeling_outputs.Seq2SeqModelOutput</a> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) and inputs.</p>\\n<ul>\\n<li>\\n<p><strong>last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) — Sequence of hidden-states at the output of the last layer of the decoder of the model.</p>\\n<p>If <code>past_key_values</code> is used only the last hidden-state of the sequences of shape <code>(batch_size, 1, hidden_size)</code> is output.</p>\\n</li>\\n<li>\\n<p><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) — Tuple of <code>tuple(torch.FloatTensor)</code> of length <code>config.n_layers</code>, with each tuple having 2 tensors of shape\\n<code>(batch_size, num_heads, sequence_length, embed_size_per_head)</code>) and 2 additional tensors of shape\\n<code>(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)</code>.</p>\\n<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\\nblocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.</p>\\n</li>\\n<li>\\n<p><strong>decoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the decoder at the output of each layer plus the optional initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>decoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>cross_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder’s cross-attention layer, after the attention softmax, used to compute the\\nweighted average in the cross-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>encoder_last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) — Sequence of hidden-states at the output of the last layer of the encoder of the model.</p>\\n</li>\\n<li>\\n<p><strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the encoder at the output of each layer plus the optional initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-1xl5s38\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Model\">UMT5Model</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div> <div class=\"relative group rounded-md\"><a id=\"transformers.UMT5Model.forward.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5Model.forward.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-11lpom8\">Example:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer, UMT5Model\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = UMT5Model.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>input_ids = tokenizer(\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-string\">\"Studies have been shown that owning a dog is good for you\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>\\n<span class=\"hljs-meta\">... </span>).input_ids  <span class=\"hljs-comment\"># Batch size 1</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>decoder_input_ids = tokenizer(<span class=\"hljs-string\">\"Studies show that\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>).input_ids  <span class=\"hljs-comment\"># Batch size 1</span>\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># preprocess: Prepend decoder_input_ids with start token which is pad token for UMT5Model.</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># This is not needed for torch\\'s UMT5ForConditionalGeneration as it does this internally using labels arg.</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>decoder_input_ids = model._shift_right(decoder_input_ids)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># forward pass</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state</pre></div></div></div></div> <h2 class=\"relative group\"><a id=\"transformers.UMT5ForConditionalGeneration\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-140wotv\">UMT5ForConditionalGeneration</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5ForConditionalGeneration\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">UMT5ForConditionalGeneration</span></span></h3> <a id=\"transformers.UMT5ForConditionalGeneration\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5ForConditionalGeneration\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1102\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-1h0jipp\">UMT5 Model with a <code>language modeling</code> head on top.</p> <p data-svelte-h=\"svelte-4ex3z6\">The UMT5 model was proposed in <a href=\"https://arxiv.org/abs/1910.10683\" rel=\"nofollow\">Exploring the Limits of Transfer Learning with a Unified Text-to-Text\\nTransformer</a> by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\\nNarang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. It’s an encoder decoder transformer pre-trained in a\\ntext-to-text denoising generative setting.</p> <p data-svelte-h=\"svelte-hmtw9k\">This model inherits from <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel\">PreTrainedModel</a>. Check the superclass documentation for the generic methods the\\nlibrary implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\\netc.)</p> <p data-svelte-h=\"svelte-hswkmf\">This model is also a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> subclass.\\nUse it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\\nand behavior.</p> <div class=\"relative group rounded-md\"><a id=\"transformers.UMT5ForConditionalGeneration.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-kvfsh7\">Examples:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> UMT5ForConditionalGeneration, AutoTokenizer\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = UMT5ForConditionalGeneration.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>article = <span class=\"hljs-string\">\"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>summary = <span class=\"hljs-string\">\"Weiter Verhandlung in Syrien.\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>inputs = tokenizer(article, text_target=summary, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model(**inputs)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>loss = outputs.loss</pre></div></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5ForConditionalGeneration.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.UMT5ForConditionalGeneration.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5ForConditionalGeneration.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1171\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">attention_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_attention_mask<span class=\"opacity-60\">: typing.Optional[torch.BoolTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">cross_attn_head_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">encoder_outputs<span class=\"opacity-60\">: typing.Optional[typing.Tuple[typing.Tuple[torch.Tensor]]] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">past_key_values<span class=\"opacity-60\">: typing.Optional[typing.Tuple[typing.Tuple[torch.Tensor]]] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">labels<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">use_cache<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_attentions<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput\">transformers.modeling_outputs.Seq2SeqLMOutput</a> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 16 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) —\\nIndices of input sequence tokens in the vocabulary. UMT5 is a model with relative position embeddings so\\nyou should be able to pad the inputs on both the right and the left.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for detail.</p>\\n<p><a href=\"../glossary#input-ids\">What are input IDs?</a></p>\\n<p>To know more on how to prepare <code>input_ids</code> for pretraining take a look a <a href=\"./umt5#training\">UMT5 Training</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) —\\nMask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 for tokens that are <strong>not masked</strong>,</li>\\n<li>0 for tokens that are <strong>masked</strong>.</li>\\n</ul>\\n<p><a href=\"../glossary#attention-mask\">What are attention masks?</a></p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.decoder_input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.decoder_input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nIndices of decoder input sequence tokens in the vocabulary.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>\\n<p><a href=\"../glossary#decoder-input-ids\">What are decoder input IDs?</a></p>\\n<p>UMT5 uses the <code>pad_token_id</code> as the starting token for <code>decoder_input_ids</code> generation. If <code>past_key_values</code>\\nis used, optionally only the last <code>decoder_input_ids</code> have to be input (see <code>past_key_values</code>).</p>\\n<p>To know more on how to prepare <code>decoder_input_ids</code> for pretraining take a look at <a href=\"./umt5#training\">UMT5\\nTraining</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.decoder_attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.decoder_attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_attention_mask</strong> (<code>torch.BoolTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nDefault behavior: generate a tensor that ignores pad tokens in <code>decoder_input_ids</code>. Causal mask will also\\nbe used by default.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the encoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.decoder_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.decoder_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the decoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.cross_attn_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.cross_attn_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>cross_attn_head_mask</strong> (<code>torch.Tensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in\\n<code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.encoder_outputs\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.encoder_outputs\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>encoder_outputs</strong> (<code>tuple(tuple(torch.FloatTensor)</code>, <em>optional</em>) —\\nTuple consists of (<code>last_hidden_state</code>, <code>optional</code>: <em>hidden_states</em>, <code>optional</code>: <em>attentions</em>)\\n<code>last_hidden_state</code> of shape <code>(batch_size, sequence_length, hidden_size)</code> is a sequence of hidden states at\\nthe output of the last layer of the encoder. Used in the cross-attention of the decoder.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.past_key_values\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.past_key_values\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code> of length <code>config.n_layers</code> with each tuple having 4 tensors of shape <code>(batch_size, num_heads, sequence_length - 1, embed_size_per_head)</code>) —\\nContains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.<p></p>\\n<p>If <code>past_key_values</code> are used, the user can optionally input only the last <code>decoder_input_ids</code> (those that\\ndon’t have their past key value states given to this model) of shape <code>(batch_size, 1)</code> instead of all\\n<code>decoder_input_ids</code> of shape <code>(batch_size, sequence_length)</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This\\nis useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the\\nmodel’s internal embedding lookup matrix.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.decoder_inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.decoder_inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, target_sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>decoder_input_ids</code> you can choose to directly pass an embedded\\nrepresentation. If <code>past_key_values</code> is used, optionally only the last <code>decoder_inputs_embeds</code> have to be\\ninput (see <code>past_key_values</code>). This is useful if you want more control over how to convert\\n<code>decoder_input_ids</code> indices into associated vectors than the model’s internal embedding lookup matrix.<p></p>\\n<p>If <code>decoder_input_ids</code> and <code>decoder_inputs_embeds</code> are both unset, <code>decoder_inputs_embeds</code> takes the value\\nof <code>inputs_embeds</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.use_cache\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.use_cache\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>use_cache</strong> (<code>bool</code>, <em>optional</em>) —\\nIf set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding (see\\n<code>past_key_values</code>).</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.output_attentions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.output_attentions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned\\ntensors for more detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.output_hidden_states\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.output_hidden_states\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for\\nmore detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.return_dict\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.return_dict\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return a <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.utils.ModelOutput\">ModelOutput</a> instead of a plain tuple.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.labels\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.labels\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) —\\nLabels for computing the sequence classification/regression loss. Indices should be in <code>[-100, 0, ..., config.vocab_size - 1]</code>. All labels set to <code>-100</code> are ignored (masked), the loss is only computed for\\nlabels in <code>[0, ..., config.vocab_size]</code></span></span> </li></ul>  <div id=\"transformers.UMT5ForConditionalGeneration.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput\">transformers.modeling_outputs.Seq2SeqLMOutput</a> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqLMOutput\">transformers.modeling_outputs.Seq2SeqLMOutput</a> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) and inputs.</p>\\n<ul>\\n<li>\\n<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) — Language modeling loss.</p>\\n</li>\\n<li>\\n<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, config.vocab_size)</code>) — Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p>\\n</li>\\n<li>\\n<p><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) — Tuple of <code>tuple(torch.FloatTensor)</code> of length <code>config.n_layers</code>, with each tuple having 2 tensors of shape\\n<code>(batch_size, num_heads, sequence_length, embed_size_per_head)</code>) and 2 additional tensors of shape\\n<code>(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)</code>.</p>\\n<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\\nblocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.</p>\\n</li>\\n<li>\\n<p><strong>decoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>decoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>cross_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder’s cross-attention layer, after the attention softmax, used to compute the\\nweighted average in the cross-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>encoder_last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) — Sequence of hidden-states at the output of the last layer of the encoder of the model.</p>\\n</li>\\n<li>\\n<p><strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-1rs3r90\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5ForConditionalGeneration\">UMT5ForConditionalGeneration</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div> <div class=\"relative group rounded-md\"><a id=\"transformers.UMT5ForConditionalGeneration.forward.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForConditionalGeneration.forward.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-kvfsh7\">Examples:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer, UMT5ForConditionalGeneration\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = UMT5ForConditionalGeneration.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># training</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>input_ids = tokenizer(<span class=\"hljs-string\">\"The &lt;extra_id_0&gt; walks in &lt;extra_id_1&gt; park\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>).input_ids\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>labels = tokenizer(<span class=\"hljs-string\">\"&lt;extra_id_0&gt; cute dog &lt;extra_id_1&gt; the &lt;extra_id_2&gt;\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>).input_ids\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids, labels=labels)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>loss = outputs.loss\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>logits = outputs.logits\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-comment\"># inference</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>input_ids = tokenizer(<span class=\"hljs-string\">\"Studies have shown that &lt;extra_id_0&gt; good for you\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>).input_ids\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model.generate(input_ids)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer.decode(outputs[<span class=\"hljs-number\">0</span>], skip_special_tokens=<span class=\"hljs-literal\">True</span>)</pre></div></div></div></div> <h2 class=\"relative group\"><a id=\"transformers.UMT5EncoderModel\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-jvqard\">UMT5EncoderModel</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5EncoderModel\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">UMT5EncoderModel</span></span></h3> <a id=\"transformers.UMT5EncoderModel\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5EncoderModel\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1344\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-k2qq32\">The bare UMT5 Model transformer outputting encoder’s raw hidden-states without any specific head on top.</p> <p data-svelte-h=\"svelte-4ex3z6\">The UMT5 model was proposed in <a href=\"https://arxiv.org/abs/1910.10683\" rel=\"nofollow\">Exploring the Limits of Transfer Learning with a Unified Text-to-Text\\nTransformer</a> by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\\nNarang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. It’s an encoder decoder transformer pre-trained in a\\ntext-to-text denoising generative setting.</p> <p data-svelte-h=\"svelte-hmtw9k\">This model inherits from <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel\">PreTrainedModel</a>. Check the superclass documentation for the generic methods the\\nlibrary implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\\netc.)</p> <p data-svelte-h=\"svelte-hswkmf\">This model is also a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> subclass.\\nUse it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\\nand behavior.</p> <div class=\"relative group rounded-md\"><a id=\"transformers.UMT5EncoderModel.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-kvfsh7\">Examples:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> UMT5EncoderModel, AutoTokenizer\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = UMT5EncoderModel.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>article = <span class=\"hljs-string\">\"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>input_ids = tokenizer(article, return_tensors=<span class=\"hljs-string\">\"pt\"</span>).input_ids\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model(input_ids)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>hidden_state = outputs.last_hidden_state</pre></div></div> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5EncoderModel.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.UMT5EncoderModel.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5EncoderModel.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1397\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">attention_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_attentions<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput\">transformers.modeling_outputs.BaseModelOutput</a> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 7 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) —\\nIndices of input sequence tokens in the vocabulary. UMT5 is a model with relative position embeddings so\\nyou should be able to pad the inputs on both the right and the left.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for detail.</p>\\n<p>To know more on how to prepare <code>input_ids</code> for pretraining take a look a <a href=\"./umt5#training\">UMT5 Training</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) —\\nMask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 for tokens that are <strong>not masked</strong>,</li>\\n<li>0 for tokens that are <strong>masked</strong>.</li>\\n</ul>\\n<p><a href=\"../glossary#attention-mask\">What are attention masks?</a></p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This\\nis useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the\\nmodel’s internal embedding lookup matrix.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.output_attentions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.output_attentions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned\\ntensors for more detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.output_hidden_states\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.output_hidden_states\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for\\nmore detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5EncoderModel.forward.return_dict\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.return_dict\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return a <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.utils.ModelOutput\">ModelOutput</a> instead of a plain tuple.</span></span> </li></ul>  <div id=\"transformers.UMT5EncoderModel.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput\">transformers.modeling_outputs.BaseModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.BaseModelOutput\">transformers.modeling_outputs.BaseModelOutput</a> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) and inputs.</p>\\n<ul>\\n<li>\\n<p><strong>last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) — Sequence of hidden-states at the output of the last layer of the model.</p>\\n</li>\\n<li>\\n<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\\nheads.</p>\\n</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-l0rtgs\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5EncoderModel\">UMT5EncoderModel</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div> <div class=\"relative group rounded-md\"><a id=\"transformers.UMT5EncoderModel.forward.example\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5EncoderModel.forward.example\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <p data-svelte-h=\"svelte-11lpom8\">Example:</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 \" title=\"code excerpt\" type=\"button\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" aria-hidden=\"true\" fill=\"currentColor\" focusable=\"false\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 32 32\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" width=\"32\" height=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><span class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer, UMT5EncoderModel\\n\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = UMT5EncoderModel.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"</span>)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>input_ids = tokenizer(\\n<span class=\"hljs-meta\">... </span>    <span class=\"hljs-string\">\"Studies have been shown that owning a dog is good for you\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>\\n<span class=\"hljs-meta\">... </span>).input_ids  <span class=\"hljs-comment\"># Batch size 1</span>\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>outputs = model(input_ids=input_ids)\\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state</pre></div></div></div></div> <h2 class=\"relative group\"><a id=\"transformers.UMT5ForSequenceClassification\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-18krpz2\">UMT5ForSequenceClassification</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5ForSequenceClassification\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">UMT5ForSequenceClassification</span></span></h3> <a id=\"transformers.UMT5ForSequenceClassification\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5ForSequenceClassification\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1448\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\">: UMT5Config</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-1o18zcb\">UMT5 model with a sequence classification/head on top (a linear layer on top of the pooled output) e.g. for GLUE\\ntasks.</p> <p data-svelte-h=\"svelte-4ex3z6\">The UMT5 model was proposed in <a href=\"https://arxiv.org/abs/1910.10683\" rel=\"nofollow\">Exploring the Limits of Transfer Learning with a Unified Text-to-Text\\nTransformer</a> by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\\nNarang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. It’s an encoder decoder transformer pre-trained in a\\ntext-to-text denoising generative setting.</p> <p data-svelte-h=\"svelte-hmtw9k\">This model inherits from <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel\">PreTrainedModel</a>. Check the superclass documentation for the generic methods the\\nlibrary implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\\netc.)</p> <p data-svelte-h=\"svelte-hswkmf\">This model is also a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> subclass.\\nUse it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\\nand behavior.</p> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5ForSequenceClassification.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.UMT5ForSequenceClassification.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5ForSequenceClassification.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1463\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">input_ids<span class=\"opacity-60\">: LongTensor = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">attention_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_attention_mask<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">head_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_head_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">cross_attn_head_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">encoder_outputs<span class=\"opacity-60\">: typing.Optional[typing.List[torch.FloatTensor]] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">labels<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">use_cache<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_attentions<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput\">transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput</a> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 16 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) —\\nIndices of input sequence tokens in the vocabulary. UMT5 is a model with relative position embeddings so\\nyou should be able to pad the inputs on both the right and the left.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for detail.</p>\\n<p><a href=\"../glossary#input-ids\">What are input IDs?</a></p>\\n<p>To know more on how to prepare <code>input_ids</code> for pretraining take a look a <a href=\"./umt5#training\">UMT5 Training</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) —\\nMask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 for tokens that are <strong>not masked</strong>,</li>\\n<li>0 for tokens that are <strong>masked</strong>.</li>\\n</ul>\\n<p><a href=\"../glossary#attention-mask\">What are attention masks?</a></p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.decoder_input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.decoder_input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nIndices of decoder input sequence tokens in the vocabulary.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>\\n<p><a href=\"../glossary#decoder-input-ids\">What are decoder input IDs?</a></p>\\n<p>UMT5 uses the <code>pad_token_id</code> as the starting token for <code>decoder_input_ids</code> generation. If <code>past_key_values</code>\\nis used, optionally only the last <code>decoder_input_ids</code> have to be input (see <code>past_key_values</code>).</p>\\n<p>To know more on how to prepare <code>decoder_input_ids</code> for pretraining take a look at <a href=\"./umt5#training\">UMT5\\nTraining</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.decoder_attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.decoder_attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_attention_mask</strong> (<code>torch.BoolTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nDefault behavior: generate a tensor that ignores pad tokens in <code>decoder_input_ids</code>. Causal mask will also\\nbe used by default.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the encoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.decoder_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.decoder_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the decoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.cross_attn_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.cross_attn_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>cross_attn_head_mask</strong> (<code>torch.Tensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in\\n<code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.encoder_outputs\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.encoder_outputs\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>encoder_outputs</strong> (<code>tuple(tuple(torch.FloatTensor)</code>, <em>optional</em>) —\\nTuple consists of (<code>last_hidden_state</code>, <code>optional</code>: <em>hidden_states</em>, <code>optional</code>: <em>attentions</em>)\\n<code>last_hidden_state</code> of shape <code>(batch_size, sequence_length, hidden_size)</code> is a sequence of hidden states at\\nthe output of the last layer of the encoder. Used in the cross-attention of the decoder.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.past_key_values\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.past_key_values\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code> of length <code>config.n_layers</code> with each tuple having 4 tensors of shape <code>(batch_size, num_heads, sequence_length - 1, embed_size_per_head)</code>) —\\nContains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.<p></p>\\n<p>If <code>past_key_values</code> are used, the user can optionally input only the last <code>decoder_input_ids</code> (those that\\ndon’t have their past key value states given to this model) of shape <code>(batch_size, 1)</code> instead of all\\n<code>decoder_input_ids</code> of shape <code>(batch_size, sequence_length)</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This\\nis useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the\\nmodel’s internal embedding lookup matrix.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.decoder_inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.decoder_inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, target_sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>decoder_input_ids</code> you can choose to directly pass an embedded\\nrepresentation. If <code>past_key_values</code> is used, optionally only the last <code>decoder_inputs_embeds</code> have to be\\ninput (see <code>past_key_values</code>). This is useful if you want more control over how to convert\\n<code>decoder_input_ids</code> indices into associated vectors than the model’s internal embedding lookup matrix.<p></p>\\n<p>If <code>decoder_input_ids</code> and <code>decoder_inputs_embeds</code> are both unset, <code>decoder_inputs_embeds</code> takes the value\\nof <code>inputs_embeds</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.use_cache\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.use_cache\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>use_cache</strong> (<code>bool</code>, <em>optional</em>) —\\nIf set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding (see\\n<code>past_key_values</code>).</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.output_attentions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.output_attentions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned\\ntensors for more detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.output_hidden_states\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.output_hidden_states\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for\\nmore detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.return_dict\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.return_dict\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return a <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.utils.ModelOutput\">ModelOutput</a> instead of a plain tuple.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForSequenceClassification.forward.labels\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForSequenceClassification.forward.labels\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) —\\nLabels for computing the sequence classification/regression loss. Indices should be in <code>[0, ..., config.num_labels - 1]</code>. If <code>config.num_labels &gt; 1</code> a classification loss is computed (Cross-Entropy).</span></span> </li></ul>  <div id=\"transformers.UMT5ForSequenceClassification.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput\">transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput</a> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput\">transformers.modeling_outputs.Seq2SeqSequenceClassifierOutput</a> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) and inputs.</p>\\n<ul>\\n<li>\\n<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>label</code> is provided) — Classification (or regression if config.num_labels==1) loss.</p>\\n</li>\\n<li>\\n<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.num_labels)</code>) — Classification (or regression if config.num_labels==1) scores (before SoftMax).</p>\\n</li>\\n<li>\\n<p><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) — Tuple of <code>tuple(torch.FloatTensor)</code> of length <code>config.n_layers</code>, with each tuple having 2 tensors of shape\\n<code>(batch_size, num_heads, sequence_length, embed_size_per_head)</code>) and 2 additional tensors of shape\\n<code>(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)</code>.</p>\\n<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\\nblocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.</p>\\n</li>\\n<li>\\n<p><strong>decoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>decoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>cross_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder’s cross-attention layer, after the attention softmax, used to compute the\\nweighted average in the cross-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>encoder_last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) — Sequence of hidden-states at the output of the last layer of the encoder of the model.</p>\\n</li>\\n<li>\\n<p><strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-1eys80k\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5ForSequenceClassification\">UMT5ForSequenceClassification</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div></div></div> <h2 class=\"relative group\"><a id=\"transformers.UMT5ForQuestionAnswering\" class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering\"><span><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span data-svelte-h=\"svelte-16wfbcv\">UMT5ForQuestionAnswering</span></h2> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5ForQuestionAnswering\"><h3 class=\"!m-0\"><span class=\"flex-1 break-all md:text-lg bg-gradient-to-r px-2.5 py-1.5 rounded-xl from-indigo-50/70 to-white dark:from-gray-900 dark:to-gray-950 dark:text-indigo-300 text-indigo-700\"><svg class=\"mr-1.5 text-indigo-500 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" focusable=\"false\" role=\"img\" width=\".8em\" height=\".8em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 24 24\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" opacity=\".25\" fill=\"currentColor\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" opacity=\".5\" fill=\"currentColor\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg><span class=\"font-light\">class</span> <span class=\"font-medium\">transformers.</span><span class=\"font-semibold\">UMT5ForQuestionAnswering</span></span></h3> <a id=\"transformers.UMT5ForQuestionAnswering\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5ForQuestionAnswering\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1582\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">config<span class=\"opacity-60\"></span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> </p> <div class=\"!mb-10 relative docstring-details \"> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.config\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.config\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>config</strong> (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) — Model configuration class with all the parameters of the model.\\nInitializing with a config file does not load the weights associated with the model, only the\\nconfiguration. Check out the <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\">from_pretrained()</a> method to load the model weights.</span></span> </li></ul>   </div></div> <p data-svelte-h=\"svelte-m1fu1b\">UMT5 Model with a span classification head on top for extractive question-answering tasks like SQuAD (linear layers\\non top of the hidden-states output to compute <code>span start logits</code> and <code>span end logits</code>).</p> <p data-svelte-h=\"svelte-4ex3z6\">The UMT5 model was proposed in <a href=\"https://arxiv.org/abs/1910.10683\" rel=\"nofollow\">Exploring the Limits of Transfer Learning with a Unified Text-to-Text\\nTransformer</a> by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\\nNarang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. It’s an encoder decoder transformer pre-trained in a\\ntext-to-text denoising generative setting.</p> <p data-svelte-h=\"svelte-hmtw9k\">This model inherits from <a href=\"/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel\">PreTrainedModel</a>. Check the superclass documentation for the generic methods the\\nlibrary implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\\netc.)</p> <p data-svelte-h=\"svelte-hswkmf\">This model is also a PyTorch <a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.Module\" rel=\"nofollow\">torch.nn.Module</a> subclass.\\nUse it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\\nand behavior.</p> <div class=\"docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8\"><div><span class=\"group flex space-x-1.5 items-center text-gray-800 bg-gradient-to-r rounded-tr-lg -mt-4 -ml-4 pt-3 px-2.5\" id=\"transformers.UMT5ForQuestionAnswering.forward\"><h4 class=\"!m-0\"><span class=\"flex-1 rounded-xl py-0.5 break-all bg-gradient-to-r from-blue-50/60 to-white dark:from-gray-900 dark:to-gray-950 text-blue-700 dark:text-blue-300 font-medium px-2\"><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 32 33\" class=\"mr-1 inline-block -mt-0.5\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.80566 18.3545C4.90766 17.4565 4.90766 16.0005 5.80566 15.1025L14.3768 6.53142C15.2748 5.63342 16.7307 5.63342 17.6287 6.53142L26.1999 15.1025C27.0979 16.0005 27.0979 17.4565 26.1999 18.3545L17.6287 26.9256C16.7307 27.8236 15.2748 27.8236 14.3768 26.9256L5.80566 18.3545Z\" fill=\"currentColor\" fill-opacity=\"0.25\"></path><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.4801 13.9619C16.4801 12.9761 16.7467 12.5436 16.9443 12.3296C17.1764 12.078 17.5731 11.8517 18.2275 11.707C18.8821 11.5623 19.638 11.5342 20.4038 11.5582C20.7804 11.57 21.1341 11.5932 21.4719 11.6156L21.5263 11.6193C21.8195 11.6389 22.1626 11.6618 22.4429 11.6618V7.40825C22.3209 7.40825 22.1219 7.39596 21.7544 7.37149C21.4202 7.34925 20.9976 7.32115 20.5371 7.30672C19.6286 7.27824 18.4672 7.29779 17.3093 7.55377C16.1512 7.8098 14.8404 8.33724 13.8181 9.4452C12.7612 10.5907 12.2266 12.1236 12.2266 13.9619V15.0127H10.6836V19.2662H12.2266V26.6332H16.4801V19.2662H20.3394V15.0127H16.4801V13.9619Z\" fill=\"currentColor\"></path></svg>forward</span></h4> <a id=\"transformers.UMT5ForQuestionAnswering.forward\" class=\"header-link invisible with-hover:group-hover:visible pr-2\" href=\"#transformers.UMT5ForQuestionAnswering.forward\"><svg class=\"\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></a> <a class=\"!ml-auto !text-gray-400 !no-underline text-sm flex items-center\" href=\"https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/models/umt5/modeling_umt5.py#L1627\" target=\"_blank\"><span data-svelte-h=\"svelte-1kd6by1\">&lt;</span> <span class=\"hidden md:block mx-0.5 hover:!underline\" data-svelte-h=\"svelte-122apf4\">source</span> <span data-svelte-h=\"svelte-x0xyl0\">&gt;</span></a></span> <p class=\"font-mono text-xs md:text-sm !leading-relaxed !my-6\"><span data-svelte-h=\"svelte-8mvn6a\">(</span> <span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">attention_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_input_ids<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_attention_mask<span class=\"opacity-60\">: typing.Optional[torch.BoolTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_head_mask<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">cross_attn_head_mask<span class=\"opacity-60\">: typing.Optional[torch.Tensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">encoder_outputs<span class=\"opacity-60\">: typing.Optional[typing.Tuple[typing.Tuple[torch.Tensor]]] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">start_positions<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">end_positions<span class=\"opacity-60\">: typing.Optional[torch.LongTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">decoder_inputs_embeds<span class=\"opacity-60\">: typing.Optional[torch.FloatTensor] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">use_cache<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_attentions<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">output_hidden_states<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span><span class=\"comma cursor-pointer\"><span class=\"rounded hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black\">return_dict<span class=\"opacity-60\">: typing.Optional[bool] = None</span></span></span> <span data-svelte-h=\"svelte-1jq0pl7\">)</span> <span class=\"font-bold\" data-svelte-h=\"svelte-1j6k10o\">→</span> <span class=\"rounded hover:bg-gray-400 cursor-pointer\"><span><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput\">transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput</a> or <code>tuple(torch.FloatTensor)</code></span></span></p> <div class=\"!mb-10 relative docstring-details max-h-96 overflow-hidden\"><div class=\"absolute inset-0 bg-gradient-to-t from-white to-white/0 dark:from-gray-950 dark:to-gray-950/0 z-10 flex justify-center\"><button class=\"absolute leading-tight px-3 py-1.5 dark:bg-gray-900 bg-black text-gray-200 hover:text-white rounded-xl bottom-12 ring-offset-2 hover:ring-black hover:ring-2\">Expand 17 parameters</button></div> <p class=\"flex items-center font-semibold !mt-2 !mb-2 text-gray-800\" data-svelte-h=\"svelte-lt6pb6\">Parameters <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700 ml-3\"></span></p> <ul class=\"px-2\"><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) —\\nIndices of input sequence tokens in the vocabulary. UMT5 is a model with relative position embeddings so\\nyou should be able to pad the inputs on both the right and the left.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for detail.</p>\\n<p><a href=\"../glossary#input-ids\">What are input IDs?</a></p>\\n<p>To know more on how to prepare <code>input_ids</code> for pretraining take a look a <a href=\"./umt5#training\">UMT5 Training</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) —\\nMask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 for tokens that are <strong>not masked</strong>,</li>\\n<li>0 for tokens that are <strong>masked</strong>.</li>\\n</ul>\\n<p><a href=\"../glossary#attention-mask\">What are attention masks?</a></p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.decoder_input_ids\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.decoder_input_ids\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nIndices of decoder input sequence tokens in the vocabulary.<p></p>\\n<p>Indices can be obtained using <a href=\"/docs/transformers/v4.34.0/en/model_doc/auto#transformers.AutoTokenizer\">AutoTokenizer</a>. See <a href=\"/docs/transformers/v4.34.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode\">PreTrainedTokenizer.encode()</a> and\\n<a href=\"/docs/transformers/v4.34.0/en/model_doc/vits#transformers.VitsTokenizer.__call__\">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>\\n<p><a href=\"../glossary#decoder-input-ids\">What are decoder input IDs?</a></p>\\n<p>UMT5 uses the <code>pad_token_id</code> as the starting token for <code>decoder_input_ids</code> generation. If <code>past_key_values</code>\\nis used, optionally only the last <code>decoder_input_ids</code> have to be input (see <code>past_key_values</code>).</p>\\n<p>To know more on how to prepare <code>decoder_input_ids</code> for pretraining take a look at <a href=\"./umt5#training\">UMT5\\nTraining</a>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.decoder_attention_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.decoder_attention_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_attention_mask</strong> (<code>torch.BoolTensor</code> of shape <code>(batch_size, target_sequence_length)</code>, <em>optional</em>) —\\nDefault behavior: generate a tensor that ignores pad tokens in <code>decoder_input_ids</code>. Causal mask will also\\nbe used by default.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the encoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.decoder_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.decoder_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the self-attention modules in the decoder. Mask values selected in <code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.cross_attn_head_mask\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.cross_attn_head_mask\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>cross_attn_head_mask</strong> (<code>torch.Tensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) —\\nMask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in\\n<code>[0, 1]</code>:<p></p>\\n<ul>\\n<li>1 indicates the head is <strong>not masked</strong>,</li>\\n<li>0 indicates the head is <strong>masked</strong>.</li>\\n</ul></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.encoder_outputs\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.encoder_outputs\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>encoder_outputs</strong> (<code>tuple(tuple(torch.FloatTensor)</code>, <em>optional</em>) —\\nTuple consists of (<code>last_hidden_state</code>, <code>optional</code>: <em>hidden_states</em>, <code>optional</code>: <em>attentions</em>)\\n<code>last_hidden_state</code> of shape <code>(batch_size, sequence_length, hidden_size)</code> is a sequence of hidden states at\\nthe output of the last layer of the encoder. Used in the cross-attention of the decoder.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.past_key_values\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.past_key_values\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code> of length <code>config.n_layers</code> with each tuple having 4 tensors of shape <code>(batch_size, num_heads, sequence_length - 1, embed_size_per_head)</code>) —\\nContains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.<p></p>\\n<p>If <code>past_key_values</code> are used, the user can optionally input only the last <code>decoder_input_ids</code> (those that\\ndon’t have their past key value states given to this model) of shape <code>(batch_size, 1)</code> instead of all\\n<code>decoder_input_ids</code> of shape <code>(batch_size, sequence_length)</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This\\nis useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the\\nmodel’s internal embedding lookup matrix.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.decoder_inputs_embeds\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.decoder_inputs_embeds\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>decoder_inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, target_sequence_length, hidden_size)</code>, <em>optional</em>) —\\nOptionally, instead of passing <code>decoder_input_ids</code> you can choose to directly pass an embedded\\nrepresentation. If <code>past_key_values</code> is used, optionally only the last <code>decoder_inputs_embeds</code> have to be\\ninput (see <code>past_key_values</code>). This is useful if you want more control over how to convert\\n<code>decoder_input_ids</code> indices into associated vectors than the model’s internal embedding lookup matrix.<p></p>\\n<p>If <code>decoder_input_ids</code> and <code>decoder_inputs_embeds</code> are both unset, <code>decoder_inputs_embeds</code> takes the value\\nof <code>inputs_embeds</code>.</p></span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.use_cache\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.use_cache\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>use_cache</strong> (<code>bool</code>, <em>optional</em>) —\\nIf set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding (see\\n<code>past_key_values</code>).</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.output_attentions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.output_attentions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned\\ntensors for more detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.output_hidden_states\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.output_hidden_states\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for\\nmore detail.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.return_dict\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.return_dict\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) —\\nWhether or not to return a <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.utils.ModelOutput\">ModelOutput</a> instead of a plain tuple.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.start_positions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.start_positions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>start_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) —\\nLabels for position (index) of the start of the labelled span for computing the token classification loss.\\nPositions are clamped to the length of the sequence (<em>sequence_length</em>). Position outside of the sequence\\nare not taken into account for computing the loss.</span></span> </li><li class=\"text-base !pl-4 my-3 rounded \"><span class=\"group flex space-x-1.5 items-start\"><a id=\"transformers.UMT5ForQuestionAnswering.forward.end_positions\" class=\"header-link block pr-0.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"#transformers.UMT5ForQuestionAnswering.forward.end_positions\"><span><svg class=\"text-smd\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" width=\"1em\" height=\"1em\" preserveAspectRatio=\"xMidYMid meet\" viewBox=\"0 0 256 256\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span><strong>end_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) —\\nLabels for position (index) of the end of the labelled span for computing the token classification loss.\\nPositions are clamped to the length of the sequence (<em>sequence_length</em>). Position outside of the sequence\\nare not taken into account for computing the loss.</span></span> </li></ul>  <div id=\"transformers.UMT5ForQuestionAnswering.forward.returns\" class=\"flex items-center font-semibold space-x-3 text-base !mt-0 !mb-0 text-gray-800 rounded \"><p class=\"text-base\">Returns</p> \\n<p><a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput\">transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput</a> or <code>tuple(torch.FloatTensor)</code></p>\\n <span class=\"flex-auto border-t-2 border-gray-100 dark:border-gray-700\"></span></div> <p class=\"text-base\">\\n<p>A <a href=\"/docs/transformers/v4.34.0/en/main_classes/output#transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput\">transformers.modeling_outputs.Seq2SeqQuestionAnsweringModelOutput</a> or a tuple of\\n<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various\\nelements depending on the configuration (<a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5Config\">UMT5Config</a>) and inputs.</p>\\n<ul>\\n<li>\\n<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) — Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.</p>\\n</li>\\n<li>\\n<p><strong>start_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>) — Span-start scores (before SoftMax).</p>\\n</li>\\n<li>\\n<p><strong>end_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>) — Span-end scores (before SoftMax).</p>\\n</li>\\n<li>\\n<p><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) — Tuple of <code>tuple(torch.FloatTensor)</code> of length <code>config.n_layers</code>, with each tuple having 2 tensors of shape\\n<code>(batch_size, num_heads, sequence_length, embed_size_per_head)</code>) and 2 additional tensors of shape\\n<code>(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)</code>.</p>\\n<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\\nblocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.</p>\\n</li>\\n<li>\\n<p><strong>decoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>decoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>cross_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the decoder’s cross-attention layer, after the attention softmax, used to compute the\\nweighted average in the cross-attention heads.</p>\\n</li>\\n<li>\\n<p><strong>encoder_last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>, <em>optional</em>) — Sequence of hidden-states at the output of the last layer of the encoder of the model.</p>\\n</li>\\n<li>\\n<p><strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +\\none for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>\\n<p>Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.</p>\\n</li>\\n<li>\\n<p><strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>\\n<p>Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in the\\nself-attention heads.</p>\\n</li>\\n</ul>\\n</p> </div></div> <p data-svelte-h=\"svelte-4ddtzs\">The <a href=\"/docs/transformers/v4.34.0/en/model_doc/umt5#transformers.UMT5ForQuestionAnswering\">UMT5ForQuestionAnswering</a> forward method, overrides the <code>__call__</code> special method.</p> <div class=\"course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400\"><p data-svelte-h=\"svelte-fincs2\">Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>\\ninstance afterwards instead of this since the former takes care of running the pre and post processing steps while\\nthe latter silently ignores them.</p></div></div></div> <p></p> <div id=\"svelte-announcer\" aria-live=\"assertive\" aria-atomic=\"true\" style=\"position: absolute; left: 0px; top: 0px; clip: rect(0px, 0px, 0px, 0px); clip-path: inset(50%); overflow: hidden; white-space: nowrap; width: 1px; height: 1px;\"></div></div>\\n\\t\\t\\t\\t<div class=\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\"><a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/model_doc/ul2\" class=\"mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300\"><span class=\"mr-2 translate-y-px\">←</span>UL2</a>\\n\\t\\t\\t\\t\\t<a data-sveltekit-reload=\"\" href=\"/docs/transformers/v4.34.0/en/model_doc/xmod\" class=\"ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300\">X-MOD<span class=\"ml-2 translate-y-px\">→</span></a></div></div></div>\\n\\t\\t<div class=\"sticky top-0 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{&quot;chapter&quot;:{&quot;title&quot;:&quot;Sample usage&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;sample-usage&quot;,&quot;url&quot;:&quot;#sample-usage&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;UMT5Config&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.UMT5Config&quot;,&quot;url&quot;:&quot;#transformers.UMT5Config&quot;},{&quot;title&quot;:&quot;UMT5Model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.UMT5Model&quot;,&quot;url&quot;:&quot;#transformers.UMT5Model&quot;},{&quot;title&quot;:&quot;UMT5ForConditionalGeneration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.UMT5ForConditionalGeneration&quot;,&quot;url&quot;:&quot;#transformers.UMT5ForConditionalGeneration&quot;},{&quot;title&quot;:&quot;UMT5EncoderModel&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.UMT5EncoderModel&quot;,&quot;url&quot;:&quot;#transformers.UMT5EncoderModel&quot;},{&quot;title&quot;:&quot;UMT5ForSequenceClassification&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.UMT5ForSequenceClassification&quot;,&quot;url&quot;:&quot;#transformers.UMT5ForSequenceClassification&quot;},{&quot;title&quot;:&quot;UMT5ForQuestionAnswering&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;transformers.UMT5ForQuestionAnswering&quot;,&quot;url&quot;:&quot;#transformers.UMT5ForQuestionAnswering&quot;}]}}\" data-target=\"SubSideMenu\"><nav class=\"hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pt-24 pl-6 pr-10 pb-16 text-sm lg:flex 2xl:w-[305px]\"><a href=\"#sample-usage\" class=\" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-sample-usage\"><wbr>Sample usage</a> <a href=\"#transformers.UMT5Config\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.UMT5Config\">UM<wbr>T5<wbr>Config</a> <a href=\"#transformers.UMT5Model\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.UMT5Model\">UM<wbr>T5<wbr>Model</a> <a href=\"#transformers.UMT5ForConditionalGeneration\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.UMT5ForConditionalGeneration\">UM<wbr>T5<wbr>For<wbr>Conditional<wbr>Generation</a> <a href=\"#transformers.UMT5EncoderModel\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.UMT5EncoderModel\">UM<wbr>T5<wbr>Encoder<wbr>Model</a> <a href=\"#transformers.UMT5ForSequenceClassification\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.UMT5ForSequenceClassification\">UM<wbr>T5<wbr>For<wbr>Sequence<wbr>Classification</a> <a href=\"#transformers.UMT5ForQuestionAnswering\" class=\"pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300\" id=\"nav-transformers.UMT5ForQuestionAnswering\">UM<wbr>T5<wbr>For<wbr>Question<wbr>Answering</a> </nav></div></div></div>\\n\\t<div id=\"doc-footer\"></div></main>\\n\\t</div>\\n\\n\\t\\t<script>\\n\\t\\t\\timport(\"/front/build/kube-b0520c1/index.js\");\\n\\t\\t\\twindow.moonSha = \"kube-b0520c1/\";\\n\\t\\t\\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\"}`);\\n\\t\\t</script>\\n\\n\\t\\t<!-- Stripe -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://js.stripe.com/v3/\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google analytics v4 -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\tconst script = document.createElement(\"script\");\\n\\t\\t\\t\\tscript.src = \"https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL\";\\n\\t\\t\\t\\tscript.async = true;\\n\\t\\t\\t\\tdocument.head.appendChild(script);\\n\\n\\t\\t\\t\\twindow.dataLayer = window.dataLayer || [];\\n\\t\\t\\t\\tfunction gtag() {\\n\\t\\t\\t\\t\\tif (window.dataLayer !== undefined) {\\n\\t\\t\\t\\t\\t\\twindow.dataLayer.push(arguments);\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t\\tgtag(\"js\", new Date());\\n\\t\\t\\t\\tgtag(\"config\", \"G-8Q63TH4CSL\", { page_path: \"/docs/transformers/v4.34.0/en/model_doc/umt5\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages\\n\\t\\t\\t\\tgtag(\"consent\", \"default\", { ad_storage: \"denied\", analytics_storage: \"denied\" });\\n\\t\\t\\t\\t/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent\\n\\t\\t\\t\\t/// TODO: ask the user for their consent and update this with gtag(\\'consent\\', \\'update\\')\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\n\\t\\t<!-- Google Analytics v3 (deprecated) -->\\n\\t\\t<script>\\n\\t\\t\\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\\n\\t\\t\\t\\t(function (i, s, o, g, r, a, m) {\\n\\t\\t\\t\\t\\ti[\"GoogleAnalyticsObject\"] = r;\\n\\t\\t\\t\\t\\t(i[r] =\\n\\t\\t\\t\\t\\t\\ti[r] ||\\n\\t\\t\\t\\t\\t\\tfunction () {\\n\\t\\t\\t\\t\\t\\t\\t(i[r].q = i[r].q || []).push(arguments);\\n\\t\\t\\t\\t\\t\\t}),\\n\\t\\t\\t\\t\\t\\t(i[r].l = 1 * new Date());\\n\\t\\t\\t\\t\\t(a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);\\n\\t\\t\\t\\t\\ta.async = 1;\\n\\t\\t\\t\\t\\ta.src = g;\\n\\t\\t\\t\\t\\tm.parentNode.insertBefore(a, m);\\n\\t\\t\\t\\t})(window, document, \"script\", \"https://www.google-analytics.com/analytics.js\", \"ganalytics\");\\n\\t\\t\\t\\tganalytics(\"create\", \"UA-83738774-2\", \"auto\");\\n\\t\\t\\t\\tganalytics(\"send\", \"pageview\", \"/docs/transformers/v4.34.0/en/model_doc/umt5\");\\n\\t\\t\\t}\\n\\t\\t</script>\\n\\t\\n\\n<iframe name=\"__privateStripeMetricsController8950\" frameborder=\"0\" allowtransparency=\"true\" scrolling=\"no\" role=\"presentation\" allow=\"payment *\" src=\"https://js.stripe.com/v3/m-outer-27c67c0d52761104439bb051c7856ab1.html#url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftransformers%2Fv4.34.0%2Fen%2Fmodel_doc%2Fumt5&amp;title=Sample%20usage&amp;referrer=&amp;muid=NA&amp;sid=NA&amp;version=6&amp;preview=false\" aria-hidden=\"true\" tabindex=\"-1\" style=\"border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;\"></iframe></body></html>',\n",
       "  'mime_type': 'text/plain',\n",
       "  'metadata': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        document_id=str(idx),\n",
    "        content=context,\n",
    "        mime_type=\"text/plain\",\n",
    "        metadata={},\n",
    "    )\n",
    "    for idx, context in zip(df.index, df[\"context\"])\n",
    "]\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████▉                                                      | 27/100 [06:34<34:43, 28.54s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(documents))):\n",
    "    client.memory.insert(\n",
    "        bank_id=bank_id,\n",
    "        documents=[documents[i]],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
