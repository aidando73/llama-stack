{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Server command:\n",
    "\n",
    "```bash\n",
    "# Setup\n",
    "source ~/miniconda3/bin/activate\n",
    "conda create --prefix ./envs python=3.10\n",
    "pip install -e .\n",
    "llama download --model-id Llama3.2-11B-Vision-Instruct\n",
    "llama download --model-id Llama-Guard-3-1B\n",
    "\n",
    "export LLAMA_STACK_PORT=5001\n",
    "export INFERENCE_MODEL=meta-llama/Llama-3.2-11B-Vision-Instruct\n",
    "export INFERENCE_PORT=8000\n",
    "export SAFETY_MODEL=meta-llama/Llama-Guard-3-1B\n",
    "\n",
    "# Start server\n",
    "source ~/miniconda3/bin/activate\n",
    "conda activate ./envs\n",
    "llama stack build --template meta-reference-gpu --image-type conda && track llama stack run distributions/meta-reference-gpu/run-with-safety.yaml \\\n",
    "  --port 5001 \\\n",
    "  --env INFERENCE_MODEL=meta-llama/Llama-3.2-11B-Vision-Instruct\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank_496762bf-7a55-435f-9133-7520f8769673'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.types.memory_insert_params import Document\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=\"http://localhost:5001\",\n",
    ")\n",
    "\n",
    "providers = client.providers.list()\n",
    "memory_banks_response = client.memory_banks.list()\n",
    "\n",
    "bank_id = f\"bank_{uuid.uuid4()}\"\n",
    "provider = providers[\"memory\"][0]\n",
    "client.memory_banks.register(\n",
    "    memory_bank_id=bank_id,\n",
    "    params={\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "        # Is the default for agent config: https://github.com/meta-llama/llama-stack/blob/66d8f4ffd126bff668434b314892a99fe854a034/llama_stack/providers/inline/agents/meta_reference/agent_instance.py#L668\n",
    "        \"chunk_size_in_tokens\": 512,\n",
    "    },\n",
    "    provider_id=provider.provider_id,\n",
    ")\n",
    "bank_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"long_story.txt\", \"r\") as f:\n",
    "    story = f.read()\n",
    "\n",
    "document = Document(\n",
    "    document_id=str(uuid.uuid4()),\n",
    "    content=story,\n",
    "    metadata={\"source\": \"long_story.txt\"}\n",
    ")\n",
    "\n",
    "client.memory.insert(\n",
    "    bank_id=bank_id,\n",
    "    documents=[document],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
