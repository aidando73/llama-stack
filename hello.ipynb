{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(completion_message=CompletionMessage(content=\"Hello there! It's great to meet you, world client! How can I help you today?\", role='assistant', stop_reason='end_of_turn', tool_calls=[]), logprobs=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "from IPython.display import display\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=\"http://localhost:5001\",\n",
    ")\n",
    "\n",
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world client!\"},\n",
    "    ],\n",
    "    # stream=True,\n",
    ")\n",
    "\n",
    "display(response)\n",
    "\n",
    "# for chunk in response:\n",
    "    # print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inference': [ProviderInfo(provider_id='groq', provider_type='remote::groq')],\n",
       " 'memory': [ProviderInfo(provider_id='faiss', provider_type='inline::faiss')],\n",
       " 'safety': [ProviderInfo(provider_id='llama-guard', provider_type='inline::llama-guard')],\n",
       " 'agents': [ProviderInfo(provider_id='meta-reference', provider_type='inline::meta-reference')],\n",
       " 'telemetry': [ProviderInfo(provider_id='meta-reference', provider_type='inline::meta-reference')],\n",
       " 'eval': [ProviderInfo(provider_id='meta-reference', provider_type='inline::meta-reference')],\n",
       " 'datasetio': [ProviderInfo(provider_id='localfs', provider_type='inline::localfs')],\n",
       " 'scoring': [ProviderInfo(provider_id='basic', provider_type='inline::basic')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.providers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A question that has puzzled humans for centuries!\n",
      "\n",
      "In many organizations, systems, and societies, it can be tricky to determine who is really in charge. Sometimes, it may seem like there are multiple individuals or groups holding power, or that power is distributed unevenly. Here are a few common scenarios:\n",
      "\n",
      "1. **Autocratic leaders**: In some cases, a single individual has absolute authority, making decisions without input from others. This can be seen in dictatorships or strongly hierarchical organizations.\n",
      "2. **Collective leadership**: In other situations, power is distributed among a group of individuals, such as a council, board, or cabinet. Each member may have a specific role, and decisions are made through collective consensus or voting.\n",
      "3. **Informal power structures**: In many organizations, informal networks and cliques can exert significant influence, even if they don't formally hold positions of authority. These dynamics can be difficult to quantify or understand.\n",
      "4. **Hidden agendas**: In some cases, individuals or groups may be pulling the strings from behind the scenes, influencing decisions without being openly recognized as the power holders.\n",
      "\n",
      "In some systems, it's challenging to determine who is \"really\" in charge because:\n",
      "\n",
      "1. **Delegation and distributed decision-making**: In organizations, decision-making power may be delegated to lower-level managers or teams, making it difficult to pinpoint a single authority figure.\n",
      "2. **Distributed power**: In some cases, power is distributed among multiple stakeholders, such as shareholders, customers, suppliers, or regulatory bodies.\n",
      "3. **Adaptive systems**: Complex systems, like ecosystems or markets, may be driven by feedback loops and internal dynamics, making it hard to identify a single entity in charge.\n",
      "4. **Subtle influences**: Social relationships, cultural background, and personal biases can all contribute to an individual's influence and power, even if they don't hold an official position.\n",
      "\n",
      "To navigate these complexities, it's essential to:\n",
      "\n",
      "1. **Understand the organizational structure**: Familiarize yourself with the formal and informal hierarchies, roles, and decision-making processes.\n",
      "2. **Observe and analyze behavior**: Pay attention to how individuals and groups interact, make decisions, and exert influence.\n",
      "3. **Identify key stakeholders**: Recognize the individuals and groups with significant influence, even if they don't formally hold power.\n",
      "4. **Be aware of hidden agendas and biases**: Consider the potential biases and interests that may shape decisions and actions.\n",
      "\n",
      "Remember, \"who's in charge\" is often a matter of perspective and context. By being attentive to these factors, you can better understand the dynamics at play and navigate complex systems with greater ease."
     ]
    },
    {
     "ename": "RemoteProtocolError",
     "evalue": "peer closed connection without sending complete message body (incomplete chunked read)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_sync/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_sync/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_sync/http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_sync/http11.py:213\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions({h11\u001b[38;5;241m.\u001b[39mRemoteProtocolError: RemoteProtocolError}):\n\u001b[1;32m    214\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: peer closed connection without sending complete message body (incomplete chunked read)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39minference\u001b[38;5;241m.\u001b[39mchat_completion(\n\u001b[1;32m      2\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlama3.2-3B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mdelta, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/llama_stack_client/_streaming.py:45\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/llama_stack_client/_streaming.py:57\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[1;32m     55\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sse \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m process_data(data\u001b[38;5;241m=\u001b[39msse\u001b[38;5;241m.\u001b[39mjson(), cast_to\u001b[38;5;241m=\u001b[39mcast_to, response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Ensure the entire stream is consumed\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/llama_stack_client/_streaming.py:49\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter_bytes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_bytes())\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/llama_stack_client/_streaming.py:203\u001b[0m, in \u001b[0;36mSSEDecoder.iter_bytes\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_chunks(iterator):\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;66;03m# Split before decoding so splitlines() only uses \\r and \\n\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m raw_line \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39msplitlines():\n\u001b[1;32m    206\u001b[0m             line \u001b[38;5;241m=\u001b[39m raw_line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/llama_stack_client/_streaming.py:214\u001b[0m, in \u001b[0;36mSSEDecoder._iter_chunks\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39msplitlines(keepends\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    216\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m line\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_transports/default.py:126\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: peer closed connection without sending complete message body (incomplete chunked read)"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who is really in charge?\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
