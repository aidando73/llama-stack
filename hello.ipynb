{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(completion_message=CompletionMessage(content=\"Hello there! How are you today? I'm excited to be your AI companion. What brings you to our conversation today? Do you have a specific topic you'd like to discuss or ask about? I'm all ears!\", role='assistant', stop_reason='end_of_turn', tool_calls=[]), logprobs=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "from IPython.display import display\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=\"http://localhost:5001\",\n",
    ")\n",
    "\n",
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world client!\"},\n",
    "    ],\n",
    "    # stream=True,\n",
    ")\n",
    "\n",
    "display(response)\n",
    "\n",
    "# for chunk in response:\n",
    "    # print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inference': [ProviderInfo(provider_id='groq', provider_type='remote::groq')],\n",
       " 'memory': [ProviderInfo(provider_id='faiss', provider_type='inline::faiss')],\n",
       " 'safety': [ProviderInfo(provider_id='llama-guard', provider_type='inline::llama-guard')],\n",
       " 'agents': [ProviderInfo(provider_id='meta-reference', provider_type='inline::meta-reference')],\n",
       " 'telemetry': [ProviderInfo(provider_id='meta-reference', provider_type='inline::meta-reference')],\n",
       " 'eval': [ProviderInfo(provider_id='meta-reference', provider_type='inline::meta-reference')],\n",
       " 'datasetio': [ProviderInfo(provider_id='localfs', provider_type='inline::localfs')],\n",
       " 'scoring': [ProviderInfo(provider_id='basic', provider_type='inline::basic')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.providers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASGI (Asynchronous Server Gateway Interface) is a Python specification for server-side APIs. It allows developers to create asynchronous, concurrent, and scalable web applications. ASGI is designed to be a successor to the WSGI (Web Server Gateway Interface) standard, which is used for traditional synchronous web applications.\n",
      "\n",
      "Here's how ASGI works:\n",
      "\n",
      "**ASGI Components**\n",
      "\n",
      "1. **ASGI Application**: The ASGI application is the main entry point for the ASGI server. It's responsible for handling requests and sending responses. ASGI applications are similar to WSGI applications, but they're designed to handle asynchronous requests and responses.\n",
      "2. **ASGI Server**: The ASGI server is responsible for handling incoming requests and forwarding them to the ASGI application. ASGI servers can be implemented using various technologies, such as asyncio, uvloop, or traditional threading.\n",
      "3. **ASGI Protocol**: The ASGI protocol defines the communication between the ASGI application and the ASGI server. It specifies how requests and responses are serialized and transmitted over the network.\n",
      "\n",
      "**ASGI Request and Response**\n",
      "\n",
      "1. **Request**: An ASGI request consists of two parts:\n",
      "\t* **Message**: The message is the underlying data that represents the request. It includes information such as the request method, URI, headers, and body.\n",
      "\t* **Body**: The body is the actual data sent in the request, such as JSON or form data.\n",
      "2. **Response**: An ASGI response consists of two parts:\n",
      "\t* **Message**: The message is the response to the request. It includes information such as the response status code, headers, and body.\n",
      "\t* **Body**: The body is the actual data sent in the response, such as JSON or HTML.\n",
      "\n",
      "**ASGI Protocol Messages**\n",
      "\n",
      "The ASGI protocol uses a text-based protocol to communicate between the ASGI application and the ASGI server. There are three types of messages:\n",
      "\n",
      "1. **onCONNECT**: Sent from the ASGI application to the ASGI server when a new connection is established.\n",
      "2. **onSEND**: Sent from the ASGI application to the ASGI server to transmit request data.\n",
      "3. **onRECV**: Sent from the ASGI server to the ASGI application when request data is received.\n",
      "4. **onSHUTDOWN**: Sent from the ASGI application to the ASGI server when the connection is closed.\n",
      "\n",
      "**How ASGI Works**\n",
      "\n",
      "Here's an example of how ASGI works:\n",
      "\n",
      "1. A client sends a request to the ASGI server.\n",
      "2. The ASGI server creates a new connection and sends an `onCONNECT` message to the ASGI application.\n",
      "3. The ASGI application receives the `onCONNECT` message and initializes a new request.\n",
      "4. The ASGI application sends an `onSEND` message to the ASGI server to transmit the request data.\n",
      "5. The ASGI server receives the request data and sends an `onRECV` message to the ASGI application.\n",
      "6. The ASGI application processes the request and generates a response.\n",
      "7. The ASGI application sends an `onSEND` message to the ASGI server to transmit the response data.\n",
      "8. The ASGI server receives the response data and sends it back to the client.\n",
      "\n",
      "**Benefits of ASGI**\n",
      "\n",
      "1. **Concurrency**: ASGI allows for true concurrency, enabling multiple requests to be handled simultaneously.\n",
      "2. **Scalability**: ASGI applications can be scaled vertically or horizontally to handle increasing traffic.\n",
      "3. **Low-overhead**: ASGI applications have lower overhead compared to traditional synchronous web applications.\n",
      "4. **Flexibility**: ASGI applications can be implemented using various programming languages and frameworks.\n",
      "\n",
      "In summary, ASGI is a Python specification that enables asynchronous, concurrent, and scalable web applications. It provides a lightweight and flexible framework for building high-performance web applications."
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain to me how ASGI in python works\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASGI (Asynchronous Server Gateway Interface) is a specification for building asynchronous web servers and applications in Python. It provides a standardized way for developers to write asynchronous code that can be executed by multiple frameworks and servers.\n",
      "\n",
      "Here's a high-level overview of how ASGI works:\n",
      "\n",
      "**ASGI Spec**\n",
      "\n",
      "The ASGI specification defines a few key components:\n",
      "\n",
      "1. **ASGI Application**: This is the core of the ASGI system. It's an object that implements the `asgi` module, which provides an interface for handling incoming requests and sending responses.\n",
      "2. **ASGI Server**: This is the component that runs the ASGI application. It's responsible for accepting incoming connections, dispatching requests to the application, and sending responses back to the client.\n",
      "3. **ASGI Protocol**: This is the communication protocol used by the ASGI server and application to exchange messages. It's based on TCP and supports bidirectional communication.\n",
      "\n",
      "**ASGI Request/Response Cycle**\n",
      "\n",
      "Here's a step-by-step breakdown of the ASGI request/response cycle:\n",
      "\n",
      "1. **Client connects**: A client (e.g., a web browser) establishes a connection to the ASGI server.\n",
      "2. **Server dispatches**: The server dispatches the incoming connection to the ASGI application.\n",
      "3. **Application receives**: The ASGI application receives the request from the server and performs any necessary processing (e.g., handling forms, authenticating users, or validating input).\n",
      "4. **Application sends response**: The ASGI application sends a response back to the server, which is then sent to the client.\n",
      "5. **Server sends response**: The server sends the response to the client.\n",
      "\n",
      "**ASGI Protocol Messages**\n",
      "\n",
      "The ASGI protocol uses the following types of messages to communicate between the server and application:\n",
      "\n",
      "1. ** message**: This is the primary message type used for request/response exchange. It contains the request data, such as headers, method, and path.\n",
      "2. **ready**: This message is used to indicate that the application is ready to receive the next message.\n",
      "3. **complete**: This message is used to indicate that the response is complete and can be sent to the client.\n",
      "\n",
      "**Python Framework Support**\n",
      "\n",
      "Several Python frameworks support ASGI, including:\n",
      "\n",
      "1. **ASGI**: The official ASGI specification provides a reference implementation in Python.\n",
      "2. **Django**: Django 3.1 and later versions support ASGI through the `django.asgi` module.\n",
      "3. **FastAPI**: FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\n",
      "4. **Sanic**: Sanic is a Python 3.7+ web framework that's built on top of uvloop and httptools, allowing for high-performance async web development.\n",
      "\n",
      "When using ASGI with a Python framework, you typically need to:\n",
      "\n",
      "1. Create an ASGI application object, which implements the `asgi` module.\n",
      "2. Register the application with the ASGI server.\n",
      "3. Start the ASGI server to begin handling incoming requests and sending responses.\n",
      "\n",
      "By using ASGI, you can build high-performance, scalable, and concurrent web applications with Python."
     ]
    }
   ],
   "source": [
    "from llama_models.datatypes import SamplingParams\n",
    "\n",
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain to me how ASGI in python works\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    sampling_params=SamplingParams(\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASGI (Asynchronous Server Gateway Interface) is a standard for Python web servers that allows them to communicate with web frameworks and other applications in an asynchronous manner. It's designed to be a replacement for the older WSGI (Web Server Gateway Interface) standard, which was synchronous.\n",
      "\n",
      "Here's a high-level overview of how ASGI works:\n",
      "\n",
      "**The Problem with WSGI**\n",
      "\n",
      "WSGI was introduced in the early 2000s as a way for web frameworks to communicate with web servers. However, WSGI is synchronous, meaning that it blocks the execution of the web server until the web framework has finished processing the request. This can lead to performance issues and scalability problems, especially in modern web applications that require handling many concurrent requests.\n",
      "\n",
      "**The Solution: ASGI**\n",
      "\n",
      "ASGI addresses the limitations of WSGI by introducing an asynchronous programming model. Instead of blocking the execution of the web server, ASGI allows the web framework to yield control back to the web server at specific points in the request processing pipeline. This allows the web server to handle other requests concurrently, improving performance and scalability.\n",
      "\n",
      "**The ASGI Protocol**\n",
      "\n",
      "The ASGI protocol defines a set of messages that can be sent between the web server and the web framework. These messages include:\n",
      "\n",
      "1. `connect`: The web server sends a `connect` message to the web framework to initiate a new connection.\n",
      "2. `receive`: The web framework sends a `receive` message to the web server to receive a request.\n",
      "3. `send`: The web framework sends a `send` message to the web server to send a response.\n",
      "4. `close`: The web framework sends a `close` message to the web server to close the connection.\n",
      "\n",
      "**How ASGI Works**\n",
      "\n",
      "Here's a step-by-step explanation of how ASGI works:\n",
      "\n",
      "1. The web server receives a request and sends a `connect` message to the web framework.\n",
      "2. The web framework processes the request and yields control back to the web server at specific points in the request processing pipeline (e.g., when waiting for I/O operations to complete).\n",
      "3. The web server handles other requests concurrently while the web framework is yielding control.\n",
      "4. When the web framework is ready to send a response, it sends a `send` message to the web server.\n",
      "5. The web server sends the response back to the client.\n",
      "6. When the response is complete, the web framework sends a `close` message to the web server to close the connection.\n",
      "\n",
      "**ASGI Implementations**\n",
      "\n",
      "There are several ASGI implementations available for Python, including:\n",
      "\n",
      "1. `uvicorn`: A popular ASGI server that supports HTTP/1.1 and HTTP/2.\n",
      "2. `hypercorn`: Another popular ASGI server that supports HTTP/1.1 and HTTP/2.\n",
      "3. `daphne`: An ASGI server that supports WebSockets and other advanced features.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "ASGI is a powerful standard for Python web servers that allows them to communicate with web frameworks in an asynchronous manner. By yielding control back to the web server at specific points in the request processing pipeline, ASGI enables web servers to handle many concurrent requests, improving performance and scalability."
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain to me how ASGI in python works\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    sampling_params=SamplingParams(\n",
    "        top_p=1\n",
    "    ),\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASGI (Asynchronous Server Gateway Interface) is a standard for Python web servers that allows them to communicate with web frameworks and other applications in an asynchronous manner. It's designed to be a replacement for the older WSGI (Web Server Gateway Interface"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain to me how ASGI in python works\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    sampling_params=SamplingParams(\n",
    "        max_tokens=50\n",
    "    ),\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ToolDefinition' from 'llama_models.datatypes' (/Users/aidand/dev/llama-stack/envs/lib/python3.10/site-packages/llama_models/datatypes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolDefinition\n\u001b[1;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39minference\u001b[38;5;241m.\u001b[39mchat_completion(\n\u001b[1;32m      4\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlama3.2-3B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     ]\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ToolDefinition' from 'llama_models.datatypes' (/Users/aidand/dev/llama-stack/envs/lib/python3.10/site-packages/llama_models/datatypes.py)"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain to me how ASGI in python works\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    sampling_params=SamplingParams(\n",
    "        max_tokens=50\n",
    "    ),\n",
    "    logprobs={\n",
    "        \"top_k\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatCompletionResponse' object has no attribute 'event'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/pydantic/main.py:884\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpydantic_extra\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'event'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 27\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39minference\u001b[38;5;241m.\u001b[39mchat_completion(\n\u001b[1;32m      2\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlama3.2-3B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     ]\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241m.\u001b[39mdelta, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/llama-stack/envs/lib/python3.10/site-packages/pydantic/main.py:886\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pydantic_extra[item]\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 886\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, item):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatCompletionResponse' object has no attribute 'event'"
     ]
    }
   ],
   "source": [
    "response = client.inference.chat_completion(\n",
    "    model_id=\"Llama3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"When's the next flight from Adelaide to Sydney?\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    tools=[\n",
    "        {\n",
    "            \"tool_name\": \"get_flight_info\",\n",
    "            \"parameters\": {\n",
    "                \"origin\": {\n",
    "                    \"param_type\": \"string\",\n",
    "                    \"description\": \"The origin airport code. E.g., AU\",\n",
    "                    \"required\": True,\n",
    "                },\n",
    "                \"destination\": {\n",
    "                    \"param_type\": \"string\",\n",
    "                    \"description\": \"The destination airport code. E.g., 'LAX'\",\n",
    "                    \"required\": True,\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.event.delta, end='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
