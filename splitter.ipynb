{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.0-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.3 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.3.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.3.0-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.57.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (6.0.2)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (3.11.10)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Using cached Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (2.1.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (11.0.0)\n",
      "Collecting pydantic<2.10.0,>=2.7.0 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./envs/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Using cached wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting llama-cloud>=0.1.5 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.6-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: pandas in ./envs/lib/python3.10/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./envs/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in ./envs/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in ./envs/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./envs/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./envs/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./envs/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in ./envs/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in ./envs/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./envs/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in ./envs/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./envs/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./envs/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in ./envs/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./envs/lib/python3.10/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (0.7.0)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./envs/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./envs/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.3->llama-index)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./envs/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./envs/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./envs/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./envs/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./envs/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.3->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in ./envs/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.12.3-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_agent_openai-0.4.0-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.12.3-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.3.2-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.3.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.1-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_cloud-0.1.6-py3-none-any.whl (195 kB)\n",
      "Downloading llama_parse-0.5.17-py3-none-any.whl (14 kB)\n",
      "Downloading openai-1.57.0-py3-none-any.whl (389 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m141.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m160.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, tenacity, pydantic-core, mypy-extensions, marshmallow, joblib, jiter, greenlet, typing-inspect, SQLAlchemy, pydantic, nltk, deprecated, openai, llama-cloud, dataclasses-json, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.1\n",
      "    Uninstalling pydantic_core-2.27.1:\n",
      "      Successfully uninstalled pydantic_core-2.27.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/ubuntu/1xa100-2/llama-stack/envs/lib/python3.10/site-packages/~ydantic_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.2\n",
      "    Uninstalling pydantic-2.10.2:\n",
      "      Successfully uninstalled pydantic-2.10.2\n",
      "Successfully installed SQLAlchemy-2.0.36 dataclasses-json-0.6.7 deprecated-1.2.15 dirtyjson-1.0.8 filetype-1.2.0 greenlet-3.1.1 jiter-0.8.0 joblib-1.4.2 llama-cloud-0.1.6 llama-index-0.12.3 llama-index-agent-openai-0.4.0 llama-index-cli-0.4.0 llama-index-core-0.12.3 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.3.2 llama-index-multi-modal-llms-openai-0.3.0 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.1 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.17 marshmallow-3.23.1 mypy-extensions-1.0.0 nltk-3.9.1 openai-1.57.0 pydantic-2.9.2 pydantic-core-2.23.4 striprtf-0.0.26 tenacity-8.5.0 typing-inspect-0.9.0 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser.text import SentenceSplitter\n",
    "\n",
    "chunker = SentenceSplitter(chunk_size=512, chunk_overlap=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"deepmind/narrativeqa\")\n",
    "df = dataset[\"validation\"].to_pandas()\n",
    "df['context'] = df['document'].apply(lambda x: x['summary']['text'])\n",
    "df['question'] = df['question'].apply(lambda x: x['text'])\n",
    "df = df.rename(columns={'question': 'questions'})\n",
    "df = df.groupby('context').agg({'questions': list}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['\"Goblin Market\" is about two close sisters, Laura and Lizzie, as well as the goblins to whom the title refers.\\nAlthough the sisters seem to be quite young, they live by themselves in a house, and are accustomed to draw water every evening from a stream. As the poem begins, twilight is falling, and as usual, the sisters hear the calls from the goblin merchants, who sell fruits in fantastic abundance, variety and savour. On this evening, Laura lingers at the stream after her sister has left for home, intrigued by the goblins\\' strange manner and appearance. (Rossetti hints that the \"goblin men\" resemble animalsâ\\x80\\x94for example, having faces like wombats or cats, and possessing tails.) Longing for the goblin fruits but having no money, the impulsive Laura offers a lock of her hair and \"a tear more rare than pearl.\"\\nLaura gorges on the delicious fruit in a sort of bacchic frenzy, then once she is finished, after picking up one of the seeds, returns home in an ecstatic trance. Lizzie, waiting at home, and \"full of wise upbraidings,\" reminds Laura about the cautionary tale of Jeanie, another girl, who, having likewise partaken of the goblins\\' fruits, died just at the beginning of winter, after a long and pathetic decline. Strangely, no grass grows over Jeanie\\'s grave. Laura dismisses her sister\\'s worries, and says she shall return to the goblins the next night and return with more fruits for herself and Lizzie. That night, the sisters go to sleep in their shared bed.\\nThe next day, as Laura and Lizzie go about their work in the house, Laura dreamily longs for the coming evening\\'s meeting with the goblins. However, at the stream that evening, as she strains to hear the usual goblin chants and cries, Laura discovers to her horror that, although Lizzie still hears the goblins\\' voices, she cannot.\\nUnable to buy more of the forbidden fruit, and sickening for the lack of it, Laura falls into a slow physical deterioration and depression. As winter approaches, she withers away, aging at an unnatural rate and physically unable to do her accustomed household work. One day she remembers the saved seed and plants it, but nothing grows.\\nMonths pass, and Lizzie realizes that Laura is on the verge of death.',\n",
       " \"However, at the stream that evening, as she strains to hear the usual goblin chants and cries, Laura discovers to her horror that, although Lizzie still hears the goblins' voices, she cannot.\\nUnable to buy more of the forbidden fruit, and sickening for the lack of it, Laura falls into a slow physical deterioration and depression. As winter approaches, she withers away, aging at an unnatural rate and physically unable to do her accustomed household work. One day she remembers the saved seed and plants it, but nothing grows.\\nMonths pass, and Lizzie realizes that Laura is on the verge of death. Lizzie resolves to visit the goblins to buy some of their fruit, hoping to soothe Laura's pain. Carrying a silver penny, Lizzie goes down to the brook and is greeted in a friendly way by the goblins, who invite her to sit and dine with them. When they realize, however, that the Lizzie means to pay with mere silver to buy the goblin-fruits to help another person, they turn upon the girl. The goblins viciously pummel and assault Lizzie, and try to feed her their fruits by force. In the process, they drench the brave girl in fruit juice and pulpâ\\x80\\x94but Lizzie ingests none of the goblin fruit.\\nLizzie escapes and runs home, hoping that Laura will eat and drink the pulp and juice from her body. Her dying sister does so, but the taste of the fruit repulses her rather than satisfies her hunger. Laura then undergoes a violent transformation of such intensity that her life seems to hang in the balance.\\nBy morning, however, Laura is restored, emotionally, physically, and mentally. The last stanza attests that both Laura and Lizzie live to tell their children of the evils of the goblins' fruitsâ\\x80\\x94and the powers of sisterly love.\",\n",
       " \"(From Conan The Warrior, ISBN 0-441-11465-2)\\nThe foreword to the story tells of his travels to Punt with Muriela, refers to a scam perpetrated against worshippers of an ivory goddess and then on to Zembabwei, where he joins a trading caravan on its way to Shem. Around 40 now, Conan visits his homeland and finds his old friends are fathers. Bored, Conan sets off for the Bossonian Marches and becomes a Scout at Fort Tuscelan on the Black River. Naturally, there is a war going on...\\nA young settler named Balthus encounters Conan in the forests slaying a forest devil. Accompanying the young man back to the Fort, Conan finds the body of a merchant ensorcelled by a Pictish wizard named Zogar Sag and slain by a swamp demon.\\nThe Fort Tuscelan Commander, Valannus, is a desperate man and asks Conan to slay Zogar Sag before he raises the Picts against the whole borderlands. Taking a hand picked team of scouts and Balthus, Conan sets off stealthily in canoes. Balthus is captured and most of Conan's men slaughtered in an ambush.\\nBalthus and one of the Scouts are tied to stakes and the scout is sacrificed by Zogar Sag to one of his jungle creatures. Before Balthus can meet a similar fate, Conan sets the Pictish village on fire and the two flee into the woods. Conan tells Balthus of the cult of Jhebbal Sag, now forgotten by most. Once all living things worshipped him when men and beasts spoke the same language. Over time men and most beasts forgot his worship. Zogar Sag has not, however, and can control those few animals and creatures who also remember. And they are on Conan's trail now.\\nConan is able to neutralize them using a symbol he once noticed, and the pair hurry to return to the Fort to warn them of the impending Pictish assault, but they are too late. The Picts already are all around the fort, and furious fighting is going on. The number of Picts ensures that eventually the fort will be overwhelmed and the defenders slaughtered. The only thing left to do is warn the settlers to flee while the Picts are busy with the fort - otherwise they will be slaughtered, too.\",\n",
       " 'And they are on Conan\\'s trail now.\\nConan is able to neutralize them using a symbol he once noticed, and the pair hurry to return to the Fort to warn them of the impending Pictish assault, but they are too late. The Picts already are all around the fort, and furious fighting is going on. The number of Picts ensures that eventually the fort will be overwhelmed and the defenders slaughtered. The only thing left to do is warn the settlers to flee while the Picts are busy with the fort - otherwise they will be slaughtered, too.\\nConan and Balthus go to warn the settlers that the Picts have crossed the river and are raiding. They are joined by Slasher, a feral dog formerly owned by a settler who had been slain by the Picts. Balthus is sent on to warn settlers of the coming Pict raid, and Conan parts from him to warn a group of settler who had gone to gather salt. Balthus warns women and children to leave their huts and flee. When a band of Picts arrives, who move quicker and might overtake the women, Balthus stays behind to cover their escape. Accompanied by Slasher he makes a stand against the coming Pict raiders, first shooting arrows from concealment and then in a furious face to face battle. The man and dog\\'s sacrifice delays the Picts and gives the settlers time to reach safety. Conan manages to warn the salt-gathering party in time, but finds he has been marked for death by the gods of darkness for misusing the symbol of Jhebbal Sag. In the end Conan triumphs, but the fort is lost, and so is the entire province.\\nThe story ends in a tavern. A survivor tells Conan about the courageous act of Balthus and Slasher, and how their final stand had delayed the Picts just barely long enough for the settlers to reach safety. Upon hearing of the fight, Conan vowed to take the heads of ten Picts to pay for Balthus\\' sacrifice, along with seven heads for the dog, who was \"a better warrior than many a man.\"',\n",
       " '(Note: The following synopsis was that of Emma Goldman, as published in a 1914 collection entitled The Social Significance of the Moden Drama:)\\nThe play opens in the office of James How & Sons, solicitors. The senior clerk, Robert Cokeson, discovers that a check he had issued for nine pounds has been forged to ninety. By elimination, suspicion falls upon William Falder, the junior office clerk. The latter is in love with a married woman, the abused and ill-treated wife of a brutal drunkard. Pressed by his employer, a severe yet not unkindly man, Falder confesses the forgery, pleading the dire necessity of his sweetheart, Ruth Honeywill, with whom he had planned to escape to save her from the unbearable brutality of her husband. Notwithstanding the entreaties of young Walter How, who holds modern ideas, his father, a moral and law-respecting citizen, turns Falder over to the police.\\nThe second act, in the court room, shows Justice in the very process of manufacture. The scene equals in dramatic power and psychologic verity the great court scene in \"Resurrection\". Young Falder, a youth of twenty-three, stands before the bar. Ruth, his faithful sweetheart, full of love and devotion, burns with anxiety to save the young man, whose affection for her has brought about his present predicament. Falder is defended by Lawyer Frome, whose speech to the jury is a masterpiece of social philosophy. He does not attempt to dispute the mere fact that his client had altered the check; and though he pleads temporary aberration in his defense, the argument is based on a social consciousness as fundamental and all-embracing as the roots of our social ills. He shows Falder to have faced the alternative of seeing the beloved woman murdered by her brutal husband, whom she cannot divorce, or of taking the law into his own hands. He pleads with the jury not to turn the weak young man into a criminal by condemning him to prison.\\nIn prison the young, inexperienced convict soon finds himself the victim of the terrible \"system.\" The authorities admit that young Falder is mentally and physically \"in bad shape,\" but nothing can be done in the matter: many others are in a similar position, and \"the quarters are inadequate.\"\\nThe third scene of the third act takes place in Falder\\'s prison cell.\\nFalder leaves the prison, a broken man.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "for idx, row in df.iterrows():\n",
    "    chunks.extend(chunker.split_text(row['context']))\n",
    "\n",
    "display(len(chunks))\n",
    "chunks[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
